{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import importlib\n",
    "importlib.reload(logging) # see https://stackoverflow.com/a/21475297/1469195\n",
    "log = logging.getLogger()\n",
    "log.setLevel('INFO')\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s : %(message)s',\n",
    "                     level=logging.INFO, stream=sys.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import os\n",
    "import site\n",
    "os.sys.path.insert(0, '/home/schirrmr/code/reversible/')\n",
    "os.sys.path.insert(0, '/home/schirrmr/braindecode/code/braindecode/')\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import logging\n",
    "log = logging.getLogger()\n",
    "log.setLevel('INFO')\n",
    "import sys\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s : %(message)s',\n",
    "                     level=logging.INFO, stream=sys.stdout)\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'png'\n",
    "matplotlib.rcParams['figure.figsize'] = (12.0, 1.0)\n",
    "matplotlib.rcParams['font.size'] = 14\n",
    "import seaborn\n",
    "seaborn.set_style('darkgrid')\n",
    "\n",
    "from reversible2.sliced import sliced_from_samples\n",
    "from numpy.random import RandomState\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import copy\n",
    "import math\n",
    "\n",
    "import itertools\n",
    "import torch as th\n",
    "from braindecode.torch_ext.util import np_to_var, var_to_np\n",
    "from reversible2.splitter import SubsampleSplitter\n",
    "\n",
    "from reversible2.view_as import ViewAs\n",
    "\n",
    "from reversible2.affine import AdditiveBlock\n",
    "from reversible2.plot import display_text, display_close\n",
    "from reversible2.bhno import load_file, create_inputs\n",
    "th.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_names = ['C3',]\n",
    "orig_train_cnt = load_file('/data/schirrmr/schirrmr/HGD-public/reduced/train/4.mat')\n",
    "train_cnt = orig_train_cnt.reorder_channels(sensor_names)\n",
    "\n",
    "train_inputs = create_inputs(train_cnt, final_hz=64, half_before=True,\n",
    "                            start_ms=500,stop_ms=1500)\n",
    "t = train_inputs[1]\n",
    "\n",
    "t_fft = th.rfft(t.squeeze(), signal_ndim=1)\n",
    "t_fft[:,7:13] *= 2\n",
    "train_inputs[1] = th.irfft(t_fft, signal_sizes=[64], signal_ndim=1).unsqueeze(1).unsqueeze(-1).detach().clone()\n",
    "n_split = len(train_inputs[0]) - 40\n",
    "test_inputs = [t[-40:] for t in train_inputs]\n",
    "train_inputs = [t[:-40] for t in train_inputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cuda = True\n",
    "if cuda:\n",
    "    train_inputs = [i.cuda() for i in train_inputs]\n",
    "    test_inputs = [i.cuda() for i in test_inputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from reversible2.graph import Node\n",
    "from reversible2.branching import CatChans, ChunkChans, Select\n",
    "from reversible2.constantmemory import graph_to_constant_memory\n",
    "\n",
    "from copy import deepcopy\n",
    "from reversible2.graph import Node\n",
    "from reversible2.distribution import TwoClassDist\n",
    "from reversible2.wrap_invertible import WrapInvertible\n",
    "from reversible2.blocks import dense_add_no_switch, conv_add_3x3_no_switch\n",
    "from reversible2.rfft import RFFT, Interleave\n",
    "from reversible2.util import set_random_seeds\n",
    "import torch as th\n",
    "from reversible2.splitter import SubsampleSplitter\n",
    "from reversible2.models import smaller_model\n",
    "\n",
    "final_fft = False\n",
    "constant_memory = False\n",
    "\n",
    "set_random_seeds(2019011641, cuda)\n",
    "n_chans = train_inputs[0].shape[1]\n",
    "n_time = train_inputs[0].shape[2]\n",
    "feature_model = smaller_model(n_chans, n_time, final_fft, constant_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_zero_init = False\n",
    "set_distribution_to_empirical = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reversible2.constantmemory import clear_ctx_dicts\n",
    "if data_zero_init:\n",
    "    feature_model.data_init(th.cat((train_inputs[0], train_inputs[1]), dim=0))\n",
    "\n",
    "# Check that forward + inverse is really identical\n",
    "t_out = feature_model(train_inputs[0][:2])\n",
    "inverted = feature_model.invert(t_out)\n",
    "clear_ctx_dicts(feature_model)\n",
    "assert th.allclose(train_inputs[0][:2], inverted, rtol=1e-3, atol=1e-4)\n",
    "from reversible2.ot_exact import ot_euclidean_loss_for_samples\n",
    "from reversible2.distribution import TwoClassIndependentDist\n",
    "class_dist = TwoClassIndependentDist(np.prod(train_inputs[0].size()[1:]))\n",
    "class_dist.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if set_distribution_to_empirical:\n",
    "    for i_class in range(2):\n",
    "        with th.no_grad():\n",
    "            this_outs = feature_model(train_inputs[i_class])\n",
    "            mean = th.mean(this_outs, dim=0)\n",
    "            std = th.std(this_outs, dim=0)\n",
    "            class_dist.set_mean_std(i_class, mean, std)\n",
    "            # Just check\n",
    "            setted_mean, setted_std = class_dist.get_mean_std(i_class)\n",
    "            assert th.allclose(mean, setted_mean)\n",
    "            assert th.allclose(std, setted_std)\n",
    "    clear_ctx_dicts(feature_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optim_model = th.optim.Adam(feature_model.parameters(), lr=1e-3, betas=(0.9, 0.999))\n",
    "optim_dist = th.optim.Adam(class_dist.parameters(), lr=1e-2, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_loss = None\n",
    "ot_on_class_dims = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from reversible2.training import CLFTrainer\n",
    "from reversible2.classifier import SubspaceClassifier\n",
    "from reversible2.monitor import compute_accs\n",
    "from reversible2.monitor import compute_clf_accs\n",
    "if clf_loss is not None:\n",
    "    clf = SubspaceClassifier(2, 10, np.prod(train_inputs[0].shape[1:]))\n",
    "    clf.cuda()\n",
    "\n",
    "    optim_clf = th.optim.Adam(clf.parameters(), lr=1e-3)\n",
    "    clf_trainer = CLFTrainer(\n",
    "        feature_model,\n",
    "        clf,\n",
    "        class_dist,\n",
    "        optim_model,\n",
    "        optim_clf,\n",
    "        optim_dist,\n",
    "        outs_loss=clf_loss,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "from reversible2.training import OTTrainer\n",
    "\n",
    "trainer = OTTrainer(feature_model, class_dist, optim_model, optim_dist)\n",
    "\n",
    "from reversible2.constantmemory import clear_ctx_dicts\n",
    "from reversible2.timer import Timer\n",
    "\n",
    "i_start_epoch_out = 401\n",
    "n_epochs = 1001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_epoch in range(n_epochs):\n",
    "    i_epoch = i_epoch\n",
    "    epoch_row = {}\n",
    "    with Timer(name=\"EpochLoop\", verbose=False) as loop_time:\n",
    "        loss_on_outs = i_epoch >= i_start_epoch_out\n",
    "        result = trainer.train(train_inputs, loss_on_outs=(loss_on_outs and ot_on_class_dims))\n",
    "        if clf_loss is not None:\n",
    "            result_clf = clf_trainer.train(train_inputs, loss_on_outs=loss_on_outs)\n",
    "            epoch_row.update(result_clf)\n",
    "\n",
    "    epoch_row.update(result)\n",
    "    epoch_row[\"runtime\"] = loop_time.elapsed_secs * 1000\n",
    "    acc_results = compute_accs(feature_model, train_inputs, test_inputs, class_dist)\n",
    "    epoch_row.update(acc_results)\n",
    "    if clf_loss is not None:\n",
    "        clf_accs = compute_clf_accs(clf, feature_model, train_inputs, test_inputs)\n",
    "        epoch_row.update(clf_accs)\n",
    "    if i_epoch % (n_epochs // 20) != 0:\n",
    "        df = df.append(epoch_row, ignore_index=True)\n",
    "        # otherwise add ot loss in\n",
    "    else:\n",
    "        for i_class in range(len(train_inputs)):\n",
    "            with th.no_grad():\n",
    "                class_ins = train_inputs[i_class]\n",
    "                samples = class_dist.get_samples(\n",
    "                    i_class, len(train_inputs[i_class]) * 4\n",
    "                )\n",
    "                inverted = feature_model.invert(samples)\n",
    "                clear_ctx_dicts(feature_model)\n",
    "                ot_loss_in = ot_euclidean_loss_for_samples(\n",
    "                    class_ins.view(class_ins.shape[0], -1),\n",
    "                    inverted.view(inverted.shape[0], -1)[: (len(class_ins))],\n",
    "                )\n",
    "                epoch_row[\"ot_loss_in_{:d}\".format(i_class)] = ot_loss_in.item()\n",
    "        df = df.append(epoch_row, ignore_index=True)\n",
    "        print(\"Epoch {:d} of {:d}\".format(i_epoch, n_epochs))\n",
    "        print(\"Loop Time: {:.0f} ms\".format(loop_time.elapsed_secs * 1000))\n",
    "        display(df.iloc[-3:].loc[:,['test_acc', 'test_clf_acc', 'test_data_acc', 'train_acc',\n",
    "          'train_clf_acc', 'train_data_acc',\n",
    "                'ot_loss_in_0', 'ot_loss_in_1', 'ot_out_loss', \n",
    "          'runtime', 'subspace_loss_0', 'subspace_loss_1',\n",
    "          'clf_loss_0', 'clf_loss_1',\n",
    "          'g_grad', 'g_grad_norm', 'g_loss',\n",
    "       ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.style as style\n",
    "style.use('seaborn-poster')\n",
    "seaborn.set_context('poster')\n",
    "\n",
    "seaborn.set_palette(\"colorblind\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with seaborn.axes_style(\"white\"):\n",
    "    plt.figure(figsize=(8,2))\n",
    "    plt.plot(var_to_np(train_inputs[0][0].squeeze()))\n",
    "    plt.axis('off')\n",
    "    plt.savefig('/data/schirrmr/schirrmr/ohbm-rom/signal3.png', dpi=300 ,transparent=True,\n",
    "               bbox_inches='tight', pad_inches=0)\n",
    "    plt.ylim(-2.5,2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with seaborn.axes_style(\"white\"):\n",
    "    plt.figure(figsize=(8,2))\n",
    "    plt.plot(var_to_np(train_inputs[1][0].squeeze()), color=seaborn.color_palette()[1])\n",
    "    plt.axis('off')\n",
    "    plt.savefig('/data/schirrmr/schirrmr/ohbm-rom/signal4.png', dpi=300 ,transparent=True,\n",
    "               bbox_inches='tight', pad_inches=0)\n",
    "    plt.ylim(-2.5,2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with seaborn.axes_style(\"white\"):\n",
    "    plt.figure(figsize=(8,2))\n",
    "    plt.plot(var_to_np(train_inputs[0][1].squeeze()))\n",
    "    plt.axis('off')\n",
    "    plt.savefig('/data/schirrmr/schirrmr/ohbm-rom/signal3.png', dpi=300 ,transparent=True,\n",
    "               bbox_inches='tight', pad_inches=0)\n",
    "    plt.ylim(-2.5,2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with seaborn.axes_style(\"white\"):\n",
    "    plt.figure(figsize=(8,2))\n",
    "    plt.plot(var_to_np(train_inputs[1][6].squeeze()), color=seaborn.color_palette()[1])\n",
    "    plt.axis('off')\n",
    "    plt.savefig('/data/schirrmr/schirrmr/ohbm-rom/signal4.png', dpi=300 ,transparent=True,\n",
    "               bbox_inches='tight', pad_inches=0)\n",
    "    plt.ylim(-2.5,2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([0,1], color=seaborn.color_palette()[0])\n",
    "plt.plot([0,1], color=seaborn.color_palette()[1])\n",
    "plt.legend([\"Class 1\", \"Class 2\"], bbox_to_anchor=(1,1,0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_example in range(2,8):\n",
    "    with seaborn.axes_style(\"white\"):\n",
    "        plt.figure(figsize=(8,2))\n",
    "        plt.plot(var_to_np(train_inputs[0][i_example].squeeze()))\n",
    "        plt.axis('off')\n",
    "        i_file = i_example * 2\n",
    "        plt.savefig('/data/schirrmr/schirrmr/ohbm-rom/signal{:d}.png'.format(i_file), dpi=300 ,transparent=True,\n",
    "                   bbox_inches='tight', pad_inches=0)\n",
    "        plt.ylim(-2.5,2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_example in range(2,8):\n",
    "    with seaborn.axes_style(\"white\"):\n",
    "        plt.figure(figsize=(8,2))\n",
    "        plt.plot(var_to_np(train_inputs[1][i_example].squeeze()), color=seaborn.color_palette()[1])\n",
    "        plt.axis('off')\n",
    "        i_file = i_example * 2 + 1\n",
    "        plt.savefig('/data/schirrmr/schirrmr/ohbm-rom/signal{:d}.png'.format(i_file), dpi=300 ,transparent=True,\n",
    "                   bbox_inches='tight', pad_inches=0)\n",
    "        plt.ylim(-4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,4))\n",
    "rng = RandomState(45984985)\n",
    "means = [[-2,2], [3,-3]]\n",
    "stds = [[1,0.5], [0.75,1]]\n",
    "with seaborn.axes_style(\"white\"):\n",
    "    for i_class in range(2):\n",
    "        x,y = (rng.randn(2,500) * np.array(stds[i_class])[:,None]) + np.array(means[i_class])[:,None]\n",
    "        plt.scatter(x,y, alpha=.15, color=seaborn.color_palette()[i_class])\n",
    "        plt.scatter(means[i_class][0], means[i_class][1], color=seaborn.color_palette()[i_class], \n",
    "                   label=\"Class {:d}\".format(i_class))\n",
    "        plt.scatter(means[i_class][0], means[i_class][1], color=lighten_color(seaborn.color_palette()[i_class], amount=0.75), \n",
    "                   label=\"Mean {:d}\".format(i_class),\n",
    "                    marker='x')\n",
    "        #plt.scatter(x[:3], y[:3], color=seaborn.color_palette()[i_class], marker='x')\n",
    "plt.legend(bbox_to_anchor=(0.67,1.52,0,0))\n",
    "plt.axis('off');\n",
    "plt.savefig('/data/schirrmr/schirrmr/ohbm-rom/dists.png', dpi=300 ,transparent=True,\n",
    "                   bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lighten_color(color, amount=0.5):\n",
    "    \"\"\"\n",
    "    Lightens the given color by multiplying (1-luminosity) by the given amount.\n",
    "    Input can be matplotlib color string, hex string, or RGB tuple.\n",
    "\n",
    "    Examples:\n",
    "    >> lighten_color('g', 0.3)\n",
    "    >> lighten_color('#F034A3', 0.6)\n",
    "    >> lighten_color((.3,.55,.1), 0.5)\n",
    "    \"\"\"\n",
    "    import matplotlib.colors as mc\n",
    "    import colorsys\n",
    "    try:\n",
    "        c = mc.cnames[color]\n",
    "    except:\n",
    "        c = color\n",
    "    c = colorsys.rgb_to_hls(*mc.to_rgb(c))\n",
    "    return colorsys.hls_to_rgb(c[0], 1 - amount * (1 - c[1]), c[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with seaborn.axes_style(\"white\"):\n",
    "    fig, axes = plt.subplots(2,1, figsize=(8,3), sharex=True, sharey=True)\n",
    "    for i_class in range(2):\n",
    "        axes[i_class].plot(var_to_np(train_inputs[i_class][0].squeeze()),\n",
    "                color=lighten_color(seaborn.color_palette()[i_class], amount=0.75))\n",
    "    axes[0].axis('off')\n",
    "    axes[1].axis('off')\n",
    "    ls = axes[0].get_lines() + axes[1].get_lines()\n",
    "    fig.legend(ls, [\"Mean 1\", \"Mean 2\"], fontsize=24,loc='upper right',\n",
    "              bbox_to_anchor=(1.3,0.8))\n",
    "    plt.tight_layout(pad=0)\n",
    "    plt.savefig('/data/schirrmr/schirrmr/ohbm-rom/means.png', dpi=300 ,transparent=True,\n",
    "               bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = RandomState(21434)\n",
    "prior = rng.randn(80,2) * 0.5\n",
    "outputs = rng.rand(80,2) * np.array([1,4]) + np.array([[-2,-2]])\n",
    "\n",
    "fig = plt.figure(figsize=(7,7))\n",
    "\n",
    "plt.plot(outputs[:,0], outputs[:,1], ls='', marker='o', label='Real EEG Signals',\n",
    "        color=seaborn.color_palette()[2])\n",
    "plt.plot(prior[:,0], prior[:,1], ls='', marker='o', label='Generated Signals',\n",
    "        color=seaborn.color_palette()[3])\n",
    "\n",
    "\n",
    "\n",
    "#plt.xlim(-3, 1.5)\n",
    "#plt.ylim(-2.5, 2.5)\n",
    "\n",
    "import ot\n",
    "\n",
    "dists = np.sum(np.square(prior[:,None] - outputs[None]), axis=2)\n",
    "\n",
    "t_map = ot.emd([],[], dists)\n",
    "\n",
    "matchings = np.argmax(t_map, axis=1)\n",
    "\n",
    "\n",
    "for i_line, prior_p, out_p in zip(range(len(prior)), prior, outputs[matchings]):\n",
    "    label = ''\n",
    "    if i_line == 0:\n",
    "        label = 'Matching'\n",
    "    plt.plot([prior_p[0], out_p[0]], [prior_p[1], out_p[1]], color='black',\n",
    "            lw=0.25, label=label)\n",
    "plt.legend(fontsize=22, bbox_to_anchor=(0,0,1.05,1.3))\n",
    "plt.axis('off')\n",
    "\n",
    "plt.savefig('/data/schirrmr/schirrmr/ohbm-rom/OT.png', dpi=300 ,transparent=True,\n",
    "           bbox_inches='tight', pad_inches=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_prior = prior * 0.3 + outputs * 0.7\n",
    "\n",
    "\n",
    "rng = RandomState(21434)\n",
    "\n",
    "fig = plt.figure(figsize=(7,7))\n",
    "\n",
    "plt.plot(outputs[:,0], outputs[:,1], ls='', marker='o', label='Real EEG Signals',\n",
    "        color=seaborn.color_palette()[2])\n",
    "plt.plot(new_prior[:,0], new_prior[:,1], ls='', marker='o', label='Generated Signals',\n",
    "        color=seaborn.color_palette()[3])\n",
    "\n",
    "\n",
    "\n",
    "plt.xlim(np.min(outputs)-0.2, np.max(prior))\n",
    "\n",
    "import ot\n",
    "\n",
    "dists = np.sum(np.square(new_prior[:,None] - outputs[None]), axis=2)\n",
    "\n",
    "t_map = ot.emd([],[], dists)\n",
    "\n",
    "matchings = np.argmax(t_map, axis=1)\n",
    "\n",
    "\n",
    "for i_line, prior_p, out_p in zip(range(len(prior)), new_prior, outputs[matchings]):\n",
    "    label = ''\n",
    "    if i_line == 0:\n",
    "        label = 'Matching'\n",
    "    plt.plot([prior_p[0], out_p[0]], [prior_p[1], out_p[1]], color='black',\n",
    "            lw=0.25, label=label)\n",
    "plt.legend(fontsize=22, bbox_to_anchor=(0,0,1.05,1.3))\n",
    "plt.axis('off')\n",
    "\n",
    "plt.savefig('/data/schirrmr/schirrmr/ohbm-rom/OT_updated.png', dpi=300 ,transparent=True,\n",
    "           bbox_inches='tight', pad_inches=0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
