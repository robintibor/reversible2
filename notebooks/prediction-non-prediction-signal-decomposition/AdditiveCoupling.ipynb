{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import os\n",
    "import site\n",
    "os.sys.path.insert(0, '/home/schirrmr/code/reversible/reversible2/')\n",
    "os.sys.path.insert(0, '/home/schirrmr/braindecode/code/braindecode/')\n",
    "os.sys.path.insert(0, '/home/schirrmr/code/explaining/reversible//')\n",
    "%cd /home/schirrmr/\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import logging\n",
    "log = logging.getLogger()\n",
    "log.setLevel('INFO')\n",
    "import sys\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s : %(message)s',\n",
    "                     level=logging.INFO, stream=sys.stdout)\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'png'\n",
    "matplotlib.rcParams['figure.figsize'] = (12.0, 1.0)\n",
    "matplotlib.rcParams['font.size'] = 14\n",
    "import seaborn\n",
    "seaborn.set_style('darkgrid')\n",
    "\n",
    "from reversible.sliced import sliced_from_samples\n",
    "\n",
    "from numpy.random import RandomState\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import copy\n",
    "import math\n",
    "\n",
    "import itertools\n",
    "from reversible.plot import create_bw_image\n",
    "import torch as th\n",
    "from braindecode.torch_ext.util import np_to_var, var_to_np\n",
    "from reversible.revnet import ResidualBlock, invert, SubsampleSplitter, ViewAs, ReversibleBlockOld\n",
    "from spectral_norm import spectral_norm\n",
    "from conv_spectral_norm import conv_spectral_norm\n",
    "\n",
    "def display_text(text, fontsize=18):\n",
    "    fig = plt.figure(figsize=(12,0.1))\n",
    "    plt.title(text, fontsize=fontsize)\n",
    "    plt.axis('off')\n",
    "    display(fig)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from braindecode.datasets.bbci import BBCIDataset\n",
    "from braindecode.mne_ext.signalproc import mne_apply\n",
    "from collections import OrderedDict\n",
    "from braindecode.datautil.trial_segment import create_signal_target_from_raw_mne\n",
    "\n",
    "def load_file(filename):\n",
    "    cnt = BBCIDataset(filename).load()\n",
    "    cnt = cnt.drop_channels(['STI 014'])\n",
    "    def car(a):\n",
    "        return a - np.mean(a, keepdims=True, axis=0)\n",
    "\n",
    "    cnt = mne_apply(\n",
    "        car, cnt)\n",
    "    return cnt\n",
    "\n",
    "\n",
    "def create_set(cnt):\n",
    "    marker_def = OrderedDict([('Right Hand', [1]), ('Left Hand', [2],),\n",
    "                             ('Rest', [3]), ('Feet', [4])])\n",
    "    ival = [500,1500]\n",
    "    from braindecode.mne_ext.signalproc import mne_apply, resample_cnt\n",
    "    from braindecode.datautil.signalproc import exponential_running_standardize, bandpass_cnt\n",
    "\n",
    "    log.info(\"Resampling train...\")\n",
    "    cnt = resample_cnt(cnt, 250.0)\n",
    "    log.info(\"Standardizing train...\")\n",
    "    cnt = mne_apply(lambda a: exponential_running_standardize(a.T ,factor_new=1e-3, init_block_size=1000, eps=1e-4).T,\n",
    "                         cnt)\n",
    "    cnt = resample_cnt(cnt, 32.0)\n",
    "    cnt = resample_cnt(cnt, 64.0)\n",
    "\n",
    "    dataset = create_signal_target_from_raw_mne(cnt, marker_def, ival)\n",
    "    return dataset\n",
    "def create_inputs(dataset):\n",
    "    x_right = dataset.X[dataset.y == 0]\n",
    "\n",
    "    x_rest = dataset.X[dataset.y == 2]\n",
    "\n",
    "    inputs_a = np_to_var(x_right[:,0:1,:,None], dtype=np.float32)\n",
    "\n",
    "    inputs_b = np_to_var(x_rest[:,0:1,:,None], dtype=np.float32)\n",
    "    inputs = [inputs_a, inputs_b]\n",
    "    return inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_cnt = load_file('/data/schirrmr/schirrmr/HGD-public/reduced/train/4.mat')\n",
    "train_cnt = train_cnt.reorder_channels(['C3', 'C4'])\n",
    "train_set = create_set(train_cnt)\n",
    "train_inputs = create_inputs(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_cnt = load_file('/data/schirrmr/schirrmr/HGD-public/reduced/test/4.mat')\n",
    "test_cnt = test_cnt.reorder_channels(['C3', 'C4'])\n",
    "test_set = create_set(test_cnt)\n",
    "test_inputs = create_inputs(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rev_block(n_c, n_i_c):\n",
    "     return ReversibleBlockOld(\n",
    "        nn.Sequential(\n",
    "        nn.Conv2d(n_c // 2, n_i_c,(3,1), stride=1, padding=(1,0),bias=True),\n",
    "        nn.ReLU(),\n",
    "            nn.Conv2d(n_i_c, n_c // 2,(3,1), stride=1, padding=(1,0),bias=True)),\n",
    "         \n",
    "        nn.Sequential(\n",
    "        nn.Conv2d(n_c // 2, n_i_c,(3,1), stride=1, padding=(1,0),bias=True),\n",
    "        nn.ReLU(),\n",
    "            nn.Conv2d(n_i_c, n_c // 2,(3,1), stride=1, padding=(1,0),bias=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from rfft import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from rfft import RFFT, Interleave\n",
    "from discriminator import ProjectionDiscriminator\n",
    "from reversible.revnet import SubsampleSplitter, ViewAs\n",
    "from reversible.util import set_random_seeds\n",
    "from reversible.revnet import init_model_params\n",
    "from torch.nn import ConstantPad2d\n",
    "import torch as th\n",
    "from conv_spectral_norm import conv_spectral_norm\n",
    "from disttransform import DistTransformResNet\n",
    "\n",
    "\n",
    "set_random_seeds(2019011641, True)\n",
    "feature_model_a = nn.Sequential(\n",
    "    SubsampleSplitter(stride=[2,1],chunk_chans_first=False),# 2 x 32\n",
    "    rev_block(2,32),\n",
    "    rev_block(2,32),\n",
    "    SubsampleSplitter(stride=[2,1],chunk_chans_first=True), # 4 x 16\n",
    "    rev_block(4,32),\n",
    "    rev_block(4,32),\n",
    "    SubsampleSplitter(stride=[2,1],chunk_chans_first=True), # 8 x 8\n",
    "    rev_block(8,32),\n",
    "    rev_block(8,32),\n",
    "    SubsampleSplitter(stride=[2,1],chunk_chans_first=True), # 16 x 4\n",
    "    rev_block(16,32),\n",
    "    rev_block(16,32),\n",
    "    SubsampleSplitter(stride=[2,1],chunk_chans_first=True), # 32 x 2\n",
    "    rev_block(32,32),\n",
    "    rev_block(32,32),\n",
    "    SubsampleSplitter(stride=[2,1],chunk_chans_first=True), # 64 x 1\n",
    "    rev_block(64,64),\n",
    "    rev_block(64,64),\n",
    "    rev_block(64,64),\n",
    "    rev_block(64,64),\n",
    "    ViewAs((-1,64,1, 1), (-1,64)),\n",
    "    RFFT(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = th.optim.Adam(feature_model_a.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 101\n",
    "for i_epoch in range(n_epochs):\n",
    "    outs_0  = feature_model_a(train_inputs[0])\n",
    "    outs_1  = feature_model_a(train_inputs[1])\n",
    "\n",
    "    preds_0 = F.log_softmax(outs_0[:,:2], dim=1)\n",
    "    preds_1 = F.log_softmax(outs_1[:,:2], dim=1)\n",
    "\n",
    "    labels_0 = th.zeros(len(preds_0), dtype=th.int64)\n",
    "    labels_1 = th.ones(len(preds_1), dtype=th.int64)\n",
    "\n",
    "    loss = F.nll_loss(preds_0, labels_0) + F.nll_loss(preds_1, labels_1)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i_epoch % (n_epochs // 20) == 0:\n",
    "        print(\"Epoch {:d} of {:d}\".format(i_epoch, n_epochs))\n",
    "        print(\"Loss: {:E}\".format(loss.item()))\n",
    "        for set_name, dataset in (('Train', train_inputs), ('Test', test_inputs)):\n",
    "            pred_labels_0 = np.argmax(var_to_np(feature_model_a(dataset[0])[:,:2]), axis=1)\n",
    "            pred_labels_1 = np.argmax(var_to_np(feature_model_a(dataset[1])[:,:2]), axis=1)\n",
    "            acc = np.mean(np.concatenate(((pred_labels_0 == 0), (pred_labels_1 == 1))))\n",
    "            print(\"{:s} Accuracy: {:.2f}%\".format(set_name, acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_class in range(2):\n",
    "    outs = feature_model_a(train_inputs[i_class])\n",
    "\n",
    "    _, i_sorted = th.sort(F.softmax(outs[:,:2], dim=1)[:,i_class])\n",
    "\n",
    "    sorted_ins = var_to_np(train_inputs[i_class].squeeze())[var_to_np(i_sorted)]\n",
    "\n",
    "    fig, axes = plt.subplots(8,3, figsize=(16,24), sharex=True, sharey=True)\n",
    "    for i_ax, ax in enumerate(axes.flatten()):\n",
    "        ax.plot(sorted_ins[i_ax * 9])\n",
    "    display(fig)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.mean(feature_model_a(test_inputs[0])[:,:2], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.mean(feature_model_a(test_inputs[1])[:,:2], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_inputs = train_inputs\n",
    "for i_class in range(2):\n",
    "    with th.no_grad():\n",
    "        outs = feature_model_a(set_inputs[i_class])\n",
    "        # only take those confidently correctly predicted\n",
    "        preds = F.softmax(outs[:,:2], dim=1)\n",
    "        mask = preds[:,i_class] > 0.9\n",
    "        outs = outs[mask]\n",
    "        ins = set_inputs[i_class][mask]\n",
    "        outs_other = feature_model_a(set_inputs[1-i_class])\n",
    "        preds_other = F.softmax(outs_other[:,:2], dim=1)\n",
    "        mask_other = preds_other[:,1-i_class] > 0.9\n",
    "        outs_other = outs_other[mask_other]\n",
    "        other_ins = set_inputs[1-i_class][mask_other]\n",
    "        n_min = min(len(outs_other), len(outs))\n",
    "        outs = outs[:n_min]\n",
    "        outs_other = outs_other[:n_min]\n",
    "        outs.data[:,:2] = outs_other[:,:2].data * 0.02 + outs.data[:,:2] * 0.98\n",
    "        inverted = invert(feature_model_a, outs, )\n",
    "        fig, axes = plt.subplots(3,3, figsize=(16,7), sharex=True, sharey=True)\n",
    "        for i_example in range(3):\n",
    "            axes[0][i_example].plot(var_to_np(ins[i_example].squeeze()))\n",
    "            axes[1][i_example].plot(var_to_np(inverted[i_example].squeeze()))\n",
    "            axes[2][i_example].plot(var_to_np(other_ins[i_example].squeeze()))\n",
    "        display(fig)\n",
    "        plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
