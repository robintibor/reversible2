{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import importlib\n",
    "importlib.reload(logging) # see https://stackoverflow.com/a/21475297/1469195\n",
    "log = logging.getLogger()\n",
    "log.setLevel('INFO')\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s : %(message)s',\n",
    "                     level=logging.INFO, stream=sys.stdout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import os\n",
    "import site\n",
    "os.sys.path.insert(0, '/home/schirrmr/code/reversible/')\n",
    "os.sys.path.insert(0, '/home/schirrmr/braindecode/code/braindecode/')\n",
    "os.sys.path.insert(0, '/home/schirrmr/code/explaining/reversible//')\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import logging\n",
    "log = logging.getLogger()\n",
    "log.setLevel('INFO')\n",
    "import sys\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s : %(message)s',\n",
    "                     level=logging.INFO, stream=sys.stdout)\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'png'\n",
    "matplotlib.rcParams['figure.figsize'] = (12.0, 1.0)\n",
    "matplotlib.rcParams['font.size'] = 14\n",
    "import seaborn\n",
    "seaborn.set_style('darkgrid')\n",
    "\n",
    "from reversible2.sliced import sliced_from_samples\n",
    "from numpy.random import RandomState\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import copy\n",
    "import math\n",
    "\n",
    "import itertools\n",
    "import torch as th\n",
    "from braindecode.torch_ext.util import np_to_var, var_to_np\n",
    "from reversible2.splitter import SubsampleSplitter\n",
    "\n",
    "from reversible2.view_as import ViewAs\n",
    "\n",
    "from reversible2.affine import AdditiveBlock\n",
    "from reversible2.plot import display_text, display_close\n",
    "from reversible2.bhno import load_file, create_inputs\n",
    "th.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ipyexperiments import IPyExperimentsPytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp1 = IPyExperimentsPytorch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reversible2.util import set_random_seeds\n",
    "from reversible2.affine import AdditiveBlock\n",
    "\n",
    "a = th.linspace(0,2000,1000).unsqueeze(0).repeat(1000,1).cuda()\n",
    "\n",
    "def additive_dense_block():\n",
    "    # Reversible Block for 1x20 input\n",
    "    return nn.Sequential(nn.Linear(500,1000, bias=False),\n",
    "                        nn.ReLU(),\n",
    "                         nn.Linear(1000,500, bias=False),)\n",
    "\n",
    "\n",
    "set_random_seeds(394834, False)\n",
    "b1a = additive_dense_block()\n",
    "b1b = additive_dense_block()\n",
    "b2a = additive_dense_block()\n",
    "b2b = additive_dense_block()\n",
    "b3a = additive_dense_block()\n",
    "b3b = additive_dense_block()\n",
    "b4a = additive_dense_block()\n",
    "b4b = additive_dense_block()\n",
    "\n",
    "net = nn.Sequential(\n",
    "    AdditiveBlock(b1a,b1b, switched_order=False),\n",
    "    AdditiveBlock(b2a,b2b, switched_order=False),\n",
    "    AdditiveBlock(b3a,b3b, switched_order=False),\n",
    "    AdditiveBlock(b4a,b4b, switched_order=False),)\n",
    "\n",
    "net = net.cuda()\n",
    "out = net(a)\n",
    "\n",
    "loss = out.sum()\n",
    "#loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del exp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp1 = IPyExperimentsPytorch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reversible2.util import set_random_seeds\n",
    "from reversible2.newadditive import AdditiveBlock as AdditiveBlockNew\n",
    "\n",
    "a = th.linspace(0,2000,1000).unsqueeze(0).repeat(1000,1).cuda()\n",
    "\n",
    "def additive_dense_block():\n",
    "    # Reversible Block for 1x20 input\n",
    "    return nn.Sequential(nn.Linear(500,1000, bias=False),\n",
    "                        nn.ReLU(),\n",
    "                         nn.Linear(1000,500, bias=False),)\n",
    "\n",
    "\n",
    "set_random_seeds(394834, False)\n",
    "b1a = additive_dense_block()\n",
    "b1b = additive_dense_block()\n",
    "b2a = additive_dense_block()\n",
    "b2b = additive_dense_block()\n",
    "b3a = additive_dense_block()\n",
    "b3b = additive_dense_block()\n",
    "b4a = additive_dense_block()\n",
    "b4b = additive_dense_block()\n",
    "\n",
    "net = nn.Sequential(\n",
    "    AdditiveBlockNew(b1a,b1b, keep_input=True),\n",
    "    AdditiveBlockNew(b2a,b2b),\n",
    "    AdditiveBlockNew(b3a,b3b),\n",
    "    AdditiveBlockNew(b4a,b4b, final_block=True),)\n",
    "net.cuda()\n",
    "for _ in range(5):\n",
    "    #with th.no_grad():\n",
    "        out = net(a)\n",
    "\n",
    "        loss = out.sum()\n",
    "        #loss.backward()\n",
    "        for m in net.modules():\n",
    "            if hasattr(m, 'ctx_dict'):\n",
    "                m.ctx_dict.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del exp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp1 = IPyExperimentsPytorch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reversible2.util import set_random_seeds\n",
    "from reversible2.newadditive import AdditiveBlock as AdditiveBlockNew\n",
    "\n",
    "a = th.linspace(0,2000,1000).unsqueeze(0).repeat(1000,1).cuda()\n",
    "\n",
    "def additive_dense_block():\n",
    "    # Reversible Block for 1x20 input\n",
    "    return nn.Sequential(nn.Linear(500,1000, bias=False),\n",
    "                        nn.ReLU(),\n",
    "                         nn.Linear(1000,500, bias=False),)\n",
    "\n",
    "\n",
    "set_random_seeds(394834, False)\n",
    "b1a = additive_dense_block()\n",
    "b1b = additive_dense_block()\n",
    "b2a = additive_dense_block()\n",
    "b2b = additive_dense_block()\n",
    "b3a = additive_dense_block()\n",
    "b3b = additive_dense_block()\n",
    "b4a = additive_dense_block()\n",
    "b4b = additive_dense_block()\n",
    "b5a = additive_dense_block()\n",
    "b5b = additive_dense_block()\n",
    "b6a = additive_dense_block()\n",
    "b6b = additive_dense_block()\n",
    "b7a = additive_dense_block()\n",
    "b7b = additive_dense_block()\n",
    "b8a = additive_dense_block()\n",
    "b8b = additive_dense_block()\n",
    "\n",
    "net = nn.Sequential(\n",
    "    AdditiveBlockNew(b1a,b1b, keep_input=True),\n",
    "    AdditiveBlockNew(b2a,b2b),\n",
    "    AdditiveBlockNew(b3a,b3b),\n",
    "    AdditiveBlockNew(b4a,b4b),\n",
    "    AdditiveBlockNew(b5a,b5b),\n",
    "    AdditiveBlockNew(b6a,b6b),\n",
    "    AdditiveBlockNew(b7a,b7b),\n",
    "    AdditiveBlockNew(b8a,b8b, final_block=True),)\n",
    "net = net.cuda()\n",
    "for _ in range(5):\n",
    "    #with th.no_grad():\n",
    "        out = net(a)\n",
    "\n",
    "        loss = out.sum()\n",
    "        #loss.backward()\n",
    "        for m in net.modules():\n",
    "            if hasattr(m, 'ctx_dict'):\n",
    "                m.ctx_dict.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del exp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp1 = IPyExperimentsPytorch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reversible2.util import set_random_seeds\n",
    "from reversible2.affine import AdditiveBlock\n",
    "\n",
    "a = th.linspace(0,2000,1000).unsqueeze(0).repeat(1000,1).cuda()\n",
    "\n",
    "def additive_dense_block():\n",
    "    # Reversible Block for 1x20 input\n",
    "    return nn.Sequential(nn.Linear(500,1000, bias=False),\n",
    "                        nn.ReLU(),\n",
    "                         nn.Linear(1000,500, bias=False),)\n",
    "\n",
    "\n",
    "set_random_seeds(394834, False)\n",
    "\n",
    "modules = [AdditiveBlock(additive_dense_block(),additive_dense_block(), switched_order=False),]\n",
    "\n",
    "for _ in range(300):\n",
    "    modules.append(AdditiveBlock(additive_dense_block(),additive_dense_block(), switched_order=False))\n",
    "\n",
    "modules.append(AdditiveBlock(additive_dense_block(),additive_dense_block(), switched_order=False))\n",
    "net = nn.Sequential(*modules)\n",
    "net = net.cuda()\n",
    "for i_iter in range(5):\n",
    "    print(\"i_iter\", i_iter)\n",
    "    out = net(a)\n",
    "\n",
    "    loss = out.sum()\n",
    "    #loss.backward()\n",
    "    for m in net.modules():\n",
    "        if hasattr(m, 'ctx_dict'):\n",
    "            m.ctx_dict.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del exp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp1 = IPyExperimentsPytorch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(((1000*1000+1000*2000+1000*2000+1000*1000) * 4) * 200) / (1024 ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(((1000*1000+1000*2000+1000*2000+1000*1000) * 4) * 300) / (1024 ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reversible2.util import set_random_seeds\n",
    "from reversible2.newadditive import AdditiveBlock as AdditiveBlockNew\n",
    "\n",
    "a = th.linspace(0,2000,1000).unsqueeze(0).repeat(1000,1).cuda()\n",
    "\n",
    "def additive_dense_block():\n",
    "    # Reversible Block for 1x20 input\n",
    "    return nn.Sequential(nn.Linear(500,1000, bias=False),\n",
    "                        nn.ReLU(),\n",
    "                         nn.Linear(1000,500, bias=False),)\n",
    "\n",
    "\n",
    "set_random_seeds(394834, False)\n",
    "\n",
    "modules = [AdditiveBlockNew(additive_dense_block(),additive_dense_block(), keep_input=True),]\n",
    "\n",
    "for _ in range(300):\n",
    "    modules.append(AdditiveBlockNew(additive_dense_block(),additive_dense_block()))\n",
    "\n",
    "modules.append(AdditiveBlockNew(additive_dense_block(),additive_dense_block(), final_block=True))\n",
    "net = nn.Sequential(*modules)\n",
    "net = net.cuda()\n",
    "for i_iter in range(5):\n",
    "    print(\"i_iter\", i_iter)\n",
    "    out = net(a)\n",
    "\n",
    "    loss = out.sum()\n",
    "    #loss.backward()\n",
    "    for m in net.modules():\n",
    "        if hasattr(m, 'ctx_dict'):\n",
    "            m.ctx_dict.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del exp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Wrapper: take class, on forward, make forward as before, \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
