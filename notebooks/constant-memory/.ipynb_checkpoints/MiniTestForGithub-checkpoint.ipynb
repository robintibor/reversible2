{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import importlib\n",
    "importlib.reload(logging) # see https://stackoverflow.com/a/21475297/1469195\n",
    "log = logging.getLogger()\n",
    "log.setLevel('INFO')\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s : %(message)s',\n",
    "                     level=logging.INFO, stream=sys.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.sys.path.insert(0, '/home/schirrmr/code/memcnn/')\n",
    "\n",
    "import unittest\n",
    "import torch\n",
    "import torch.nn\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import memcnn.models.revop as revop\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parts of original test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dims = (2, 10, 8, 8)\n",
    "data = np.random.random(dims).astype(np.float32)\n",
    "target_data = np.random.random(dims).astype(np.float32)\n",
    "\n",
    "class SubModule(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SubModule, self).__init__()\n",
    "        self.bn = torch.nn.BatchNorm2d(10 // 2)\n",
    "        self.conv = torch.nn.Conv2d(10 // 2, 10 // 2, (3, 3), padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.bn(self.conv(x))\n",
    "\n",
    "Gm = SubModule()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruction of X fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bwd = False\n",
    "coupling = 'additive'\n",
    "keep_input = False\n",
    "implementation_fwd = 0\n",
    "implementation_bwd = 0\n",
    "\n",
    "this_iter_keep_input = keep_input or (implementation_bwd == -1)\n",
    "\n",
    "X = Variable(torch.from_numpy(data.copy())).clone()\n",
    "Ytarget = Variable(torch.from_numpy(target_data.copy())).clone()\n",
    "Xshape = X.shape\n",
    "Gm2 = copy.deepcopy(Gm)\n",
    "rb = revop.ReversibleBlock(Gm2, coupling=coupling, implementation_fwd=implementation_fwd,\n",
    "                           implementation_bwd=implementation_bwd, keep_input=this_iter_keep_input)\n",
    "rb.train()\n",
    "rb.zero_grad()\n",
    "\n",
    "optim = torch.optim.RMSprop(rb.parameters())\n",
    "optim.zero_grad()\n",
    "if not bwd:\n",
    "    Y = rb(X)\n",
    "    Yrev = Y.clone()\n",
    "    Xinv = rb.inverse(Yrev)\n",
    "loss = torch.nn.MSELoss()(Y, Ytarget)\n",
    "\n",
    "if this_iter_keep_input:\n",
    "    self.assertTrue(X.data.shape == Xshape)\n",
    "    self.assertTrue(Y.data.shape == Yrev.shape)\n",
    "else:\n",
    "    try:\n",
    "        assert (len(X.data.shape) == 0 or (len(X.data.shape) == 1 and X.data.shape[0] == 0))\n",
    "        assert (len(Yrev.data.shape) == 0 or (len(Yrev.data.shape) == 1\n",
    "                                              and Yrev.data.shape[0] == 0))\n",
    "    except AssertionError:\n",
    "        print(\"Test would have failed\")\n",
    "        \n",
    "\n",
    "optim.zero_grad()\n",
    "loss.backward()\n",
    "optim.step()\n",
    "\n",
    "    \n",
    "assert (Y.shape == Xshape)\n",
    "assert (X.data.numpy().shape == data.shape)\n",
    "np.testing.assert_allclose(X.data.numpy(), data, atol=1e-06)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking 2 rev blocks will lead to wrong gradients as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DoubleBlocks(nn.Module):\n",
    "    def __init__(self, revblock):\n",
    "        super(DoubleBlocks, self).__init__()\n",
    "        self.revblock1 = revblock\n",
    "        self.revblock2 = copy.deepcopy(revblock)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.revblock2(self.revblock1(x))\n",
    "    \n",
    "    def inverse(self, y):\n",
    "        return self.revblock1(self.revblock2(y))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect correct gradients with naive implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bwd = False\n",
    "coupling = 'additive'\n",
    "keep_input = False\n",
    "implementation_fwd = -1\n",
    "implementation_bwd = -1\n",
    "\n",
    "this_iter_keep_input = keep_input or (implementation_bwd == -1)\n",
    "\n",
    "X = Variable(torch.from_numpy(data.copy())).clone()\n",
    "Ytarget = Variable(torch.from_numpy(target_data.copy())).clone()\n",
    "Xshape = X.shape\n",
    "Gm2 = copy.deepcopy(Gm)\n",
    "rb = revop.ReversibleBlock(Gm2, coupling=coupling, implementation_fwd=implementation_fwd,\n",
    "                           implementation_bwd=implementation_bwd, keep_input=this_iter_keep_input)\n",
    "rb = DoubleBlocks(rb)\n",
    "rb.train()\n",
    "rb.zero_grad()\n",
    "\n",
    "optim = torch.optim.RMSprop(rb.parameters())\n",
    "optim.zero_grad()\n",
    "if not bwd:\n",
    "    Y = rb(X)\n",
    "    Yrev = Y.clone()\n",
    "    Xinv = rb.inverse(Yrev)\n",
    "loss = torch.nn.MSELoss()(Y, Ytarget)\n",
    "\n",
    "if this_iter_keep_input:\n",
    "    assert (X.data.shape == Xshape)\n",
    "    assert (Y.data.shape == Yrev.shape)\n",
    "else:\n",
    "    try:\n",
    "        assert (len(X.data.shape) == 0 or (len(X.data.shape) == 1 and X.data.shape[0] == 0))\n",
    "        assert (len(Yrev.data.shape) == 0 or (len(Yrev.data.shape) == 1\n",
    "                                              and Yrev.data.shape[0] == 0))\n",
    "    except AssertionError:\n",
    "        print(\"Test would have failed\")\n",
    "        \n",
    "\n",
    "optim.zero_grad()\n",
    "loss.backward()\n",
    "optim.step()\n",
    "\n",
    "    \n",
    "assert (Y.shape == Xshape)\n",
    "assert (X.data.numpy().shape == data.shape)\n",
    "np.testing.assert_allclose(X.data.numpy(), data, atol=1e-06)\n",
    "\n",
    "correct_grads = [copy.deepcopy(p.grad.numpy()) for p in rb.parameters()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fails with keep_input=False and imp=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bwd = False\n",
    "coupling = 'additive'\n",
    "keep_input = False\n",
    "implementation_fwd = 0\n",
    "implementation_bwd = 0\n",
    "\n",
    "this_iter_keep_input = keep_input or (implementation_bwd == -1)\n",
    "\n",
    "X = Variable(torch.from_numpy(data.copy())).clone()\n",
    "Ytarget = Variable(torch.from_numpy(target_data.copy())).clone()\n",
    "Xshape = X.shape\n",
    "Gm2 = copy.deepcopy(Gm)\n",
    "rb = revop.ReversibleBlock(Gm2, coupling=coupling, implementation_fwd=implementation_fwd,\n",
    "                           implementation_bwd=implementation_bwd, keep_input=this_iter_keep_input)\n",
    "rb = DoubleBlocks(rb)\n",
    "rb.train()\n",
    "rb.zero_grad()\n",
    "\n",
    "optim = torch.optim.RMSprop(rb.parameters())\n",
    "optim.zero_grad()\n",
    "if not bwd:\n",
    "    Y = rb(X)\n",
    "    Yrev = Y.clone()\n",
    "    Xinv = rb.inverse(Yrev)\n",
    "loss = torch.nn.MSELoss()(Y, Ytarget)\n",
    "\n",
    "if this_iter_keep_input:\n",
    "    assert (X.data.shape == Xshape)\n",
    "    assert (Y.data.shape == Yrev.shape)\n",
    "else:\n",
    "    try:\n",
    "        assert (len(X.data.shape) == 0 or (len(X.data.shape) == 1 and X.data.shape[0] == 0))\n",
    "        assert (len(Yrev.data.shape) == 0 or (len(Yrev.data.shape) == 1\n",
    "                                              and Yrev.data.shape[0] == 0))\n",
    "    except AssertionError:\n",
    "        print(\"Test would have failed\")\n",
    "        \n",
    "\n",
    "optim.zero_grad()\n",
    "loss.backward()\n",
    "optim.step()\n",
    "\n",
    "    \n",
    "assert (Y.shape == Xshape)\n",
    "assert (X.data.numpy().shape == data.shape)\n",
    "#np.testing.assert_allclose(X.data.numpy(), data, atol=1e-06)\n",
    "cur_grads = [copy.deepcopy(p.grad.numpy()) for p in rb.parameters()]\n",
    "for g1, g2 in zip(correct_grads, cur_grads):\n",
    "    np.testing.assert_allclose(g1, g2, atol=1e-06)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Everything fine with keep_input=True and imp=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bwd = False\n",
    "coupling = 'additive'\n",
    "keep_input = True\n",
    "implementation_fwd = 0\n",
    "implementation_bwd = 0\n",
    "\n",
    "this_iter_keep_input = keep_input or (implementation_bwd == -1)\n",
    "\n",
    "X = Variable(torch.from_numpy(data.copy())).clone()\n",
    "Ytarget = Variable(torch.from_numpy(target_data.copy())).clone()\n",
    "Xshape = X.shape\n",
    "Gm2 = copy.deepcopy(Gm)\n",
    "rb = revop.ReversibleBlock(Gm2, coupling=coupling, implementation_fwd=implementation_fwd,\n",
    "                           implementation_bwd=implementation_bwd, keep_input=this_iter_keep_input)\n",
    "rb = DoubleBlocks(rb)\n",
    "rb.train()\n",
    "rb.zero_grad()\n",
    "\n",
    "optim = torch.optim.RMSprop(rb.parameters())\n",
    "optim.zero_grad()\n",
    "if not bwd:\n",
    "    Y = rb(X)\n",
    "    Yrev = Y.clone()\n",
    "    Xinv = rb.inverse(Yrev)\n",
    "loss = torch.nn.MSELoss()(Y, Ytarget)\n",
    "\n",
    "if this_iter_keep_input:\n",
    "    assert (X.data.shape == Xshape)\n",
    "    assert (Y.data.shape == Yrev.shape)\n",
    "else:\n",
    "    try:\n",
    "        assert (len(X.data.shape) == 0 or (len(X.data.shape) == 1 and X.data.shape[0] == 0))\n",
    "        assert (len(Yrev.data.shape) == 0 or (len(Yrev.data.shape) == 1\n",
    "                                              and Yrev.data.shape[0] == 0))\n",
    "    except AssertionError:\n",
    "        print(\"Test would have failed\")\n",
    "        \n",
    "\n",
    "optim.zero_grad()\n",
    "loss.backward()\n",
    "optim.step()\n",
    "\n",
    "    \n",
    "assert (Y.shape == Xshape)\n",
    "assert (X.data.numpy().shape == data.shape)\n",
    "#np.testing.assert_allclose(X.data.numpy(), data, atol=1e-06)\n",
    "cur_grads = [copy.deepcopy(p.grad.numpy()) for p in rb.parameters()]\n",
    "for g1, g2 in zip(correct_grads, cur_grads):\n",
    "    np.testing.assert_allclose(g1, g2, atol=1e-06)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
