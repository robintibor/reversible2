{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import importlib\n",
    "importlib.reload(logging) # see https://stackoverflow.com/a/21475297/1469195\n",
    "log = logging.getLogger()\n",
    "log.setLevel('INFO')\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s : %(message)s',\n",
    "                     level=logging.INFO, stream=sys.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import os\n",
    "import site\n",
    "os.sys.path.insert(0, '/home/schirrmr/code/reversible/')\n",
    "os.sys.path.insert(0, '/home/schirrmr/braindecode/code/braindecode/')\n",
    "os.sys.path.insert(0, '/home/schirrmr/code/explaining/reversible//')\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import logging\n",
    "log = logging.getLogger()\n",
    "log.setLevel('INFO')\n",
    "import sys\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s : %(message)s',\n",
    "                     level=logging.INFO, stream=sys.stdout)\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'png'\n",
    "matplotlib.rcParams['figure.figsize'] = (12.0, 1.0)\n",
    "matplotlib.rcParams['font.size'] = 14\n",
    "import seaborn\n",
    "seaborn.set_style('darkgrid')\n",
    "\n",
    "from reversible2.sliced import sliced_from_samples\n",
    "from numpy.random import RandomState\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import copy\n",
    "import math\n",
    "\n",
    "import itertools\n",
    "import torch as th\n",
    "from braindecode.torch_ext.util import np_to_var, var_to_np\n",
    "from reversible2.splitter import SubsampleSplitter\n",
    "\n",
    "from reversible2.view_as import ViewAs\n",
    "\n",
    "from reversible2.affine import AdditiveBlock\n",
    "from reversible2.plot import display_text, display_close\n",
    "from reversible2.bhno import load_file, create_inputs\n",
    "th.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sensor_names = ['Fz', \n",
    "                'FC3','FC1','FCz','FC2','FC4',\n",
    "                'C5','C3','C1','Cz','C2','C4','C6',\n",
    "                'CP3','CP1','CPz','CP2','CP4',\n",
    "                'P1','Pz','P2',\n",
    "                'POz']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_train_cnt = load_file('/data/schirrmr/schirrmr/HGD-public/reduced/train/4.mat')\n",
    "train_cnt = orig_train_cnt.reorder_channels(sensor_names)\n",
    "\n",
    "train_inputs = create_inputs(train_cnt, final_hz=256, half_before=True)\n",
    "n_split = len(train_inputs[0]) - 40\n",
    "test_inputs = [t[-40:] for t in train_inputs]\n",
    "train_inputs = [t[:-40] for t in train_inputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cuda = True\n",
    "if cuda:\n",
    "    train_inputs = [i.cuda() for i in train_inputs]\n",
    "    test_inputs = [i.cuda() for i in test_inputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from reversible2.graph import Node\n",
    "from reversible2.branching import CatChans, ChunkChans, Select\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def invert(feature_model, out):\n",
    "    return feature_model.invert(out)\n",
    "\n",
    "from copy import deepcopy\n",
    "from reversible2.graph import Node\n",
    "from reversible2.distribution import TwoClassDist\n",
    "from reversible2.wrap_invertible import WrapInvertible\n",
    "from reversible2.blocks import dense_add_const, conv_add_3x3_const\n",
    "from reversible2.rfft import RFFT, Interleave\n",
    "from reversible2.util import set_random_seeds\n",
    "from torch.nn import ConstantPad2d\n",
    "import torch as th\n",
    "from reversible2.splitter import SubsampleSplitter\n",
    "\n",
    "set_random_seeds(2019011641, cuda)\n",
    "n_chans = train_inputs[0].shape[1]\n",
    "n_time = train_inputs[0].shape[2]\n",
    "base_model = nn.Sequential(\n",
    "    WrapInvertible(SubsampleSplitter(stride=[2,1],chunk_chans_first=False),\n",
    "                   grad_is_inverse=True, keep_input=True),# 2 x 256\n",
    "    conv_add_3x3_const(2*n_chans,32),\n",
    "    conv_add_3x3_const(2*n_chans,32),\n",
    "    WrapInvertible(SubsampleSplitter(stride=[2,1],chunk_chans_first=True), grad_is_inverse=True), # 4 x 128\n",
    "    conv_add_3x3_const(4*n_chans,32),\n",
    "    conv_add_3x3_const(4*n_chans,32),\n",
    "    WrapInvertible(SubsampleSplitter(stride=[2,1],chunk_chans_first=True), grad_is_inverse=True), # 8 x 64\n",
    "    conv_add_3x3_const(8*n_chans,32),\n",
    "    conv_add_3x3_const(8*n_chans,32, final_block=True))\n",
    "base_model.cuda();\n",
    "\n",
    "branch_1_a =  nn.Sequential(\n",
    "    WrapInvertible(SubsampleSplitter(stride=[2,1],chunk_chans_first=False), \n",
    "                   grad_is_inverse=True, keep_input=True), # 8 x 32\n",
    "    conv_add_3x3_const(8*n_chans,32),\n",
    "    conv_add_3x3_const(8*n_chans,32),\n",
    "    WrapInvertible(SubsampleSplitter(stride=[2,1],chunk_chans_first=True),\n",
    "                   grad_is_inverse=True),# 16 x 16\n",
    "    conv_add_3x3_const(16*n_chans,32),\n",
    "    conv_add_3x3_const(16*n_chans,32),\n",
    "    WrapInvertible(SubsampleSplitter(stride=[2,1],chunk_chans_first=True),\n",
    "                   grad_is_inverse=True), # 32 x 8\n",
    "    conv_add_3x3_const(32*n_chans,32),\n",
    "    conv_add_3x3_const(32*n_chans,32, final_block=True),\n",
    ")\n",
    "branch_1_b = nn.Sequential(\n",
    "    *(list(deepcopy(branch_1_a).children()) + [\n",
    "    WrapInvertible(ViewAs((-1, 32*n_chans,n_time//64,1), (-1,(n_time // 2)*n_chans)),\n",
    "                   grad_is_inverse=True, keep_input=True),\n",
    "    dense_add_const((n_time // 2)*n_chans,32),\n",
    "    dense_add_const((n_time // 2)*n_chans,32),\n",
    "    dense_add_const((n_time // 2)*n_chans,32),\n",
    "    dense_add_const((n_time // 2)*n_chans,32, final_block=True),\n",
    "]))\n",
    "branch_1_a.cuda();\n",
    "branch_1_b.cuda();\n",
    "\n",
    "branch_2_a = nn.Sequential(\n",
    "    WrapInvertible(SubsampleSplitter(stride=[2,1], chunk_chans_first=False),\n",
    "                   keep_input=True, grad_is_inverse=True),# 32 x 4\n",
    "    conv_add_3x3_const(32*n_chans,32),\n",
    "    conv_add_3x3_const(32*n_chans,32),\n",
    "    WrapInvertible(SubsampleSplitter(stride=[2,1],chunk_chans_first=True),\n",
    "                   grad_is_inverse=True),# 64 x 2\n",
    "    conv_add_3x3_const(64*n_chans,32),\n",
    "    conv_add_3x3_const(64*n_chans,32),\n",
    "    WrapInvertible(ViewAs((-1, (n_time // 4)*n_chans,1,1), (-1,(n_time // 4)*n_chans)),\n",
    "                   grad_is_inverse=True),\n",
    "    dense_add_const((n_time // 4)*n_chans,64),\n",
    "    dense_add_const((n_time // 4)*n_chans,64),\n",
    "    dense_add_const((n_time // 4)*n_chans,64),\n",
    "    dense_add_const((n_time // 4)*n_chans,64, final_block=True),\n",
    ")\n",
    "\n",
    "\n",
    "branch_2_b = deepcopy(branch_2_a).cuda()\n",
    "branch_2_a.cuda();\n",
    "branch_2_b.cuda();\n",
    "\n",
    "final_model = nn.Sequential(\n",
    "    dense_add_const(n_time*n_chans,256,keep_input=True),\n",
    "    dense_add_const(n_time*n_chans,256),\n",
    "    dense_add_const(n_time*n_chans,256),\n",
    "    dense_add_const(n_time*n_chans,256),\n",
    "    WrapInvertible(RFFT(), final_block=True),\n",
    ")\n",
    "final_model.cuda();\n",
    "o = Node(None, base_model)\n",
    "o = Node(o, ChunkChans(2))\n",
    "o1a = Node(o, Select(0))\n",
    "o1b = Node(o, Select(1))\n",
    "o1a = Node(o1a, branch_1_a)\n",
    "o1b = Node(o1b, branch_1_b)\n",
    "o2 = Node(o1a, ChunkChans(2))\n",
    "o2a = Node(o2, Select(0))\n",
    "o2b = Node(o2, Select(1))\n",
    "o2a = Node(o2a, branch_2_a)\n",
    "o2b = Node(o2b, branch_2_b)\n",
    "o = Node([o1b,o2a,o2b], CatChans())\n",
    "o = Node(o, final_model)\n",
    "feature_model = o\n",
    "if cuda:\n",
    "    feature_model.cuda()\n",
    "feature_model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from reversible2.constantmemory import clear_ctx_dicts\n",
    "\n",
    "# Check that forward + inverse is really identical\n",
    "t_out = feature_model(train_inputs[0][:2])\n",
    "inverted = invert(feature_model, t_out)\n",
    "clear_ctx_dicts(feature_model)\n",
    "assert th.allclose(train_inputs[0][:2], inverted, rtol=1e-3,atol=1e-4)\n",
    "device = list(feature_model.parameters())[0].device\n",
    "from reversible2.ot_exact import ot_euclidean_loss_for_samples\n",
    "class_dist = TwoClassDist(2, np.prod(train_inputs[0].size()[1:]) - 2)\n",
    "class_dist.cuda()\n",
    "optim_model = th.optim.Adam(feature_model.parameters())\n",
    "optim_dist = th.optim.Adam(class_dist.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile plot.py\n",
    "import torch as th\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from reversible2.util import var_to_np\n",
    "from reversible2.plot import display_close\n",
    "from matplotlib.patches import Ellipse\n",
    "import seaborn\n",
    "\n",
    "def plot_outs(feature_model, train_inputs, test_inputs, class_dist):\n",
    "    with th.no_grad():\n",
    "        # Compute dist for mean/std of encodings\n",
    "        data_cls_dists = []\n",
    "        for i_class in range(len(train_inputs)):\n",
    "            this_class_outs = feature_model(train_inputs[i_class])[:,:2]\n",
    "            data_cls_dists.append(\n",
    "                th.distributions.MultivariateNormal(th.mean(this_class_outs, dim=0),\n",
    "                covariance_matrix=th.diag(th.std(this_class_outs, dim=0) ** 2)))\n",
    "        for setname, set_inputs in ((\"Train\", train_inputs), (\"Test\", test_inputs)):\n",
    "\n",
    "            outs = [feature_model(ins) for ins in set_inputs]\n",
    "            c_outs = [o[:,:2] for o in outs]\n",
    "\n",
    "            c_outs_all = th.cat(c_outs)\n",
    "\n",
    "            cls_dists = []\n",
    "            for i_class in range(len(c_outs)):\n",
    "                mean, std = class_dist.get_mean_std(i_class)\n",
    "                cls_dists.append(\n",
    "                    th.distributions.MultivariateNormal(mean[:2],covariance_matrix=th.diag(std[:2] ** 2)))\n",
    "\n",
    "            preds_per_class = [th.stack([cls_dists[i_cls].log_prob(c_out)\n",
    "                             for i_cls in range(len(cls_dists))],\n",
    "                            dim=-1) for c_out in c_outs]\n",
    "\n",
    "            pred_labels_per_class = [np.argmax(var_to_np(preds), axis=1)\n",
    "                           for preds in preds_per_class]\n",
    "\n",
    "            labels = np.concatenate([np.ones(len(set_inputs[i_cls])) * i_cls \n",
    "             for i_cls in range(len(train_inputs))])\n",
    "\n",
    "            acc = np.mean(labels == np.concatenate(pred_labels_per_class))\n",
    "\n",
    "            data_preds_per_class = [th.stack([data_cls_dists[i_cls].log_prob(c_out)\n",
    "                             for i_cls in range(len(cls_dists))],\n",
    "                            dim=-1) for c_out in c_outs]\n",
    "            data_pred_labels_per_class = [np.argmax(var_to_np(data_preds), axis=1)\n",
    "                                for data_preds in data_preds_per_class]\n",
    "            data_acc = np.mean(labels == np.concatenate(data_pred_labels_per_class))\n",
    "\n",
    "            print(\"{:s} Accuracy: {:.1f}%\".format(setname, acc * 100))\n",
    "            fig = plt.figure(figsize=(5,5))\n",
    "            ax = plt.gca()\n",
    "            for i_class in range(len(c_outs)):\n",
    "                #if i_class == 0:\n",
    "                #    continue\n",
    "                o = var_to_np(c_outs[i_class]).squeeze()\n",
    "                incorrect_pred_mask = pred_labels_per_class[i_class] != i_class\n",
    "                plt.scatter(o[:,0], o[:,1], s=20, alpha=0.75, label=[\"Right\", \"Rest\"][i_class])\n",
    "                assert len(incorrect_pred_mask) == len(o)\n",
    "                plt.scatter(o[incorrect_pred_mask,0], o[incorrect_pred_mask,1], marker='x', color='black',\n",
    "                           alpha=1, s=5)\n",
    "                means, stds = class_dist.get_mean_std(i_class)\n",
    "                means = var_to_np(means)[:2]\n",
    "                stds = var_to_np(stds)[:2]\n",
    "                for sigma in [0.5,1,2,3]:\n",
    "                    ellipse = Ellipse(means, stds[0]*sigma, stds[1]*sigma)\n",
    "                    ax.add_artist(ellipse)\n",
    "                    ellipse.set_edgecolor(seaborn.color_palette()[i_class])\n",
    "                    ellipse.set_facecolor(\"None\")\n",
    "            for i_class in range(len(c_outs)):\n",
    "                o = var_to_np(c_outs[i_class]).squeeze()\n",
    "                plt.scatter(np.mean(o[:,0]), np.mean(o[:,1]),\n",
    "                           color=seaborn.color_palette()[i_class+2], s=80, marker=\"^\",\n",
    "                           label=[\"Right Mean\", \"Rest Mean\"][i_class])\n",
    "\n",
    "            plt.title(\"{:6s} Accuracy:        {:.1f}%\\n\"\n",
    "                      \"From data mean/std: {:.1f}%\".format(setname, acc * 100, data_acc * 100))\n",
    "            plt.legend(bbox_to_anchor=(1,1,0,0))\n",
    "            display_close(fig)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reversible2.constantmemory import clear_ctx_dicts\n",
    "from reversible2.timer import Timer\n",
    "from plot import plot_outs\n",
    "\n",
    "i_start_epoch_out = 401\n",
    "n_epochs = 1001\n",
    "for i_epoch in range(n_epochs):\n",
    "    with Timer(name='EpochLoop', verbose=False) as loop_time:\n",
    "        optim_model.zero_grad()\n",
    "        optim_dist.zero_grad()\n",
    "        for i_class in range(len(train_inputs)):\n",
    "            class_ins = train_inputs[i_class]\n",
    "            samples = class_dist.get_samples(i_class, len(train_inputs[i_class]) * 2)\n",
    "            inverted = feature_model.invert(samples)\n",
    "            ot_loss_in = ot_euclidean_loss_for_samples(class_ins.view(class_ins.shape[0], -1),\n",
    "                                                       inverted.view(inverted.shape[0], -1))\n",
    "            del inverted\n",
    "            outs = feature_model(class_ins)\n",
    "            if i_epoch < i_start_epoch_out:\n",
    "                ot_loss_out = th.zeros(1, device=class_ins.device)\n",
    "            else:\n",
    "                ot_loss_out = ot_euclidean_loss_for_samples(outs[:,:2].squeeze(), samples[:,:2].squeeze())\n",
    "            del samples\n",
    "                \n",
    "            other_class_ins = train_inputs[1-i_class]\n",
    "            changed_to_other_class = class_dist.change_to_other_class(outs, i_class_from=i_class, i_class_to=1-i_class)\n",
    "            other_inverted = feature_model.invert(changed_to_other_class)\n",
    "            ot_transformed_in = ot_euclidean_loss_for_samples(other_class_ins.view(other_class_ins.shape[0], -1),\n",
    "                                                              other_inverted.view(other_inverted.shape[0], -1))\n",
    "            \n",
    "            if i_epoch < i_start_epoch_out:\n",
    "                ot_transformed_out = th.zeros(1, device=class_ins.device)\n",
    "            else:\n",
    "                other_samples = class_dist.get_samples(1-i_class, len(train_inputs[i_class]) * 2)\n",
    "                ot_transformed_out = ot_euclidean_loss_for_samples(changed_to_other_class[:,:2].squeeze(),\n",
    "                                                                   other_samples[:,:2].squeeze(),)\n",
    "            loss =  ot_loss_out + ot_transformed_in + ot_transformed_out + ot_loss_in\n",
    "            loss.backward()\n",
    "            del outs, other_class_ins, other_inverted\n",
    "            clear_ctx_dicts(feature_model)\n",
    "        optim_model.step()\n",
    "        optim_dist.step()\n",
    "    if i_epoch % (n_epochs // 20) == 0:\n",
    "        print(\"Epoch {:d} of {:d}\".format(i_epoch, n_epochs))\n",
    "        print(\"Loss: {:.2E}\".format(loss.item()))\n",
    "        print(\"OT Loss In: {:.2E}\".format(ot_loss_in.item()))\n",
    "        print(\"OT Loss Out: {:.2E}\".format(ot_loss_out.item()))\n",
    "        print(\"Transformed OT Loss In: {:.2E}\".format(ot_transformed_in.item()))\n",
    "        print(\"Transformed OT Loss Out: {:.2E}\".format(ot_transformed_out.item()))\n",
    "        print(\"Loop Time: {:.0f} ms\".format(loop_time.elapsed_secs * 1000))\n",
    "        plot_outs(feature_model, train_inputs, test_inputs,\n",
    "                 class_dist)\n",
    "        fig = plt.figure(figsize=(8,2))\n",
    "        plt.plot(var_to_np(th.cat((th.exp(class_dist.class_log_stds),\n",
    "                                 th.exp(class_dist.non_class_log_stds)))),\n",
    "                marker='o')\n",
    "        display_close(fig)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tight_bcic_4_2a_positions = [\n",
    "    ['','','','Fz','','',''],\n",
    "    ['','FC3','FC1','FCz','FC2','FC4',''],\n",
    "    ['C5','C3','C1','Cz','C2','C4','C6'],\n",
    "    ['','CP3','CP1','CPz','CP2','CP4',''],\n",
    "    ['','','P1','Pz','P2','',''],\n",
    "    ['','','','POz','','','']]\n",
    "def get_sensor_pos(sensor_name, sensor_map=tight_bcic_4_2a_positions):\n",
    "    sensor_pos = np.where(np.char.lower(np.char.array(sensor_map)) == sensor_name.lower())\n",
    "    # unpack them: they are 1-dimensional arrays before\n",
    "    assert len(sensor_pos[0]) == 1, (\"there should be a position for the sensor \"\n",
    "        \"{:s}\".format(sensor_name))\n",
    "    return sensor_pos[0][0], sensor_pos[1][0]\n",
    "\n",
    "def plot_head_signals_tight(signals, sensor_names=None, figsize=(12, 7),\n",
    "        plot_args=None, hspace=0.35, sensor_map=tight_bcic_4_2a_positions,\n",
    "        tsplot=False, sharex=True, sharey=True):\n",
    "    assert sensor_names is None or len(signals) == len(sensor_names), (\"need \"\n",
    "        \"sensor names for all sensor matrices\")\n",
    "    assert sensor_names is not None\n",
    "    if plot_args is None:\n",
    "        plot_args = dict()\n",
    "    figure = plt.figure(figsize=figsize)\n",
    "    sensor_positions = [get_sensor_pos(name, sensor_map) for name in sensor_names]\n",
    "    sensor_positions = np.array(sensor_positions)  # sensors x 2(row and col)\n",
    "    maxima = np.max(sensor_positions, axis=0)\n",
    "    minima = np.min(sensor_positions, axis=0)\n",
    "    max_row = maxima[0]\n",
    "    max_col = maxima[1]\n",
    "    min_row = minima[0]\n",
    "    min_col = minima[1]\n",
    "    rows = max_row - min_row + 1\n",
    "    cols = max_col - min_col + 1\n",
    "    first_ax = None\n",
    "    for i in range(0, len(signals)):\n",
    "        sensor_name = sensor_names[i]\n",
    "        sensor_pos = sensor_positions[i]\n",
    "        assert np.all(sensor_pos == get_sensor_pos(sensor_name, sensor_map))\n",
    "        # Transform to flat sensor pos\n",
    "        row = sensor_pos[0]\n",
    "        col = sensor_pos[1]\n",
    "        subplot_ind = (row - min_row) * cols + col - min_col + 1  # +1 as matlab uses based indexing\n",
    "        if first_ax is None:\n",
    "            ax = figure.add_subplot(rows, cols, subplot_ind)\n",
    "            first_ax = ax\n",
    "        elif sharex  is True and sharey is True:\n",
    "            ax = figure.add_subplot(rows, cols, subplot_ind, sharey=first_ax,\n",
    "                sharex=first_ax)\n",
    "        elif sharex  is True and sharey is False:\n",
    "            ax = figure.add_subplot(rows, cols, subplot_ind,\n",
    "                sharex=first_ax)\n",
    "        elif sharex  is False and sharey is True:\n",
    "            ax = figure.add_subplot(rows, cols, subplot_ind, sharey=first_ax)\n",
    "        else:\n",
    "            ax = figure.add_subplot(rows, cols, subplot_ind)\n",
    "            \n",
    "        signal = signals[i]\n",
    "        if tsplot is False:\n",
    "            ax.plot(signal, **plot_args)\n",
    "        else:\n",
    "            seaborn.tsplot(signal.T, ax=ax, **plot_args)\n",
    "        ax.set_title(sensor_name)\n",
    "        ax.set_yticks([])\n",
    "        if len(signal) == 600:\n",
    "            ax.set_xticks([150, 300, 450])\n",
    "            ax.set_xticklabels([])\n",
    "        else:\n",
    "            ax.set_xticks([])\n",
    "            \n",
    "            \n",
    "        ax.xaxis.grid(True)\n",
    "        # make line at zero\n",
    "        ax.axhline(y=0, ls=':', color=\"grey\")\n",
    "        figure.subplots_adjust(hspace=hspace)\n",
    "    return figure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_outs = feature_model(test_inputs[1])\n",
    "clear_ctx_dicts(feature_model)\n",
    "\n",
    "\n",
    "max_val, i_max = th.max(th.max(test_outs, dim=1)[0], dim=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(var_to_np(th.max(test_outs, dim=1)[0]), marker='o')\n",
    "plt.yscale('symlog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_head_signals_tight(var_to_np(test_inputs[1][28:36]).squeeze().transpose(1,2,0),\n",
    "                              sensor_names=sensor_names,\n",
    "                             figsize=(20,12));\n",
    "plt.ylim(-3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_head_signals_tight(var_to_np(test_inputs[1][17:25]).squeeze().transpose(1,2,0),\n",
    "                              sensor_names=sensor_names,\n",
    "                             figsize=(20,12));\n",
    "plt.ylim(-3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_head_signals_tight(var_to_np(test_inputs[1][i_max.item()]).squeeze(),\n",
    "                              sensor_names=sensor_names,\n",
    "                             figsize=(20,12));\n",
    "plt.ylim(-3,3)\n",
    "fig = plot_head_signals_tight(var_to_np(test_inputs[1][i_max.item() - 1]).squeeze(),\n",
    "                              sensor_names=sensor_names,\n",
    "                             figsize=(20,12));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_head_signals_tight(var_to_np(train_inputs[1][i_max.item()]).squeeze(),\n",
    "                              sensor_names=sensor_names,\n",
    "                             figsize=(20,12));\n",
    "plt.ylim(-3,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_bps_per_class = []\n",
    "for i_class in range(len(train_inputs)):\n",
    "    samples = class_dist.get_samples(i_class, 400)\n",
    "    inverted = feature_model.invert(samples)\n",
    "    mean_bps_per_class.append(\n",
    "        np.mean(np.abs(np.fft.rfft(var_to_np(inverted.squeeze()))), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_head_signals_tight(np.stack(mean_bps_per_class, axis=-1), sensor_names=sensor_names,\n",
    "                             figsize=(20,12));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_head_signals_tight(np.log(mean_bps_per_class[0]/mean_bps_per_class[1]), sensor_names=sensor_names,\n",
    "                             figsize=(20,12));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clear_ctx_dicts(feature_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,3))\n",
    "plt.plot(np.fft.rfftfreq(inverted.shape[2],d=1/256.0),\n",
    "        np.mean(mean_bps_per_class[0], axis=0))\n",
    "plt.plot(np.fft.rfftfreq(inverted.shape[2],d=1/256.0),\n",
    "        np.mean(mean_bps_per_class[1], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_class in range(len(train_inputs)):\n",
    "    samples = class_dist.get_samples(i_class, 20)\n",
    "    inverted = feature_model.invert(samples)\n",
    "    fig, axes = plt.subplots(5,4, figsize=(16,12), sharex=True, sharey=True)\n",
    "    \n",
    "    for ax, curve in zip(axes.flatten(), var_to_np(inverted).squeeze()):\n",
    "        ax.plot(curve.T, color=seaborn.color_palette()[i_class])\n",
    "    display_close(fig)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(1,2, figsize=(12,2), sharex=True, sharey=True)\n",
    "for i_class in range(2):\n",
    "    cur_mean, cur_std = class_dist.get_mean_std(i_class, )\n",
    "    inverted = invert(feature_model, cur_mean.unsqueeze(0))\n",
    "    axes[0].plot(var_to_np(inverted.squeeze())[7], color=seaborn.color_palette()[i_class])\n",
    "    axes[1].plot(var_to_np(inverted.squeeze())[11], color=seaborn.color_palette()[i_class])\n",
    "axes[0].set_title(sensor_names[7])\n",
    "axes[1].set_title(sensor_names[11])\n",
    "plt.legend((\"Right Hand\", \"Rest\"), bbox_to_anchor=(1,1,0,0))\n",
    "display(fig)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inverted_per_class = []\n",
    "for i_class in range(2):\n",
    "    cur_mean, cur_std = class_dist.get_mean_std(i_class, )\n",
    "    inverted = invert(feature_model, cur_mean.unsqueeze(0))\n",
    "    inverted_per_class.append(var_to_np(inverted).squeeze())\n",
    "\n",
    "\n",
    "signals = np.stack(inverted_per_class, axis=-1)\n",
    "\n",
    "fig = plot_head_signals_tight(signals, sensor_names, sensor_map=tight_bcic_4_2a_positions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_head_signals_tight(signals[:,:,0], sensor_names, sensor_map=tight_bcic_4_2a_positions,)\n",
    "plt.ylim(-3,3)\n",
    "fig.suptitle(\"Right Hand\")\n",
    "fig = plot_head_signals_tight(signals[:,:,1], sensor_names, sensor_map=tight_bcic_4_2a_positions)\n",
    "plt.ylim(-3,3)\n",
    "fig.suptitle(\"Rest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
