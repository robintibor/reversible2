{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import os\n",
    "import site\n",
    "os.sys.path.insert(0, '/home/schirrmr/code/reversible/reversible2/')\n",
    "os.sys.path.insert(0, '/home/schirrmr/braindecode/code/braindecode/')\n",
    "os.sys.path.insert(0, '/home/schirrmr/code/explaining/reversible//')\n",
    "%cd /home/schirrmr/\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import logging\n",
    "log = logging.getLogger()\n",
    "log.setLevel('INFO')\n",
    "import sys\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s : %(message)s',\n",
    "                     level=logging.INFO, stream=sys.stdout)\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'png'\n",
    "matplotlib.rcParams['figure.figsize'] = (12.0, 1.0)\n",
    "matplotlib.rcParams['font.size'] = 14\n",
    "from matplotlib import rcParams, cycler\n",
    "import seaborn\n",
    "seaborn.set_style('darkgrid')\n",
    "\n",
    "from reversible.sliced import sliced_from_samples\n",
    "\n",
    "from numpy.random import RandomState\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import copy\n",
    "import math\n",
    "\n",
    "import itertools\n",
    "from reversible.plot import create_bw_image\n",
    "import torch as th\n",
    "from braindecode.torch_ext.util import np_to_var, var_to_np\n",
    "from reversible.revnet import ResidualBlock, invert, SubsampleSplitter, ViewAs, ReversibleBlockOld\n",
    "from spectral_norm import spectral_norm\n",
    "from conv_spectral_norm import conv_spectral_norm\n",
    "\n",
    "def display_text(text, fontsize=18):\n",
    "    fig = plt.figure(figsize=(12,0.1))\n",
    "    plt.title(text, fontsize=fontsize)\n",
    "    plt.axis('off')\n",
    "    display(fig)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from braindecode.datasets.bbci import BBCIDataset\n",
    "from braindecode.mne_ext.signalproc import mne_apply\n",
    "# we loaded all sensors to always get same cleaning results independent of sensor selection\n",
    "# There is an inbuilt heuristic that tries to use only EEG channels and that definitely\n",
    "# works for datasets in our paper\n",
    "#train_loader = BBCIDataset('/data/schirrmr/schirrmr/HGD-public/reduced/train/13.mat')\n",
    "#test_loader = BBCIDataset('/data/schirrmr/schirrmr/HGD-public/reduced/test/13.mat')\n",
    "start_cnt = BBCIDataset('/data/schirrmr/schirrmr/HGD-public/reduced/train/4.mat',).load()\n",
    "start_cnt = start_cnt.drop_channels(['STI 014'])\n",
    "def car(a):\n",
    "    return a - np.mean(a, keepdims=True, axis=0)\n",
    "\n",
    "start_cnt = mne_apply(\n",
    "    car, start_cnt)\n",
    "\n",
    "start_cnt = start_cnt.reorder_channels(['C3', 'C4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from braindecode.datautil.trial_segment import create_signal_target_from_raw_mne\n",
    "\n",
    "marker_def = OrderedDict([('Right Hand', [1]), ('Left Hand', [2],),\n",
    "                         ('Rest', [3]), ('Feet', [4])])\n",
    "ival = [500,1500]\n",
    "from braindecode.mne_ext.signalproc import mne_apply, resample_cnt\n",
    "from braindecode.datautil.signalproc import exponential_running_standardize, bandpass_cnt\n",
    "\n",
    "log.info(\"Resampling train...\")\n",
    "cnt = resample_cnt(start_cnt, 250.0)\n",
    "log.info(\"Standardizing train...\")\n",
    "cnt = mne_apply(lambda a: exponential_running_standardize(a.T ,factor_new=1e-3, init_block_size=1000, eps=1e-4).T,\n",
    "                     cnt)\n",
    "cnt = resample_cnt(cnt, 32.0)\n",
    "cnt = resample_cnt(cnt, 64.0)\n",
    "#cnt = mne_apply(\n",
    "#    lambda a: bandpass_cnt(a, 0, 2, cnt.info['sfreq'],\n",
    "#                           filt_order=10,\n",
    "#                           axis=1), cnt)\n",
    "\n",
    "train_set = create_signal_target_from_raw_mne(cnt, marker_def, ival)\n",
    "cnt_bandpassed =  mne_apply(\n",
    "    lambda a: bandpass_cnt(a, 8, 13, cnt.info['sfreq'],\n",
    "                           filt_order=10,\n",
    "                           axis=1), cnt)\n",
    "alpha_set = create_signal_target_from_raw_mne(cnt_bandpassed, marker_def, ival)\n",
    "x_alpha_right = alpha_set.X[alpha_set.y == 0]\n",
    "\n",
    "x_alpha_rest = alpha_set.X[alpha_set.y == 2]\n",
    "\n",
    "alpha_a = np_to_var(x_alpha_right[:160,0:1,:,None], dtype=np.float32)\n",
    "\n",
    "alpha_b = np_to_var(x_alpha_rest[:160,0:1,:,None], dtype=np.float32)\n",
    "inputs_alpha = [alpha_a, alpha_b]\n",
    "\n",
    "from scipy.signal import hilbert\n",
    "alpha_env_right = np.abs(hilbert(x_alpha_right))\n",
    "alpha_env_rest = np.abs(hilbert(x_alpha_rest))\n",
    "\n",
    "env_a = np_to_var(alpha_env_right[:160,0:1,:,None], dtype=np.float32)\n",
    "\n",
    "env_b = np_to_var(alpha_env_rest[:160,0:1,:,None], dtype=np.float32)\n",
    "inputs_env = [env_a, env_b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(80,4, figsize=(14,80), sharex=True, sharey=True)\n",
    "for i_class in range(len(inputs_env)):\n",
    "    for i_example in range(len(inputs_env[i_class])):\n",
    "        i_row = i_example // 2\n",
    "        i_col = i_example % 2\n",
    "        i_col += i_class * 2\n",
    "        axes[i_row][i_col].plot(var_to_np(inputs_env[i_class][i_example]).squeeze(),\n",
    "                               color=seaborn.color_palette()[i_class])\n",
    "fig.suptitle('Input signals', y=0.9)\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "lines = [Line2D([0], [0], color=seaborn.color_palette()[i_class],) for i_class in range(2)]\n",
    "labels = ['Right', 'Rest',]\n",
    "axes[0][-1].legend(lines, labels, bbox_to_anchor=(1,1,0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rev_block(n_c, n_i_c):\n",
    "     return ReversibleBlockOld(\n",
    "        nn.Sequential(\n",
    "            nn.Linear(n_c // 2, n_i_c,),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_i_c, n_c // 2,)),\n",
    "        nn.Sequential(\n",
    "            nn.Linear(n_c // 2, n_i_c,),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_i_c, n_c // 2))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hierarchical_gaussian import sample_wavelet, convert_wavelet\n",
    "\n",
    "def this_conv_wavelet(wavelet_samples):\n",
    "    wavelet_masks = get_wavelet_masks()\n",
    "    return convert_wavelet(wavelet_samples, wavelet_masks)\n",
    "\n",
    "def get_samples(n_samples, i_class=0):\n",
    "    mean = means_per_cluster[i_class]\n",
    "    log_std = stds_per_cluster[i_class]\n",
    "    samples = sample_wavelet(n_samples, mean, log_std, convert_fn=this_conv_wavelet)\n",
    "    #samples = transform_samples(samples)\n",
    "    return samples\n",
    "\n",
    "def transform_samples(samples):\n",
    "    samples = th.cat((samples[:,::2], samples[:,1::2]), dim=1)\n",
    "    samples = invert(feature_model,samples)\n",
    "    samples = th.stack(th.chunk(samples, 2, dim=1), dim=2).view(samples.shape[0], -1)\n",
    "    return samples\n",
    "\n",
    "def get_wavelet_masks():\n",
    "    wavelet_masks = []\n",
    "    t = top_wavelet_mask - th.mean(top_wavelet_mask)\n",
    "    t = t / th.mean(th.abs(t))\n",
    "    wavelet_masks.append(t)\n",
    "\n",
    "    for i_exp in range(int(np.log2(len(top_wavelet_mask)))- 1):\n",
    "        cur_mask = th.mean(top_wavelet_mask.view(-1, 2**(i_exp+1)), dim=1)\n",
    "        cur_mask = cur_mask - th.mean(cur_mask)\n",
    "        cur_mask = cur_mask / th.mean(th.abs(cur_mask))\n",
    "        wavelet_masks.append(cur_mask)\n",
    "    return wavelet_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from reversible.util import set_random_seeds\n",
    "set_random_seeds(2019011641, True)\n",
    "n_clusters = len(inputs_env)\n",
    "n_dims = inputs_env[0].shape[2]\n",
    "means_per_cluster = [th.autograd.Variable(th.zeros(n_dims), requires_grad=True)\n",
    "                     for _ in range(n_clusters)]\n",
    "\n",
    "\n",
    "# keep in mind this is in log domain so 0 is std 1\n",
    "stds_per_cluster = [th.zeros(n_dims, requires_grad=True)\n",
    "                    for _ in range(n_clusters)]\n",
    "# mean should be zero overall,... \n",
    "top_wavelet_mask = th.rand(n_dims, dtype=th.float32, requires_grad=True)\n",
    "import itertools\n",
    "\n",
    "set_random_seeds(20190227, True)\n",
    "feature_model = nn.Sequential(\n",
    "    rev_block(64,64),\n",
    "    rev_block(64,64),\n",
    "    rev_block(64,64),\n",
    "    rev_block(64,64),\n",
    ")\n",
    "def zero_init(m):\n",
    "    if hasattr(m, 'weight'):\n",
    "        nn.init.zeros_(m.weight)\n",
    "#feature_model.apply(zero_init);\n",
    "optim_model = th.optim.Adam(feature_model.parameters(),\n",
    "                          lr=1e-3)\n",
    "optim_dist = th.optim.Adam(means_per_cluster + stds_per_cluster + [top_wavelet_mask],\n",
    "                          lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 6000\n",
    "for i_epoch in range(n_epochs):\n",
    "    i_class = 0\n",
    "    this_ins = inputs_env[i_class].squeeze()\n",
    "    mean = means_per_cluster[i_class]\n",
    "    log_stds = stds_per_cluster[i_class]\n",
    "    samples = get_samples(2*320)\n",
    "    sliced_loss = sliced_from_samples(this_ins, samples, 10, None)\n",
    "    \n",
    "    optim_model.zero_grad()\n",
    "    optim_dist.zero_grad()\n",
    "    sliced_loss.backward()\n",
    "    optim_model.step()\n",
    "    optim_dist.step()\n",
    "    if i_epoch % (n_epochs // 20) == 0:\n",
    "        display_text(\"Epoch {:d}  of {:d}\".format(i_epoch, n_epochs))\n",
    "        display_text(\"Sliced loss {:.2f}\".format(sliced_loss))\n",
    "        \n",
    "        fig = plt.figure(figsize=(8,3))\n",
    "        plt.plot(var_to_np(samples[:3]).T)\n",
    "        display(fig)\n",
    "        plt.close(fig)\n",
    "        \n",
    "        fig = plt.figure(figsize=(3,3))\n",
    "        emp_cov = np.cov(var_to_np(samples.squeeze()).T)\n",
    "        plt.imshow(emp_cov, cmap=cm.coolwarm, vmin=-np.max(np.abs(emp_cov)),\n",
    "                  vmax=np.max(np.abs(emp_cov)))\n",
    "        cbar = plt.colorbar()\n",
    "        cbar.set_label(\"Empirical Covariance\")\n",
    "        display(fig)\n",
    "        plt.close(fig)\n",
    "        fig = plt.figure(figsize=(12,4))\n",
    "        plt.errorbar(range(len(means_per_cluster[0])), \n",
    "                         var_to_np(means_per_cluster[0]),\n",
    "                    yerr=var_to_np(th.exp(stds_per_cluster[0])), ecolor='black')\n",
    "        plt.title(\"Latent distribution\")\n",
    "        display(fig)\n",
    "        plt.close(fig)\n",
    "        display_text(\"Mean stds per hierarchy\")\n",
    "        mean_stds =[th.exp(stds_per_cluster[0][0])] + [\n",
    "            th.mean(th.exp(stds_per_cluster[0][int(2**i_exp):int(2**(i_exp+1))]))\n",
    "            for i_exp in range(int(np.log2(len(mean))))]\n",
    "        display(mean_stds)\n",
    "        from matplotlib import rcParams, cycler\n",
    "        cmap = plt.cm.copper\n",
    "        N = len(get_wavelet_masks()) + 1\n",
    "        fig = plt.figure(figsize=(8,5))\n",
    "        with plt.rc_context({'axes.prop_cycle': cycler(color=cmap(np.linspace(0., 1, N)))}):\n",
    "            with seaborn.axes_style(\"whitegrid\"):\n",
    "                for i_exp in range((len(get_wavelet_masks()))):\n",
    "                    this_std = get_wavelet_masks()[i_exp]\n",
    "                    plt.plot(var_to_np(this_std.repeat(2**(i_exp))), lw=3-i_exp*0.4)\n",
    "        plt.title(\"Masks\")\n",
    "        display(fig)\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_vals = 21\n",
    "for i_dims in [[0], [1], [2,3,], [4,5,6,7]]:\n",
    "    with plt.rc_context({'axes.prop_cycle': plt.cycler(color=cm.coolwarm(np.linspace(0, 1, n_vals)))}):\n",
    "        fig, axes = plt.subplots(1, len(i_dims), figsize=(14,3))\n",
    "        if len(i_dims) == 1:\n",
    "            axes = [axes]\n",
    "        for i_ax, i_dim in enumerate(i_dims):\n",
    "            mean_vals = th.linspace((-th.exp(stds_per_cluster[0][i_dim]) * 1).item(),\n",
    "                                    (th.exp(stds_per_cluster[0][i_dim]) * 1).item(),\n",
    "                       n_vals)\n",
    "            examples = means_per_cluster[0].clone().repeat(n_vals,1)\n",
    "            examples.data[:,i_dim] = mean_vals + means_per_cluster[0][i_dim]\n",
    "            examples = this_conv_wavelet(examples)\n",
    "            #examples = transform_samples(examples)\n",
    "            axes[i_ax].plot(var_to_np(examples).squeeze().T)\n",
    "            axes[i_ax].plot(var_to_np(examples[n_vals //2].unsqueeze(0)).T, color='black', lw=2)\n",
    "            axes[i_ax].set_title(\"Changing Dimension {:d}\".format(i_dim))\n",
    "        display(fig)\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,3))\n",
    "plt.plot(var_to_np(get_wavelet_masks()[0]))\n",
    "plt.title(\"Top mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 3200\n",
    "in_samples = var_to_np(get_samples(n_samples).squeeze())\n",
    "this_ins = var_to_np(inputs_env[i_class].squeeze())\n",
    "\n",
    "diffs = this_ins[:,None] - in_samples[None]\n",
    "\n",
    "diffs = np.sqrt(np.sum(np.square(diffs), axis=-1))\n",
    "\n",
    "import ot\n",
    "coupling = ot.emd([],[], diffs)\n",
    "mask = coupling > (1/(2*len(in_samples)))\n",
    "assert np.sum(mask)  == len(in_samples)\n",
    "argmaxes = np.argmax(mask, axis=0)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(5,8, figsize=(12,6), sharex=True, sharey=True)\n",
    "for i_in, ax in enumerate(axes.flatten()):\n",
    "    i_samples = np.nonzero(argmaxes == i_in)\n",
    "    ax.plot(in_samples[i_samples].T, color=seaborn.color_palette()[0], lw=0.5)\n",
    "    ax.plot(this_ins[i_in], color='black')\n",
    "display(fig)\n",
    "plt.close(fig)\n",
    "print(\"Cost: {:.2f}\".format(np.sum(coupling * diffs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([0.3979, 0.5463])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
