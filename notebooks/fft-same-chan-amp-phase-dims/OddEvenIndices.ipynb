{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import os\n",
    "import site\n",
    "os.sys.path.insert(0, '/home/schirrmr/code/reversible/reversible2/')\n",
    "os.sys.path.insert(0, '/home/schirrmr/braindecode/code/braindecode/')\n",
    "os.sys.path.insert(0, '/home/schirrmr/code/explaining/reversible//')\n",
    "%cd /home/schirrmr/\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import logging\n",
    "log = logging.getLogger()\n",
    "log.setLevel('INFO')\n",
    "import sys\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s : %(message)s',\n",
    "                     level=logging.INFO, stream=sys.stdout)\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'png'\n",
    "matplotlib.rcParams['figure.figsize'] = (12.0, 1.0)\n",
    "matplotlib.rcParams['font.size'] = 14\n",
    "from matplotlib import rcParams, cycler\n",
    "import seaborn\n",
    "seaborn.set_style('darkgrid')\n",
    "\n",
    "from reversible.sliced import sliced_from_samples\n",
    "\n",
    "from numpy.random import RandomState\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import copy\n",
    "import math\n",
    "\n",
    "import itertools\n",
    "from reversible.plot import create_bw_image\n",
    "import torch as th\n",
    "from braindecode.torch_ext.util import np_to_var, var_to_np\n",
    "from reversible.revnet import ResidualBlock, invert, SubsampleSplitter, ViewAs, ReversibleBlockOld\n",
    "from spectral_norm import spectral_norm\n",
    "from conv_spectral_norm import conv_spectral_norm\n",
    "\n",
    "def display_text(text, fontsize=18):\n",
    "    fig = plt.figure(figsize=(12,0.1))\n",
    "    plt.title(text, fontsize=fontsize)\n",
    "    plt.axis('off')\n",
    "    display(fig)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from braindecode.datasets.bbci import BBCIDataset\n",
    "from braindecode.mne_ext.signalproc import mne_apply\n",
    "# we loaded all sensors to always get same cleaning results independent of sensor selection\n",
    "# There is an inbuilt heuristic that tries to use only EEG channels and that definitely\n",
    "# works for datasets in our paper\n",
    "#train_loader = BBCIDataset('/data/schirrmr/schirrmr/HGD-public/reduced/train/13.mat')\n",
    "#test_loader = BBCIDataset('/data/schirrmr/schirrmr/HGD-public/reduced/test/13.mat')\n",
    "start_cnt = BBCIDataset('/data/schirrmr/schirrmr/HGD-public/reduced/train/4.mat',).load()\n",
    "start_cnt = start_cnt.drop_channels(['STI 014'])\n",
    "def car(a):\n",
    "    return a - np.mean(a, keepdims=True, axis=0)\n",
    "\n",
    "start_cnt = mne_apply(\n",
    "    car, start_cnt)\n",
    "\n",
    "start_cnt = start_cnt.reorder_channels(['C3', 'C4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from braindecode.datautil.trial_segment import create_signal_target_from_raw_mne\n",
    "\n",
    "marker_def = OrderedDict([('Right Hand', [1]), ('Left Hand', [2],),\n",
    "                         ('Rest', [3]), ('Feet', [4])])\n",
    "ival = [500,1500]\n",
    "from braindecode.mne_ext.signalproc import mne_apply, resample_cnt\n",
    "from braindecode.datautil.signalproc import exponential_running_standardize, bandpass_cnt\n",
    "\n",
    "log.info(\"Resampling train...\")\n",
    "cnt = resample_cnt(start_cnt, 250.0)\n",
    "log.info(\"Standardizing train...\")\n",
    "cnt = mne_apply(lambda a: exponential_running_standardize(a.T ,factor_new=1e-3, init_block_size=1000, eps=1e-4).T,\n",
    "                     cnt)\n",
    "cnt = resample_cnt(cnt, 32.0)\n",
    "cnt = resample_cnt(cnt, 64.0)\n",
    "#cnt = mne_apply(\n",
    "#    lambda a: bandpass_cnt(a, 0, 2, cnt.info['sfreq'],\n",
    "#                           filt_order=10,\n",
    "#                           axis=1), cnt)\n",
    "\n",
    "train_set = create_signal_target_from_raw_mne(cnt, marker_def, ival)\n",
    "cnt_bandpassed =  mne_apply(\n",
    "    lambda a: bandpass_cnt(a, 8, 13, cnt.info['sfreq'],\n",
    "                           filt_order=10,\n",
    "                           axis=1), cnt)\n",
    "alpha_set = create_signal_target_from_raw_mne(cnt_bandpassed, marker_def, ival)\n",
    "x_alpha_right = alpha_set.X[alpha_set.y == 0]\n",
    "\n",
    "x_alpha_rest = alpha_set.X[alpha_set.y == 2]\n",
    "\n",
    "alpha_a = np_to_var(x_alpha_right[:160,0:1,:,None], dtype=np.float32)\n",
    "\n",
    "alpha_b = np_to_var(x_alpha_rest[:160,0:1,:,None], dtype=np.float32)\n",
    "inputs_alpha = [alpha_a, alpha_b]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_class = 0\n",
    "a_in = inputs_alpha[i_class][0]\n",
    "plt.plot(var_to_np(a_in).squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## single signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reversible.util import set_random_seeds\n",
    "\n",
    "set_random_seeds(3, True)\n",
    "templates = th.zeros((2,inputs_alpha[i_class].shape[2] // 2), requires_grad=True)\n",
    "\n",
    "templates.data[0] = th.linspace(0,63,64)[::2]\n",
    "templates.data[1] = th.linspace(0,63,64)[1::2]\n",
    "\n",
    "templates.data[0] = th.randn(32) * 0.5\n",
    "templates.data[1] = th.randn(32) * 0.5\n",
    "\n",
    "coef_a = th.ones(1, requires_grad=True)\n",
    "coef_b = th.ones(1, requires_grad=True)\n",
    "\n",
    "a_b = templates * th.cat((coef_a, coef_b)).unsqueeze(1)\n",
    "a_b.unsqueeze(0).unsqueeze(-1).shape\n",
    "inverted = invert(SubsampleSplitter((2,1), chunk_chans_first=False), a_b.unsqueeze(0).unsqueeze(-1)).squeeze()\n",
    "\n",
    "fig = plt.figure(figsize=(12,2))\n",
    "plt.plot(var_to_np(inverted).squeeze())\n",
    "plt.plot(var_to_np(a_in).squeeze())\n",
    "display(fig)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = th.optim.Adam([templates], lr=1e-2)#, coef_a, coef_b\n",
    "n_epochs = 1000\n",
    "for i_epoch in range(n_epochs):\n",
    "    a_b = templates * th.cat((coef_a, coef_b)).unsqueeze(1)\n",
    "    a_b.unsqueeze(0).unsqueeze(-1).shape\n",
    "    inverted = invert(SubsampleSplitter((2,1), chunk_chans_first=False), a_b.unsqueeze(0).unsqueeze(-1)).squeeze()\n",
    "    loss = th.sqrt(th.sum((inverted - a_in.squeeze()) ** 2))\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i_epoch % (n_epochs // 10) == 0:\n",
    "        print(\"Loss: {:.4f}\".format(loss.item()))\n",
    "        fig = plt.figure(figsize=(12,2))\n",
    "        plt.plot(var_to_np(inverted).squeeze())\n",
    "        plt.plot(var_to_np(a_in).squeeze())\n",
    "        display(fig)\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## all signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reversible.util import set_random_seeds\n",
    "\n",
    "set_random_seeds(3, True)\n",
    "templates = th.zeros((2,inputs_alpha[i_class].shape[2] // 2), requires_grad=True)\n",
    "\n",
    "\n",
    "templates.data[0] = th.randn(32) * 0.5\n",
    "templates.data[1] = th.randn(32) * 0.5\n",
    "\n",
    "coef_a = th.ones(len(inputs_alpha[i_class]), requires_grad=True)\n",
    "coef_b = th.ones(len(inputs_alpha[i_class]), requires_grad=True)\n",
    "a_b = templates.unsqueeze(0) * th.stack((coef_a, coef_b), dim=1).unsqueeze(2)\n",
    "inverted = invert(SubsampleSplitter((2,1), chunk_chans_first=False), a_b.unsqueeze(-1))\n",
    "\n",
    "fig = plt.figure(figsize=(12,2))\n",
    "plt.plot(var_to_np(inverted[0]).squeeze())\n",
    "plt.plot(var_to_np(inputs_alpha[i_class][0]).squeeze())\n",
    "display(fig)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = th.optim.Adam([templates, coef_a, coef_b], lr=1e-2)#, coef_a, coef_b\n",
    "n_epochs = 10000\n",
    "for i_epoch in range(n_epochs):\n",
    "    a_b = templates.unsqueeze(0) * th.stack((coef_a, coef_b), dim=1).unsqueeze(2)\n",
    "    inverted = invert(SubsampleSplitter((2,1), chunk_chans_first=False), a_b.unsqueeze(-1))\n",
    "    loss = th.mean(th.sqrt(th.sum((inverted - inputs_alpha[i_class]) ** 2, dim=2)).squeeze())\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i_epoch % (n_epochs // 10) == 0:\n",
    "        print(\"Loss: {:.4f}\".format(loss.item()))\n",
    "        fig = plt.figure(figsize=(12,2))\n",
    "        plt.plot(var_to_np(inverted[0]).squeeze())\n",
    "        plt.plot(var_to_np(inputs_alpha[i_class][0]).squeeze())\n",
    "        display(fig)\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,3))\n",
    "plt.plot(var_to_np(inverted[0]).squeeze(), color=seaborn.color_palette()[0])\n",
    "plt.plot(var_to_np(inputs_alpha[i_class][0]).squeeze(),\n",
    "        color=seaborn.color_palette()[1])\n",
    "plt.legend([\"Real\", \"Fake\"])\n",
    "display(fig)\n",
    "\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_b = templates.unsqueeze(0) * th.stack((coef_a, coef_b), dim=1).unsqueeze(2)\n",
    "inverted = invert(SubsampleSplitter((2,1), chunk_chans_first=False), a_b.unsqueeze(-1))\n",
    "\n",
    "fig, axes = plt.subplots(5,8, figsize=(18,12), sharex=True, sharey=True)\n",
    "for i_in, ax in enumerate(axes.flatten()):\n",
    "    ax.plot(var_to_np(inverted[i_in]).squeeze(), color=seaborn.color_palette()[0],)\n",
    "    ax.plot(var_to_np(inputs_alpha[i_class][i_in]).squeeze(), color='black')\n",
    "display(fig)\n",
    "plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,3))\n",
    "plt.plot(var_to_np(templates).T)\n",
    "plt.title(\"Templates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_b = templates.unsqueeze(0)\n",
    "inverted = invert(SubsampleSplitter((2,1), chunk_chans_first=False), a_b.unsqueeze(-1))\n",
    "fig = plt.figure(figsize=(10,3))\n",
    "plt.plot(var_to_np(inverted[0]).squeeze())\n",
    "plt.title(\"Full Template\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.fft.rfftfreq(len(inverted.squeeze()),d=1/64.0),\n",
    "    np.abs(np.fft.rfft(var_to_np(inverted).squeeze())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(var_to_np(coef_a), var_to_np(coef_b), ls='', marker='o')\n",
    "plt.xlim(-2,2)\n",
    "plt.ylim(-2,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### two full templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# two full templates\n",
    "# half templates with invertible network after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reversible.util import set_random_seeds\n",
    "\n",
    "set_random_seeds(3, True)\n",
    "templates = th.zeros((2,inputs_alpha[i_class].shape[2] ), requires_grad=True)\n",
    "\n",
    "\n",
    "templates.data[0] = th.randn(64) * 0.5\n",
    "templates.data[1] = th.randn(64) * 0.5\n",
    "\n",
    "coef_a = th.ones(len(inputs_alpha[i_class]), requires_grad=True)\n",
    "coef_b = th.ones(len(inputs_alpha[i_class]), requires_grad=True)\n",
    "a_b = templates.unsqueeze(0) * th.stack((coef_a, coef_b), dim=1).unsqueeze(2)\n",
    "inverted = (a_b[:,0] + a_b[:,1]).unsqueeze(1).unsqueeze(-1)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(12,2))\n",
    "plt.plot(var_to_np(inverted[0]).squeeze())\n",
    "plt.plot(var_to_np(inputs_alpha[i_class][0]).squeeze())\n",
    "display(fig)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = th.optim.Adam([templates, coef_a, coef_b], lr=1e-2)#, coef_a, coef_b\n",
    "n_epochs = 10000\n",
    "for i_epoch in range(n_epochs):\n",
    "    a_b = templates.unsqueeze(0) * th.stack((coef_a, coef_b), dim=1).unsqueeze(2)\n",
    "    inverted = (a_b[:,0] + a_b[:,1]).unsqueeze(1).unsqueeze(-1)\n",
    "    loss = th.mean(th.sqrt(th.sum((inverted - inputs_alpha[i_class]) ** 2, dim=2)).squeeze())\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i_epoch % (n_epochs // 10) == 0:\n",
    "        print(\"Loss: {:.4f}\".format(loss.item()))\n",
    "        fig = plt.figure(figsize=(12,2))\n",
    "        plt.plot(var_to_np(inverted[0]).squeeze())\n",
    "        plt.plot(var_to_np(inputs_alpha[i_class][0]).squeeze())\n",
    "        display(fig)\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,3))\n",
    "plt.plot(var_to_np(inverted[0]).squeeze(), color=seaborn.color_palette()[0])\n",
    "plt.plot(var_to_np(inputs_alpha[i_class][0]).squeeze(),\n",
    "        color=seaborn.color_palette()[1])\n",
    "plt.legend([\"Real\", \"Fake\"])\n",
    "display(fig)\n",
    "\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,3))\n",
    "plt.plot(var_to_np(templates).T)\n",
    "plt.title(\"Templates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,3))\n",
    "plt.plot(np.fft.rfftfreq(64, 1/64.0), np.abs(np.fft.rfft(var_to_np(templates))).T)\n",
    "plt.title(\"Spectrum of templates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### half templates with invertible network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rev_block(n_c, n_i_c):\n",
    "     return ReversibleBlockOld(\n",
    "        nn.Sequential(\n",
    "            nn.Conv2d(n_c // 2, n_i_c, (1,1)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(n_i_c, n_c // 2, (1,1))),\n",
    "        nn.Sequential(\n",
    "            nn.Conv2d(n_c // 2, n_i_c, (1,1)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(n_i_c, n_c // 2, (1,1))),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reversible.util import set_random_seeds\n",
    "\n",
    "set_random_seeds(3, True)\n",
    "templates = th.zeros((2,inputs_alpha[i_class].shape[2] // 2), requires_grad=True)\n",
    "\n",
    "\n",
    "templates.data[0] = th.randn(32) * 0.5\n",
    "templates.data[1] = th.randn(32) * 0.5\n",
    "\n",
    "coef_a = th.ones(len(inputs_alpha[i_class]), requires_grad=True)\n",
    "coef_b = th.ones(len(inputs_alpha[i_class]), requires_grad=True)\n",
    "a_b = templates.unsqueeze(0) * th.stack((coef_a, coef_b), dim=1).unsqueeze(2)\n",
    "\n",
    "feature_model = nn.Sequential(\n",
    "    SubsampleSplitter((2,1), chunk_chans_first=False),\n",
    "    rev_block(2,32),\n",
    "    rev_block(2,32),\n",
    ")\n",
    "\n",
    "inverted = invert(feature_model, a_b.unsqueeze(-1))\n",
    "\n",
    "fig = plt.figure(figsize=(12,2))\n",
    "plt.plot(var_to_np(inputs_alpha[i_class][0]).squeeze())\n",
    "plt.plot(var_to_np(inverted[0]).squeeze())\n",
    "display(fig)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = th.optim.Adam([templates, coef_a, coef_b] + list(feature_model.parameters()), lr=1e-3)\n",
    "n_epochs = 10000\n",
    "for i_epoch in range(n_epochs):\n",
    "    a_b = templates.unsqueeze(0) * th.stack((coef_a, coef_b), dim=1).unsqueeze(2)\n",
    "    inverted = invert(feature_model, a_b.unsqueeze(-1))\n",
    "    loss = th.mean(th.sqrt(th.sum((inverted - inputs_alpha[i_class]) ** 2, dim=2)).squeeze())\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i_epoch % (n_epochs // 10) == 0:\n",
    "        print(\"Loss: {:.4f}\".format(loss.item()))\n",
    "        fig = plt.figure(figsize=(12,2))\n",
    "        plt.plot(var_to_np(inputs_alpha[i_class][0]).squeeze())\n",
    "        plt.plot(var_to_np(inverted[0]).squeeze())\n",
    "        display(fig)\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,3))\n",
    "plt.plot(var_to_np(templates).T)\n",
    "plt.title(\"Templates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_b = templates.unsqueeze(0)\n",
    "inverted = invert(SubsampleSplitter((2,1), chunk_chans_first=False), a_b.unsqueeze(-1))\n",
    "fig = plt.figure(figsize=(10,3))\n",
    "plt.plot(var_to_np(inverted[0]).squeeze())\n",
    "plt.title(\"Full Template\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### with bigger network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reversible.util import set_random_seeds\n",
    "\n",
    "set_random_seeds(3, True)\n",
    "templates = th.zeros((2,inputs_alpha[i_class].shape[2] // 2), requires_grad=True)\n",
    "\n",
    "\n",
    "templates.data[0] = th.randn(32) * 0.5\n",
    "templates.data[1] = th.randn(32) * 0.5\n",
    "\n",
    "coef_a = th.ones(len(inputs_alpha[i_class]), requires_grad=True)\n",
    "coef_b = th.ones(len(inputs_alpha[i_class]), requires_grad=True)\n",
    "a_b = templates.unsqueeze(0) * th.stack((coef_a, coef_b), dim=1).unsqueeze(2)\n",
    "\n",
    "feature_model = nn.Sequential(\n",
    "    SubsampleSplitter((2,1), chunk_chans_first=False),\n",
    "    rev_block(2,32),\n",
    "    rev_block(2,32),\n",
    "    rev_block(2,32),\n",
    "    rev_block(2,32),\n",
    "    rev_block(2,32),\n",
    "    rev_block(2,32),\n",
    ")\n",
    "\n",
    "inverted = invert(feature_model, a_b.unsqueeze(-1))\n",
    "\n",
    "fig = plt.figure(figsize=(12,2))\n",
    "plt.plot(var_to_np(inputs_alpha[i_class][0]).squeeze())\n",
    "plt.plot(var_to_np(inverted[0]).squeeze())\n",
    "display(fig)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = th.optim.Adam([templates, coef_a, coef_b] + list(feature_model.parameters()), lr=1e-3)\n",
    "n_epochs = 10000\n",
    "for i_epoch in range(n_epochs):\n",
    "    a_b = templates.unsqueeze(0) * th.stack((coef_a, coef_b), dim=1).unsqueeze(2)\n",
    "    inverted = invert(feature_model, a_b.unsqueeze(-1))\n",
    "    loss = th.mean(th.sqrt(th.sum((inverted - inputs_alpha[i_class]) ** 2, dim=2)).squeeze())\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i_epoch % (n_epochs // 10) == 0:\n",
    "        print(\"Loss: {:.4f}\".format(loss.item()))\n",
    "        fig = plt.figure(figsize=(12,2))\n",
    "        plt.plot(var_to_np(inputs_alpha[i_class][0]).squeeze())\n",
    "        plt.plot(var_to_np(inverted[0]).squeeze())\n",
    "        display(fig)\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with fixed templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reversible.util import set_random_seeds\n",
    "\n",
    "set_random_seeds(3, True)\n",
    "templates = th.zeros((2,inputs_alpha[i_class].shape[2] // 2), requires_grad=True)\n",
    "\n",
    "\n",
    "templates.data[0] = th.ones(32) * 0.5\n",
    "templates.data[1] = th.ones(32) * 0.5\n",
    "\n",
    "coef_a = th.ones(len(inputs_alpha[i_class]), requires_grad=True)\n",
    "coef_b = th.ones(len(inputs_alpha[i_class]), requires_grad=True)\n",
    "a_b = templates.unsqueeze(0) * th.stack((coef_a, coef_b), dim=1).unsqueeze(2)\n",
    "\n",
    "feature_model = nn.Sequential(\n",
    "    SubsampleSplitter((2,1), chunk_chans_first=False),\n",
    "    rev_block(2,32),\n",
    "    rev_block(2,32),\n",
    ")\n",
    "\n",
    "inverted = invert(feature_model, a_b.unsqueeze(-1))\n",
    "\n",
    "fig = plt.figure(figsize=(12,2))\n",
    "plt.plot(var_to_np(inputs_alpha[i_class][0]).squeeze())\n",
    "plt.plot(var_to_np(inverted[0]).squeeze())\n",
    "display(fig)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = th.optim.Adam([coef_a, coef_b] + list(feature_model.parameters()), lr=1e-3)\n",
    "n_epochs = 10000\n",
    "for i_epoch in range(n_epochs):\n",
    "    a_b = templates.unsqueeze(0) * th.stack((coef_a, coef_b), dim=1).unsqueeze(2)\n",
    "    inverted = invert(feature_model, a_b.unsqueeze(-1))\n",
    "    loss = th.mean(th.sqrt(th.sum((inverted - inputs_alpha[i_class]) ** 2, dim=2)).squeeze())\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i_epoch % (n_epochs // 10) == 0:\n",
    "        print(\"Loss: {:.4f}\".format(loss.item()))\n",
    "        fig = plt.figure(figsize=(12,2))\n",
    "        plt.plot(var_to_np(inputs_alpha[i_class][0]).squeeze())\n",
    "        plt.plot(var_to_np(inverted[0]).squeeze())\n",
    "        display(fig)\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "64/8 .. # we need 8 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# on the \"correct\" level (upper bound) (so 8)\n",
    "# for this sample, model it, so optimize coefficients at this level\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
