{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import os\n",
    "import site\n",
    "os.sys.path.insert(0, '/home/schirrmr/code/reversible/reversible2/')\n",
    "os.sys.path.insert(0, '/home/schirrmr/braindecode/code/braindecode/')\n",
    "os.sys.path.insert(0, '/home/schirrmr/code/explaining/reversible//')\n",
    "%cd /home/schirrmr/\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import logging\n",
    "log = logging.getLogger()\n",
    "log.setLevel('INFO')\n",
    "import sys\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s : %(message)s',\n",
    "                     level=logging.INFO, stream=sys.stdout)\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'png'\n",
    "matplotlib.rcParams['figure.figsize'] = (12.0, 1.0)\n",
    "matplotlib.rcParams['font.size'] = 14\n",
    "import seaborn\n",
    "seaborn.set_style('darkgrid')\n",
    "\n",
    "from reversible.sliced import sliced_from_samples\n",
    "\n",
    "from numpy.random import RandomState\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import copy\n",
    "import math\n",
    "\n",
    "import itertools\n",
    "from reversible.plot import create_bw_image\n",
    "import torch as th\n",
    "from braindecode.torch_ext.util import np_to_var, var_to_np\n",
    "from reversible.revnet import ResidualBlock, invert, SubsampleSplitter, ViewAs, ReversibleBlockOld\n",
    "from spectral_norm import spectral_norm\n",
    "from conv_spectral_norm import conv_spectral_norm\n",
    "\n",
    "def display_text(text, fontsize=18):\n",
    "    fig = plt.figure(figsize=(12,0.1))\n",
    "    plt.title(text, fontsize=fontsize)\n",
    "    plt.axis('off')\n",
    "    display(fig)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# try switching forward and invert\n",
    "# https://github.com/rosinality/glow-pytorch/blob/ddb4b65384a5f96bdfab2f07194b98c5da46ae80/model.py\n",
    "\n",
    "class InvConv1x1(nn.Module):\n",
    "    def __init__(self, in_channel):\n",
    "        super().__init__()\n",
    "\n",
    "        weight = torch.randn(in_channel, in_channel)\n",
    "        q, _ = torch.qr(weight)\n",
    "        weight = q.unsqueeze(2).unsqueeze(3)\n",
    "        self.weight = nn.Parameter(weight)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return F.conv2d(\n",
    "            input, self.weight.squeeze().inverse().unsqueeze(2).unsqueeze(3)\n",
    "        )\n",
    "\n",
    "    def invert(self, output):\n",
    "        out = F.conv2d(output, self.weight)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = th.sin(np_to_var(np.linspace(0,8*np.pi,64, endpoint=False), dtype=np.float32))\n",
    "plt.plot(var_to_np(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffted = th.rfft(data.unsqueeze(0).unsqueeze(1), signal_ndim=1).squeeze()\n",
    "plt.plot(np.abs(np.mean(var_to_np(ffted), axis=-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "invconv = InvConv1x1(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(invconv.weight)):\n",
    "    freq = i // 2\n",
    "    if i % 2 == 0:\n",
    "        invconv.weight.data[:,i,0,0] = th.cos(np_to_var(np.linspace(0,2*freq*np.pi,64, endpoint=False), dtype=np.float32))\n",
    "    else:\n",
    "        invconv.weight.data[:,i,0,0] = th.sin(np_to_var(np.linspace(0,2*freq*np.pi,64, endpoint=False), dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.sum(invconv.weight[9].squeeze() * data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "expanded_data = data.unsqueeze(0).unsqueeze(-1).unsqueeze(-1)\n",
    "inverted = invert(invconv, expanded_data).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(var_to_np(inverted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reversible.util import set_random_seeds\n",
    "set_random_seeds(20190328, False)\n",
    "train_inputs = [th.stack([th.sin(th.linspace(0,8*np.pi,65,)[:-1] + p) * a\n",
    "               for a,p in zip(th.randn(200) + 2, th.randn(200))]).unsqueeze(1).unsqueeze(-1)]\n",
    "\n",
    "test_inputs = [th.stack([th.sin(th.linspace(0,8*np.pi,65,)[:-1] + p) * a\n",
    "               for a,p in zip(th.randn(100) + 2, th.randn(100))]).unsqueeze(1).unsqueeze(-1)]\n",
    "\n",
    "plt.plot(var_to_np(train_inputs[0]).squeeze().T);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reversible.util import set_random_seeds\n",
    "set_random_seeds(20190328, False)\n",
    "train_inputs = [th.stack([th.cos(th.linspace(0,8*np.pi,65,)[:-1]) * c1 +\n",
    "                          th.sin(th.linspace(0,8*np.pi,65,)[:-1]) * c2\n",
    "               for c1,c2 in zip(th.randn(200), th.randn(200))]).unsqueeze(1).unsqueeze(-1)]\n",
    "\n",
    "test_inputs = [th.stack([th.cos(th.linspace(0,8*np.pi,65,)[:-1]) * c1 +\n",
    "                          th.sin(th.linspace(0,8*np.pi,65,)[:-1]) * c2\n",
    "               for c1,c2 in zip(th.randn(100), th.randn(100))]).unsqueeze(1).unsqueeze(-1)]\n",
    "\n",
    "plt.plot(var_to_np(train_inputs[0]).squeeze().T);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.mean(np.abs(np.fft.rfft(var_to_np(train_inputs[0].squeeze()))), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from discriminator import ProjectionDiscriminator\n",
    "from reversible.revnet import SubsampleSplitter, ViewAs\n",
    "from reversible.util import set_random_seeds\n",
    "from reversible.revnet import init_model_params\n",
    "from torch.nn import ConstantPad2d\n",
    "import torch as th\n",
    "from conv_spectral_norm import conv_spectral_norm\n",
    "from disttransform import DistTransformResNet\n",
    "\n",
    "\n",
    "set_random_seeds(2019011641, True)\n",
    "feature_model = nn.Sequential(\n",
    "    ViewAs((-1,1,64,1), (-1,64,1,1)),\n",
    "    InvConv1x1(64),\n",
    "    ViewAs((-1,64,1,1), (-1,64)),\n",
    ")\n",
    "\n",
    "\n",
    "from reversible.training import hard_init_std_mean\n",
    "n_dims = train_inputs[0].shape[2]\n",
    "n_clusters = len(train_inputs)\n",
    "means_per_cluster = [th.autograd.Variable(th.ones(n_dims), requires_grad=True)\n",
    "                     for _ in range(n_clusters)]\n",
    "# keep in mind this is in log domain so 0 is std 1\n",
    "stds_per_cluster = [th.autograd.Variable(th.zeros(n_dims), requires_grad=True)\n",
    "                    for _ in range(n_clusters)]\n",
    "\n",
    "for i_class in range(n_clusters):\n",
    "    this_outs = feature_model(train_inputs[i_class])\n",
    "    means_per_cluster[i_class].data = th.mean(this_outs, dim=0).view(-1).data\n",
    "    stds_per_cluster[i_class].data = th.log(th.std(this_outs, dim=0),).view(-1).data\n",
    "\n",
    "\n",
    "\n",
    "from copy import deepcopy\n",
    "optimizer = th.optim.Adam(\n",
    "                          [\n",
    "    {'params': list(feature_model.parameters()),\n",
    "    'lr': 1e-3,\n",
    "    'weight_decay': 0},], betas=(0,0.9))\n",
    "\n",
    "optim_dist = th.optim.Adam(\n",
    "                          [\n",
    "    {'params': means_per_cluster + stds_per_cluster,\n",
    "    'lr': 1e-2,\n",
    "    'weight_decay': 0},], betas=(0,0.9))\n",
    "\n",
    "\n",
    "\n",
    "from reversible.gaussian import get_gauss_samples\n",
    "from reversible.uniform import get_uniform_samples\n",
    "\n",
    "from reversible.gaussian import get_gauss_samples\n",
    "from reversible.uniform import get_uniform_samples\n",
    "from reversible.revnet import invert \n",
    "import pandas as pd\n",
    "from gradient_penalty import gradient_penalty\n",
    "import time\n",
    "\n",
    "\n",
    "df = pd.DataFrame()\n",
    "g_loss = np_to_var([np.nan],dtype=np.float32)\n",
    "g_grad = np.nan\n",
    "d_loss = np_to_var([np.nan],dtype=np.float32)\n",
    "d_grad = np.nan\n",
    "gradient_loss = np_to_var([np.nan],dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def invert_hierarchical(features):\n",
    "    return invert(feature_model, features)\n",
    "\n",
    "\n",
    "def get_samples(n_samples, i_class):\n",
    "    mean = means_per_cluster[i_class]\n",
    "    std = th.exp(stds_per_cluster[i_class])\n",
    "    # let's create a mask for the std for now\n",
    "    samples = get_gauss_samples(n_samples, mean, std, truncate_to=3)\n",
    "    return samples\n",
    "import ot\n",
    "from reversible.util import ensure_on_same_device, np_to_var, var_to_np\n",
    "\n",
    "def ot_euclidean_loss_for_samples(samples_a, samples_b):\n",
    "    diffs = samples_a.unsqueeze(1) - samples_b.unsqueeze(0)\n",
    "    diffs = th.sqrt(th.clamp(th.sum(diffs * diffs, dim=2), min=1e-6))\n",
    "\n",
    "    transport_mat = ot.emd([], [], var_to_np(diffs))\n",
    "    # sometimes weird low values, try to prevent them\n",
    "    transport_mat = transport_mat * (transport_mat > (1.0/(diffs.numel())))\n",
    "\n",
    "    transport_mat = np_to_var(transport_mat, dtype=np.float32)\n",
    "    diffs, transport_mat = ensure_on_same_device(diffs, transport_mat)\n",
    "    loss = th.sum(transport_mat * diffs)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5001\n",
    "rng = RandomState(349384)\n",
    "for i_epoch in range(n_epochs):\n",
    "    start_time = time.time()\n",
    "    optimizer.zero_grad()\n",
    "    optim_dist.zero_grad()\n",
    "    for i_class in range(len(train_inputs)):\n",
    "        this_inputs = train_inputs[i_class]\n",
    "        n_samples = len(this_inputs) * 5\n",
    "        samples = get_samples(n_samples, i_class)\n",
    "        inverted = invert_hierarchical(samples)\n",
    "        g_loss = ot_euclidean_loss_for_samples(this_inputs.view(this_inputs.shape[0],-1),\n",
    "                              inverted.view(inverted.shape[0],-1))\n",
    "        g_loss.backward()\n",
    "    g_grad = np.mean([th.sum(p.grad **2).item() for p in itertools.chain(feature_model.parameters())])\n",
    "    dist_grad = np.mean([th.sum(p.grad **2).item() for p in  means_per_cluster + stds_per_cluster])\n",
    "    optimizer.step()\n",
    "    optim_dist.step()\n",
    "    with th.no_grad():\n",
    "        sample_wd_row = {}\n",
    "        for setname, setinputs in [('train', train_inputs), ('test', test_inputs)]:\n",
    "            for i_class in range(len(setinputs)):\n",
    "                this_inputs = setinputs[i_class]\n",
    "                n_samples = len(this_inputs)\n",
    "                samples = get_samples(n_samples, i_class)\n",
    "                inverted = invert_hierarchical(samples)\n",
    "                in_np = var_to_np(this_inputs).reshape(len(this_inputs), -1)\n",
    "                fake_np = var_to_np(inverted).reshape(len(inverted), -1)\n",
    "                import ot\n",
    "\n",
    "                dist = np.sqrt(np.sum(np.square(in_np[:,None] - fake_np[None]), axis=2))\n",
    "                match_matrix = ot.emd([],[], dist)\n",
    "                cost = np.sum(dist * match_matrix)\n",
    "                sample_wd_row.update({\n",
    "                    setname + '_sampled_wd' + str(i_class): cost,\n",
    "                })\n",
    "        end_time = time.time()\n",
    "        epoch_row = {\n",
    "        'g_loss': g_loss.item(),\n",
    "        'g_grad': g_grad,\n",
    "        'dist_grad': dist_grad,\n",
    "        'runtime': end_time -start_time,}\n",
    "        epoch_row.update(sample_wd_row)\n",
    "        df = df.append(epoch_row, ignore_index=True)\n",
    "        if i_epoch % (max(1,n_epochs // 20)) == 0:\n",
    "            display_text(\"Epoch {:d}\".format(i_epoch))\n",
    "            display(df.iloc[-5:])\n",
    "        if i_epoch % (n_epochs // 20) == 0:\n",
    "            print(\"stds\\n\", var_to_np(th.exp(th.stack(stds_per_cluster))))\n",
    "            fig = plt.figure(figsize=(8,4))\n",
    "            plt.plot(var_to_np(th.exp(th.stack(stds_per_cluster))).squeeze().T)\n",
    "            plt.title(\"Standard deviation\\nper dimension\")\n",
    "            display(fig)\n",
    "            plt.close(fig)\n",
    "            \n",
    "            \n",
    "            fig = plt.figure(figsize=(8,4))\n",
    "            set_inputs = train_inputs\n",
    "            for i_class in range(len(set_inputs)):\n",
    "                ins = var_to_np(set_inputs[i_class].squeeze())\n",
    "                bps = np.abs(np.fft.rfft(ins.squeeze()))\n",
    "                plt.plot(np.fft.rfftfreq(ins.squeeze().shape[1], d=1/ins.squeeze().shape[1]), np.median(bps, axis=0))\n",
    "\n",
    "                n_samples = 5000\n",
    "                samples = get_samples(n_samples, i_class)\n",
    "                inverted = var_to_np(invert_hierarchical(samples).squeeze())\n",
    "                bps = np.abs(np.fft.rfft(inverted.squeeze()))\n",
    "                plt.plot(np.fft.rfftfreq(inverted.squeeze().shape[1], d=1/ins.squeeze().shape[1]), np.median(bps, axis=0),\n",
    "                        color=seaborn.color_palette()[i_class], ls='--')\n",
    "            plt.title(\"Spectrum\")\n",
    "            plt.xlabel('Frequency [Hz]')\n",
    "\n",
    "            plt.ylabel('Amplitude')\n",
    "            plt.legend(['Real Right', 'Fake Right', 'Real Rest', 'Fake Rest'])\n",
    "            display(fig)\n",
    "            plt.close(fig)\n",
    "            \n",
    "            set_inputs = train_inputs\n",
    "            for i_class in range(len(set_inputs)):\n",
    "                fig = plt.figure(figsize=(5,5))\n",
    "                mean = means_per_cluster[i_class]\n",
    "                log_std = stds_per_cluster[i_class]\n",
    "                std = th.exp(log_std)\n",
    "                y = np_to_var([i_class])\n",
    "                n_samples = 5000\n",
    "                samples = get_samples(n_samples, i_class)\n",
    "                inverted = var_to_np(invert_hierarchical(samples).squeeze())\n",
    "                plt.plot(inverted.squeeze()[:,0], inverted.squeeze()[:,1],\n",
    "                         ls='', marker='o', color=seaborn.color_palette()[i_class + 2], alpha=0.5, markersize=2)\n",
    "                plt.plot(var_to_np(set_inputs[i_class].squeeze())[:,0], var_to_np(set_inputs[i_class].squeeze())[:,1],\n",
    "                         ls='', marker='o', color=seaborn.color_palette()[i_class])\n",
    "\n",
    "                display(fig)\n",
    "                plt.close(fig)\n",
    "                fig = plt.figure(figsize=(8,3))\n",
    "                plt.plot(inverted[:1000].T, color=seaborn.color_palette()[0],lw=0.5);\n",
    "                display(fig)\n",
    "                plt.close(fig)\n",
    "                \n",
    "                i_dims = np.argsort(var_to_np(stds_per_cluster[0]))[::-1][:2]\n",
    "\n",
    "                with th.no_grad():\n",
    "                    mean = means_per_cluster[i_class]\n",
    "                    std = th.exp(stds_per_cluster[i_class])\n",
    "                    samples = get_samples(5000, i_class)\n",
    "                    outs = feature_model(set_inputs[i_class])\n",
    "                fig = plt.figure(figsize=(3,3))\n",
    "                plt.plot(var_to_np(samples)[:,i_dims[0]].squeeze(),\n",
    "                         var_to_np(samples)[:,i_dims[1]].squeeze(), marker='o', ls='')\n",
    "                plt.plot(var_to_np(outs)[:,i_dims[0]].squeeze(),\n",
    "                         var_to_np(outs)[:,i_dims[1]].squeeze(), marker='o', ls='')\n",
    "                plt.legend([\"Fake\", \"Real\"])\n",
    "                display(fig)\n",
    "                plt.close(fig)\n",
    "            i_dims = (np.argsort(np.max(var_to_np(th.stack(stds_per_cluster)), axis=0))[::-1][:4])\n",
    "            set_inputs = train_inputs\n",
    "            for i_dim in i_dims:\n",
    "                display_text(\"Dimension {:d}\".format(i_dim))\n",
    "                examples_per_class = []\n",
    "                outs_per_class = []\n",
    "                for i_class in range(len(set_inputs)):\n",
    "                    mean = means_per_cluster[i_class]\n",
    "                    std = th.exp(stds_per_cluster[i_class])\n",
    "                    i_f_vals = th.linspace((mean[i_dim] - 2 * std[i_dim]).item(),\n",
    "                                           (mean[i_dim] +  2 *std[i_dim]).item(), 21)\n",
    "                    examples = mean.clone().repeat(len(i_f_vals), 1)\n",
    "                    examples.data[:,i_dim] = i_f_vals.data\n",
    "                    examples_per_class.append(examples)\n",
    "                    outs_per_class.append(feature_model(set_inputs[i_class]))\n",
    "                #display_text([\"Right\", \"Rest\"][i_class])\n",
    "                fig, axes = plt.subplots(1,2, figsize=(6,3), sharex=True, sharey=True)\n",
    "                for i_class in range(len(set_inputs)):\n",
    "                    from matplotlib import rcParams, cycler\n",
    "                    cmap = plt.cm.coolwarm\n",
    "                    N = len(examples)\n",
    "                    examples = examples_per_class[i_class]\n",
    "                    axes[i_class].plot(var_to_np(outs_per_class[i_class])[:,i_dim].squeeze(),\n",
    "                                       var_to_np(outs_per_class[i_class])[:,i_dim].squeeze() * 0 - 0.01,\n",
    "                                      ls='', marker='o', alpha=0.25, markersize=3,\n",
    "                                      color=seaborn.color_palette()[i_class])\n",
    "                    axes[i_class].scatter(var_to_np(examples)[:,i_dim].squeeze(),\n",
    "                                          var_to_np(examples)[:,i_dim].squeeze() * 0,\n",
    "                       c=cmap(np.linspace(0, 1, N)))\n",
    "                    if i_class == 0:\n",
    "                        axes[i_class].set_title(\"Latent space:\")\n",
    "\n",
    "                display(fig)\n",
    "                plt.close(fig)\n",
    "                with plt.rc_context({'axes.prop_cycle': cycler(color=cmap(np.linspace(0, 1, N)))}):\n",
    "                    fig, axes = plt.subplots(1,2, figsize=(16,3), sharex=True, sharey=True)\n",
    "                    for i_class in range(len(examples_per_class)):\n",
    "                        inverted = invert_hierarchical(examples_per_class[i_class])\n",
    "                        axes[i_class].plot(var_to_np(inverted).squeeze().T);\n",
    "                    display(fig)\n",
    "                    plt.close(fig)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5001\n",
    "rng = RandomState(349384)\n",
    "for i_epoch in range(n_epochs):\n",
    "    start_time = time.time()\n",
    "    optimizer.zero_grad()\n",
    "    optim_dist.zero_grad()\n",
    "    for i_class in range(len(train_inputs)):\n",
    "        this_inputs = train_inputs[i_class]\n",
    "        n_samples = len(this_inputs) * 5\n",
    "        samples = get_samples(n_samples, i_class)\n",
    "        inverted = invert_hierarchical(samples)\n",
    "        g_loss = ot_euclidean_loss_for_samples(this_inputs.view(this_inputs.shape[0],-1),\n",
    "                              inverted.view(inverted.shape[0],-1))\n",
    "        g_loss.backward()\n",
    "    g_grad = np.mean([th.sum(p.grad **2).item() for p in itertools.chain(feature_model.parameters())])\n",
    "    dist_grad = np.mean([th.sum(p.grad **2).item() for p in  means_per_cluster + stds_per_cluster])\n",
    "    optimizer.step()\n",
    "    optim_dist.step()\n",
    "    with th.no_grad():\n",
    "        sample_wd_row = {}\n",
    "        for setname, setinputs in [('train', train_inputs), ('test', test_inputs)]:\n",
    "            for i_class in range(len(setinputs)):\n",
    "                this_inputs = setinputs[i_class]\n",
    "                n_samples = len(this_inputs)\n",
    "                samples = get_samples(n_samples, i_class)\n",
    "                inverted = invert_hierarchical(samples)\n",
    "                in_np = var_to_np(this_inputs).reshape(len(this_inputs), -1)\n",
    "                fake_np = var_to_np(inverted).reshape(len(inverted), -1)\n",
    "                import ot\n",
    "\n",
    "                dist = np.sqrt(np.sum(np.square(in_np[:,None] - fake_np[None]), axis=2))\n",
    "                match_matrix = ot.emd([],[], dist)\n",
    "                cost = np.sum(dist * match_matrix)\n",
    "                sample_wd_row.update({\n",
    "                    setname + '_sampled_wd' + str(i_class): cost,\n",
    "                })\n",
    "        end_time = time.time()\n",
    "        epoch_row = {\n",
    "        'g_loss': g_loss.item(),\n",
    "        'g_grad': g_grad,\n",
    "        'dist_grad': dist_grad,\n",
    "        'runtime': end_time -start_time,}\n",
    "        epoch_row.update(sample_wd_row)\n",
    "        df = df.append(epoch_row, ignore_index=True)\n",
    "        if i_epoch % (max(1,n_epochs // 20)) == 0:\n",
    "            display_text(\"Epoch {:d}\".format(i_epoch))\n",
    "            display(df.iloc[-5:])\n",
    "        if i_epoch % (n_epochs // 20) == 0:\n",
    "            print(\"stds\\n\", var_to_np(th.exp(th.stack(stds_per_cluster))))\n",
    "            fig = plt.figure(figsize=(8,4))\n",
    "            plt.plot(var_to_np(th.exp(th.stack(stds_per_cluster))).squeeze().T)\n",
    "            plt.title(\"Standard deviation\\nper dimension\")\n",
    "            display(fig)\n",
    "            plt.close(fig)\n",
    "            \n",
    "            \n",
    "            fig = plt.figure(figsize=(8,4))\n",
    "            set_inputs = train_inputs\n",
    "            for i_class in range(len(set_inputs)):\n",
    "                ins = var_to_np(set_inputs[i_class].squeeze())\n",
    "                bps = np.abs(np.fft.rfft(ins.squeeze()))\n",
    "                plt.plot(np.fft.rfftfreq(ins.squeeze().shape[1], d=1/ins.squeeze().shape[1]), np.median(bps, axis=0))\n",
    "\n",
    "                n_samples = 5000\n",
    "                samples = get_samples(n_samples, i_class)\n",
    "                inverted = var_to_np(invert_hierarchical(samples).squeeze())\n",
    "                bps = np.abs(np.fft.rfft(inverted.squeeze()))\n",
    "                plt.plot(np.fft.rfftfreq(inverted.squeeze().shape[1], d=1/ins.squeeze().shape[1]), np.median(bps, axis=0),\n",
    "                        color=seaborn.color_palette()[i_class], ls='--')\n",
    "            plt.title(\"Spectrum\")\n",
    "            plt.xlabel('Frequency [Hz]')\n",
    "\n",
    "            plt.ylabel('Amplitude')\n",
    "            plt.legend(['Real Right', 'Fake Right', 'Real Rest', 'Fake Rest'])\n",
    "            display(fig)\n",
    "            plt.close(fig)\n",
    "            \n",
    "            set_inputs = train_inputs\n",
    "            for i_class in range(len(set_inputs)):\n",
    "                fig = plt.figure(figsize=(5,5))\n",
    "                mean = means_per_cluster[i_class]\n",
    "                log_std = stds_per_cluster[i_class]\n",
    "                std = th.exp(log_std)\n",
    "                y = np_to_var([i_class])\n",
    "                n_samples = 5000\n",
    "                samples = get_samples(n_samples, i_class)\n",
    "                inverted = var_to_np(invert_hierarchical(samples).squeeze())\n",
    "                plt.plot(inverted.squeeze()[:,0], inverted.squeeze()[:,1],\n",
    "                         ls='', marker='o', color=seaborn.color_palette()[i_class + 2], alpha=0.5, markersize=2)\n",
    "                plt.plot(var_to_np(set_inputs[i_class].squeeze())[:,0], var_to_np(set_inputs[i_class].squeeze())[:,1],\n",
    "                         ls='', marker='o', color=seaborn.color_palette()[i_class])\n",
    "\n",
    "                display(fig)\n",
    "                plt.close(fig)\n",
    "                fig = plt.figure(figsize=(8,3))\n",
    "                plt.plot(inverted[:1000].T, color=seaborn.color_palette()[0],lw=0.5);\n",
    "                display(fig)\n",
    "                plt.close(fig)\n",
    "                \n",
    "                i_dims = np.argsort(var_to_np(stds_per_cluster[0]))[::-1][:2]\n",
    "\n",
    "                with th.no_grad():\n",
    "                    mean = means_per_cluster[i_class]\n",
    "                    std = th.exp(stds_per_cluster[i_class])\n",
    "                    samples = get_samples(5000, i_class)\n",
    "                    outs = feature_model(set_inputs[i_class])\n",
    "                fig = plt.figure(figsize=(3,3))\n",
    "                plt.plot(var_to_np(samples)[:,i_dims[0]].squeeze(),\n",
    "                         var_to_np(samples)[:,i_dims[1]].squeeze(), marker='o', ls='')\n",
    "                plt.plot(var_to_np(outs)[:,i_dims[0]].squeeze(),\n",
    "                         var_to_np(outs)[:,i_dims[1]].squeeze(), marker='o', ls='')\n",
    "                plt.legend([\"Fake\", \"Real\"])\n",
    "                display(fig)\n",
    "                plt.close(fig)\n",
    "            i_dims = (np.argsort(np.max(var_to_np(th.stack(stds_per_cluster)), axis=0))[::-1][:4])\n",
    "            set_inputs = train_inputs\n",
    "            for i_dim in i_dims:\n",
    "                display_text(\"Dimension {:d}\".format(i_dim))\n",
    "                examples_per_class = []\n",
    "                outs_per_class = []\n",
    "                for i_class in range(len(set_inputs)):\n",
    "                    mean = means_per_cluster[i_class]\n",
    "                    std = th.exp(stds_per_cluster[i_class])\n",
    "                    i_f_vals = th.linspace((mean[i_dim] - 2 * std[i_dim]).item(),\n",
    "                                           (mean[i_dim] +  2 *std[i_dim]).item(), 21)\n",
    "                    examples = mean.clone().repeat(len(i_f_vals), 1)\n",
    "                    examples.data[:,i_dim] = i_f_vals.data\n",
    "                    examples_per_class.append(examples)\n",
    "                    outs_per_class.append(feature_model(set_inputs[i_class]))\n",
    "                #display_text([\"Right\", \"Rest\"][i_class])\n",
    "                fig, axes = plt.subplots(1,2, figsize=(6,3), sharex=True, sharey=True)\n",
    "                for i_class in range(len(set_inputs)):\n",
    "                    from matplotlib import rcParams, cycler\n",
    "                    cmap = plt.cm.coolwarm\n",
    "                    N = len(examples)\n",
    "                    examples = examples_per_class[i_class]\n",
    "                    axes[i_class].plot(var_to_np(outs_per_class[i_class])[:,i_dim].squeeze(),\n",
    "                                       var_to_np(outs_per_class[i_class])[:,i_dim].squeeze() * 0 - 0.01,\n",
    "                                      ls='', marker='o', alpha=0.25, markersize=3,\n",
    "                                      color=seaborn.color_palette()[i_class])\n",
    "                    axes[i_class].scatter(var_to_np(examples)[:,i_dim].squeeze(),\n",
    "                                          var_to_np(examples)[:,i_dim].squeeze() * 0,\n",
    "                       c=cmap(np.linspace(0, 1, N)))\n",
    "                    if i_class == 0:\n",
    "                        axes[i_class].set_title(\"Latent space:\")\n",
    "\n",
    "                display(fig)\n",
    "                plt.close(fig)\n",
    "                with plt.rc_context({'axes.prop_cycle': cycler(color=cmap(np.linspace(0, 1, N)))}):\n",
    "                    fig, axes = plt.subplots(1,2, figsize=(16,3), sharex=True, sharey=True)\n",
    "                    for i_class in range(len(examples_per_class)):\n",
    "                        inverted = invert_hierarchical(examples_per_class[i_class])\n",
    "                        axes[i_class].plot(var_to_np(inverted).squeeze().T);\n",
    "                    display(fig)\n",
    "                    plt.close(fig)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
