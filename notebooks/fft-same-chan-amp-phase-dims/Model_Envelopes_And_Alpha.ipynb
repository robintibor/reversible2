{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import os\n",
    "import site\n",
    "os.sys.path.insert(0, '/home/schirrmr/code/reversible/reversible2/')\n",
    "os.sys.path.insert(0, '/home/schirrmr/braindecode/code/braindecode/')\n",
    "os.sys.path.insert(0, '/home/schirrmr/code/explaining/reversible//')\n",
    "%cd /home/schirrmr/\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import logging\n",
    "log = logging.getLogger()\n",
    "log.setLevel('INFO')\n",
    "import sys\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s : %(message)s',\n",
    "                     level=logging.INFO, stream=sys.stdout)\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'png'\n",
    "matplotlib.rcParams['figure.figsize'] = (12.0, 1.0)\n",
    "matplotlib.rcParams['font.size'] = 14\n",
    "import seaborn\n",
    "seaborn.set_style('darkgrid')\n",
    "\n",
    "from reversible.sliced import sliced_from_samples\n",
    "\n",
    "from numpy.random import RandomState\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import copy\n",
    "import math\n",
    "\n",
    "import itertools\n",
    "from reversible.plot import create_bw_image\n",
    "import torch as th\n",
    "from braindecode.torch_ext.util import np_to_var, var_to_np\n",
    "from reversible.revnet import ResidualBlock, invert, SubsampleSplitter, ViewAs, ReversibleBlockOld\n",
    "from spectral_norm import spectral_norm\n",
    "from conv_spectral_norm import conv_spectral_norm\n",
    "\n",
    "def display_text(text, fontsize=18):\n",
    "    fig = plt.figure(figsize=(12,0.1))\n",
    "    plt.title(text, fontsize=fontsize)\n",
    "    plt.axis('off')\n",
    "    display(fig)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from braindecode.datasets.bbci import BBCIDataset\n",
    "from braindecode.mne_ext.signalproc import mne_apply\n",
    "# we loaded all sensors to always get same cleaning results independent of sensor selection\n",
    "# There is an inbuilt heuristic that tries to use only EEG channels and that definitely\n",
    "# works for datasets in our paper\n",
    "#train_loader = BBCIDataset('/data/schirrmr/schirrmr/HGD-public/reduced/train/13.mat')\n",
    "#test_loader = BBCIDataset('/data/schirrmr/schirrmr/HGD-public/reduced/test/13.mat')\n",
    "start_cnt = BBCIDataset('/data/schirrmr/schirrmr/HGD-public/reduced/train/4.mat',).load()\n",
    "start_cnt = start_cnt.drop_channels(['STI 014'])\n",
    "def car(a):\n",
    "    return a - np.mean(a, keepdims=True, axis=0)\n",
    "\n",
    "start_cnt = mne_apply(\n",
    "    car, start_cnt)\n",
    "\n",
    "start_cnt = start_cnt.reorder_channels(['C3', 'C4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from braindecode.datautil.trial_segment import create_signal_target_from_raw_mne\n",
    "\n",
    "marker_def = OrderedDict([('Right Hand', [1]), ('Left Hand', [2],),\n",
    "                         ('Rest', [3]), ('Feet', [4])])\n",
    "ival = [500,1500]\n",
    "from braindecode.mne_ext.signalproc import mne_apply, resample_cnt\n",
    "from braindecode.datautil.signalproc import exponential_running_standardize, bandpass_cnt\n",
    "\n",
    "log.info(\"Resampling train...\")\n",
    "cnt = resample_cnt(start_cnt, 250.0)\n",
    "log.info(\"Standardizing train...\")\n",
    "cnt = mne_apply(lambda a: exponential_running_standardize(a.T ,factor_new=1e-3, init_block_size=1000, eps=1e-4).T,\n",
    "                     cnt)\n",
    "cnt = resample_cnt(cnt, 32.0)\n",
    "cnt = resample_cnt(cnt, 64.0)\n",
    "#cnt = mne_apply(\n",
    "#    lambda a: bandpass_cnt(a, 0, 2, cnt.info['sfreq'],\n",
    "#                           filt_order=10,\n",
    "#                           axis=1), cnt)\n",
    "\n",
    "train_set = create_signal_target_from_raw_mne(cnt, marker_def, ival)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_right = train_set.X[train_set.y == 0]\n",
    "\n",
    "x_rest = train_set.X[train_set.y == 2]\n",
    "\n",
    "inputs_a = np_to_var(x_right[:160,0:1,:,None], dtype=np.float32)\n",
    "\n",
    "inputs_b = np_to_var(x_rest[:160,0:1,:,None], dtype=np.float32)\n",
    "inputs = [inputs_a, inputs_b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnt_bandpassed =  mne_apply(\n",
    "    lambda a: bandpass_cnt(a, 8, 13, cnt.info['sfreq'],\n",
    "                           filt_order=10,\n",
    "                           axis=1), cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha_set = create_signal_target_from_raw_mne(cnt_bandpassed, marker_def, ival)\n",
    "x_alpha_right = alpha_set.X[alpha_set.y == 0]\n",
    "\n",
    "x_alpha_rest = alpha_set.X[alpha_set.y == 2]\n",
    "\n",
    "alpha_a = np_to_var(x_alpha_right[:160,0:1,:,None], dtype=np.float32)\n",
    "\n",
    "alpha_b = np_to_var(x_alpha_rest[:160,0:1,:,None], dtype=np.float32)\n",
    "inputs_alpha = [alpha_a, alpha_b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.signal import hilbert\n",
    "alpha_env_right = np.abs(hilbert(x_alpha_right))\n",
    "alpha_env_rest = np.abs(hilbert(x_alpha_rest))\n",
    "\n",
    "env_a = np_to_var(alpha_env_right[:160,0:1,:,None], dtype=np.float32)\n",
    "\n",
    "env_b = np_to_var(alpha_env_rest[:160,0:1,:,None], dtype=np.float32)\n",
    "inputs_env = [env_a, env_b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(80,4, figsize=(14,80), sharex=True, sharey=True)\n",
    "for i_class in range(len(inputs)):\n",
    "    for i_example in range(len(inputs_env[i_class])):\n",
    "        i_row = i_example // 2\n",
    "        i_col = i_example % 2\n",
    "        i_col += i_class * 2\n",
    "        axes[i_row][i_col].plot(var_to_np(inputs_env[i_class][i_example]).squeeze(),\n",
    "                               color=seaborn.color_palette()[i_class])\n",
    "fig.suptitle('Input signals', y=0.9)\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "lines = [Line2D([0], [0], color=seaborn.color_palette()[i_class],) for i_class in range(2)]\n",
    "labels = ['Right', 'Rest',]\n",
    "axes[0][-1].legend(lines, labels, bbox_to_anchor=(1,1,0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from hierarchical_gaussian import sample_hierarchically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from reversible.gaussian import get_gauss_samples\n",
    "\n",
    "def sample_hierarchically(n_samples, mean, log_stds):\n",
    "    cur_mean = mean\n",
    "    cur_log_std = log_std\n",
    "    samples = th.zeros((n_samples, len(cur_mean)), dtype=th.float32)\n",
    "    covs = th.zeros((len(cur_mean), len(cur_mean)), dtype=th.float32)\n",
    "    for i_exp in range(int(np.log2(len(cur_mean))) + 1):\n",
    "        cur_mean = th.stack(th.chunk(cur_mean, int(2**i_exp)))\n",
    "        this_mean = th.mean(cur_mean, dim=1, keepdim=True)\n",
    "        cur_mean = cur_mean - this_mean\n",
    "        cur_mean = cur_mean.view(-1)\n",
    "        this_log_std = log_stds[i_exp]\n",
    "        # sample...\n",
    "        this_samples = get_gauss_samples(n_samples, this_mean.squeeze(-1), th.exp(this_log_std).squeeze(-1))\n",
    "        samples += this_samples.view(-1).repeat(\n",
    "            len(cur_mean) // int(2**i_exp),1).t().contiguous().view(samples.shape)\n",
    "        # compute cov matrix\n",
    "        for i_part in range(2 ** i_exp):\n",
    "            i_1, i_2 = int((i_part/2**i_exp) * len(covs)), int(((i_part+1)/2**i_exp) * len(covs))\n",
    "            covs[i_1:i_2, i_1:i_2] += (th.exp(this_log_std[i_part]) ** 2)\n",
    "    return samples, covs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean = means_per_cluster[i_class]\n",
    "log_stds = stds_per_cluster[i_class]\n",
    "samples, covs = sample_hierarchically(320, mean, log_stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from reversible.util import set_random_seeds\n",
    "set_random_seeds(2019011641, True)\n",
    "n_clusters = len(inputs)\n",
    "n_dims = inputs[0].shape[2]\n",
    "means_per_cluster = [th.autograd.Variable(th.ones(n_dims), requires_grad=True)\n",
    "                     for _ in range(n_clusters)]\n",
    "\n",
    "\n",
    "# keep in mind this is in log domain so 0 is std 1\n",
    "stds_per_cluster = [[th.zeros(2 ** i_exp, requires_grad=True) for i_exp in range(int(np.log2(len(mean))) + 1)]\n",
    "                    for _ in range(n_clusters)]\n",
    "\n",
    "import itertools\n",
    "\n",
    "\n",
    "\n",
    "optimizer = th.optim.Adam(means_per_cluster + list(itertools.chain(*stds_per_cluster)),\n",
    "                          lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 2000\n",
    "for i_epoch in range(n_epochs):\n",
    "    i_class = 0\n",
    "    this_ins = inputs_env[i_class].squeeze()\n",
    "    mean = means_per_cluster[i_class]\n",
    "    log_stds = stds_per_cluster[i_class]\n",
    "    samples, covs = sample_hierarchically(2*320, mean, log_stds)\n",
    "    sliced_loss = sliced_from_samples(this_ins, samples, 10, None)\n",
    "    optimizer.zero_grad()\n",
    "    sliced_loss.backward()\n",
    "    optimizer.step()\n",
    "    if i_epoch % (n_epochs // 20) == 0:\n",
    "        display_text(\"Sliced loss {:.2f}\".format(sliced_loss))\n",
    "        denominator = th.mm(th.sqrt(th.diag(covs)).unsqueeze(1), th.sqrt(th.diag(covs)).unsqueeze(0))\n",
    "        corrs = covs / denominator\n",
    "        corrs = var_to_np(corrs)\n",
    "        fig = plt.figure(figsize=(3,3))\n",
    "        plt.imshow(corrs, vmin=-1, vmax=1, cmap=cm.coolwarm)\n",
    "        cbar = plt.colorbar()\n",
    "        cbar.set_label(\"Correlation\")\n",
    "        display(fig)\n",
    "        plt.close(fig)\n",
    "        fig = plt.figure(figsize=(3,3))\n",
    "        plt.imshow(var_to_np(covs), cmap=cm.Reds, vmin=0)\n",
    "        cbar = plt.colorbar()\n",
    "        cbar.set_label(\"Covariance\")\n",
    "        display(fig)\n",
    "        plt.close(fig)\n",
    "        \n",
    "        fig = plt.figure(figsize=(8,3))\n",
    "        plt.plot(var_to_np(samples[:3]).T)\n",
    "        display(fig)\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from reversible.util import set_random_seeds\n",
    "set_random_seeds(2019011641, True)\n",
    "n_clusters = len(inputs)\n",
    "n_dims = inputs[0].shape[2] // 2\n",
    "means_per_cluster = [th.autograd.Variable(th.ones(n_dims), requires_grad=True)\n",
    "                     for _ in range(n_clusters)]\n",
    "\n",
    "\n",
    "# keep in mind this is in log domain so 0 is std 1\n",
    "stds_per_cluster = [[th.zeros(2 ** i_exp, requires_grad=True) for i_exp in range(int(np.log2(len(mean))) + 1)]\n",
    "                    for _ in range(n_clusters)]\n",
    "\n",
    "import itertools\n",
    "\n",
    "\n",
    "\n",
    "optimizer = th.optim.Adam(means_per_cluster + list(itertools.chain(*stds_per_cluster)),\n",
    "                          lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 2000\n",
    "for i_epoch in range(n_epochs):\n",
    "    i_class = 0\n",
    "    this_ins = inputs_env[i_class].squeeze()\n",
    "    mean = means_per_cluster[i_class]\n",
    "    log_stds = stds_per_cluster[i_class]\n",
    "    samples, covs = sample_hierarchically(2*320, mean, log_stds)\n",
    "    samples = nn.functional.interpolate(samples.unsqueeze(1).unsqueeze(3),size=(64,1),\n",
    "                                        mode='bilinear', align_corners=False).squeeze()\n",
    "    sliced_loss = sliced_from_samples(this_ins, samples, 10, None)\n",
    "    optimizer.zero_grad()\n",
    "    sliced_loss.backward()\n",
    "    optimizer.step()\n",
    "    if i_epoch % (n_epochs // 20) == 0:\n",
    "        display_text(\"Sliced loss {:.2f}\".format(sliced_loss))\n",
    "        denominator = th.mm(th.sqrt(th.diag(covs)).unsqueeze(1), th.sqrt(th.diag(covs)).unsqueeze(0))\n",
    "        corrs = covs / denominator\n",
    "        corrs = var_to_np(corrs)\n",
    "        fig = plt.figure(figsize=(3,3))\n",
    "        plt.imshow(corrs, vmin=-1, vmax=1, cmap=cm.coolwarm)\n",
    "        cbar = plt.colorbar()\n",
    "        cbar.set_label(\"Correlation\")\n",
    "        display(fig)\n",
    "        plt.close(fig)\n",
    "        fig = plt.figure(figsize=(3,3))\n",
    "        plt.imshow(var_to_np(covs), cmap=cm.Reds, vmin=0)\n",
    "        cbar = plt.colorbar()\n",
    "        cbar.set_label(\"Covariance\")\n",
    "        display(fig)\n",
    "        plt.close(fig)\n",
    "        \n",
    "        fig = plt.figure(figsize=(8,3))\n",
    "        plt.plot(var_to_np(samples[:3]).T)\n",
    "        display(fig)\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add alpha rhythm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_in_samples(n_samples):\n",
    "    samples, covs = sample_hierarchically(n_samples, mean, log_stds)\n",
    "    interpolated = nn.functional.interpolate(samples.unsqueeze(1).unsqueeze(3),size=(64,1),\n",
    "                                        mode='bilinear', align_corners=False).squeeze()\n",
    "\n",
    "    phase = th.rand(n_samples) * 2 * np.pi\n",
    "    step = 64 / (2*np.pi * freq)\n",
    "    timecourses = interpolated\n",
    "    template = th.sin((th.linspace(0,63,64) * step).unsqueeze(0) + phase.unsqueeze(1))\n",
    "    examples = template  * timecourses \n",
    "    return examples, covs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from reversible.util import set_random_seeds\n",
    "set_random_seeds(2019011641, True)\n",
    "n_clusters = len(inputs)\n",
    "n_dims = inputs[0].shape[2] // 2\n",
    "means_per_cluster = [th.autograd.Variable(th.ones(n_dims), requires_grad=True)\n",
    "                     for _ in range(n_clusters)]\n",
    "\n",
    "\n",
    "# keep in mind this is in log domain so 0 is std 1\n",
    "stds_per_cluster = [[th.zeros(2 ** i_exp, requires_grad=True) for i_exp in range(int(np.log2(len(mean))) + 1)]\n",
    "                    for _ in range(n_clusters)]\n",
    "\n",
    "import itertools\n",
    "\n",
    "\n",
    "freq = th.ones(1, dtype=th.float32, requires_grad=True)\n",
    "freq.data[0] = 10\n",
    "\n",
    "optimizer = th.optim.Adam(means_per_cluster + list(itertools.chain(*stds_per_cluster)) + [freq],\n",
    "                          lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 2000\n",
    "for i_epoch in range(n_epochs):\n",
    "    i_class = 0\n",
    "    this_ins = inputs_alpha[i_class].squeeze()\n",
    "    mean = means_per_cluster[i_class]\n",
    "    log_stds = stds_per_cluster[i_class]\n",
    "    n_samples = 2*320\n",
    "    examples, covs = create_in_samples(n_samples)\n",
    "    sliced_loss = sliced_from_samples(this_ins, examples, 10, None)\n",
    "    optimizer.zero_grad()\n",
    "    sliced_loss.backward()\n",
    "    optimizer.step()\n",
    "    if i_epoch % (n_epochs // 20) == 0:\n",
    "        display_text(\"Sliced loss {:.2f}\".format(sliced_loss))\n",
    "        denominator = th.mm(th.sqrt(th.diag(covs)).unsqueeze(1), th.sqrt(th.diag(covs)).unsqueeze(0))\n",
    "        corrs = covs / denominator\n",
    "        corrs = var_to_np(corrs)\n",
    "        fig = plt.figure(figsize=(3,3))\n",
    "        plt.imshow(corrs, vmin=-1, vmax=1, cmap=cm.coolwarm)\n",
    "        cbar = plt.colorbar()\n",
    "        cbar.set_label(\"Correlation\")\n",
    "        display(fig)\n",
    "        plt.close(fig)\n",
    "        fig = plt.figure(figsize=(3,3))\n",
    "        plt.imshow(var_to_np(covs), cmap=cm.Reds, vmin=0)\n",
    "        cbar = plt.colorbar()\n",
    "        cbar.set_label(\"Covariance\")\n",
    "        display(fig)\n",
    "        plt.close(fig)\n",
    "        \n",
    "        fig = plt.figure(figsize=(8,3))\n",
    "        plt.plot(var_to_np(examples[:3]).T)\n",
    "        display(fig)\n",
    "        plt.close(fig)\n",
    "        n_samples = 3200\n",
    "        in_samples = var_to_np(create_in_samples(n_samples)[0]).squeeze()\n",
    "\n",
    "        this_ins = var_to_np(inputs_alpha[i_class].squeeze())\n",
    "\n",
    "        diffs = this_ins[:,None] - in_samples[None]\n",
    "\n",
    "        diffs = np.sqrt(np.sum(np.square(diffs), axis=-1))\n",
    "\n",
    "        import ot\n",
    "        coupling = ot.emd([],[], diffs)\n",
    "        mask = coupling > (1/(2*len(in_samples)))\n",
    "        assert np.sum(mask)  == len(in_samples)\n",
    "        argmaxes = np.argmax(mask, axis=0)\n",
    "\n",
    "\n",
    "        fig, axes = plt.subplots(10,4, figsize=(16,20), sharex=True, sharey=True)\n",
    "        for i_in, ax in enumerate(axes.flatten()):\n",
    "            i_samples = np.nonzero(argmaxes == i_in)\n",
    "            ax.plot(in_samples[i_samples].T, color=seaborn.color_palette()[0], lw=0.5)\n",
    "            ax.plot(this_ins[i_in], color='black')\n",
    "        display(fig)\n",
    "        plt.close(fig)\n",
    "        display([th.exp(s) for s in log_stds])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(np.cov(var_to_np(inputs_env[0].squeeze()).T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(np.cov(var_to_np(inputs_env[0].squeeze()).T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(np.cov(var_to_np(inputs_env[0].squeeze()).T), vmin=-0.7, vmax=0.7,\n",
    "           cmap=cm.coolwarm)\n",
    "\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label(\"Covariance\")\n",
    "cbar.set_ticks([0,0.5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(np.corrcoef(var_to_np(inputs_env[0].squeeze()).T), vmin=-1, vmax=1,\n",
    "           cmap=cm.coolwarm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_to_np(this_std).repeat(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_to_np(inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from matplotlib import rcParams, cycler\n",
    "cmap = plt.cm.copper\n",
    "N = int(np.log2(len(mean))) + 1\n",
    "plt.figure(figsize=(8,5))\n",
    "with plt.rc_context({'axes.prop_cycle': cycler(color=cmap(np.linspace(0., 1, N)))}):\n",
    "    with seaborn.axes_style(\"whitegrid\"):\n",
    "        for i_exp in range(int(np.log2(len(mean))) + 1):\n",
    "            this_std = th.exp(log_stds[i_exp])\n",
    "            inds = np.arange(0,32,32 / 2**i_exp)\n",
    "            inds = inds.repeat(2)\n",
    "            inds[0::2] -= 0.1\n",
    "            inds = np.append(inds, 32)\n",
    "            inds = inds[1:]\n",
    "            plt.plot(inds, var_to_np(this_std).repeat(2), lw=3-i_exp*0.4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.exp(log_stds[i_exp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(var_to_np(mean))\n",
    "plt.plot(np.mean(var_to_np(inputs_env[0]), axis=0).squeeze()[::2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,4))\n",
    "plt.plot(var_to_np(this_ins[:10]).T, color=seaborn.color_palette()[0], lw=0.5)\n",
    "plt.plot(var_to_np(samples[:10]).T, color=seaborn.color_palette()[1], lw=0.5)\n",
    "display(fig)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(var_to_np(this_ins)[:3].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(var_to_np(mean))\n",
    "plt.plot(np.mean(var_to_np(this_ins), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur_mean = th.randn(64)#np_to_var([0,2,0,5], dtype=np.float32)\n",
    "cur_log_std = th.randn(64)#np_to_var([2,3,1,0.5], dtype=np.float32)\n",
    "n_samples = 2000\n",
    "samples, covs = sample_hierarchically(n_samples, cur_mean, cur_log_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(var_to_np(covs), cmap=cm.Reds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denominator = th.mm(th.sqrt(th.diag(covs)).unsqueeze(1), th.sqrt(th.diag(covs)).unsqueeze(0))\n",
    "\n",
    "corrs = covs / denominator\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(corrs, vmin=-1, vmax=1, cmap=cm.coolwarm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cur_mean = th.randn(64)#np_to_var([0,2,0,5], dtype=np.float32)\n",
    "cur_log_std = th.randn(64)#np_to_var([2,3,1,0.5], dtype=np.float32)\n",
    "n_samples = 2000\n",
    "samples = th.zeros((n_samples, len(cur_mean)), dtype=th.float32)\n",
    "covs = th.zeros((len(cur_mean), len(cur_mean)), dtype=th.float32)\n",
    "\n",
    "for i_exp in range(int(np.log2(len(cur_mean))) + 1):\n",
    "    cur_mean = th.stack(th.chunk(cur_mean, int(2**i_exp)))\n",
    "    this_mean = th.mean(cur_mean, dim=1, keepdim=True)\n",
    "    cur_mean = cur_mean - this_mean\n",
    "    cur_mean = cur_mean.view(-1)\n",
    "    cur_log_std = th.stack(th.chunk(cur_log_std, int(2**i_exp)))\n",
    "    this_log_std = th.mean(cur_log_std, dim=1, keepdim=True)\n",
    "    cur_log_std = cur_log_std - this_log_std\n",
    "    cur_log_std = cur_log_std.view(-1)\n",
    "    # sample...\n",
    "    this_samples = get_gauss_samples(n_samples, this_mean.squeeze(-1), th.exp(this_log_std).squeeze(-1))\n",
    "    samples += this_samples.view(-1).repeat(\n",
    "        len(cur_mean) // int(2**i_exp),1).t().contiguous().view(samples.shape)\n",
    "    # compute cov matrix\n",
    "    for i_part in range(2 ** i_exp):\n",
    "        i_1, i_2 = int((i_part/2**i_exp) * len(covs)), int(((i_part+1)/2**i_exp) * len(covs))\n",
    "        covs[i_1:i_2, i_1:i_2] += (th.exp(this_log_std.squeeze(-1)[i_part]) ** 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(var_to_np(covs), cmap=cm.Reds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denominator = th.mm(th.sqrt(th.diag(covs)).unsqueeze(1), th.sqrt(th.diag(covs)).unsqueeze(0))\n",
    "\n",
    "corrs = covs / denominator\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(corrs, vmin=-1, vmax=1, cmap=cm.coolwarm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.min(corrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emp_covs = np.cov(var_to_np(samples).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_covs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.mean(samples, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "covs = np.cov(var_to_np(samples).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(covs, vmin=0, vmax=3, cmap=cm.Reds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_mean = means_per_cluster[0]\n",
    "i_exp = 0\n",
    "for i_exp in range(int(np.log2(len(mean)))):\n",
    "    cur_mean = th.stack(th.chunk(cur_mean, int(2**i_exp)))\n",
    "\n",
    "    this_mean = th.mean(cur_mean, dim=1, keepdim=True)\n",
    "    print(this_mean)\n",
    "    # sample...\n",
    "    cur_mean = cur_mean - this_mean\n",
    "    print(cur_mean.shape)\n",
    "    cur_mean = cur_mean.view(-1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_samples = get_gauss_samples(3, th.mean(this_mean, dim=1), th.exp(th.mean(this_log_std, dim=1)), truncate_to=3)\n",
    "\n",
    "this_samples.repeat((1,64))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
