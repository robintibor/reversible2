{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import os\n",
    "import site\n",
    "os.sys.path.insert(0, '/home/schirrmr/code/reversible/reversible2/')\n",
    "os.sys.path.insert(0, '/home/schirrmr/braindecode/code/braindecode/')\n",
    "os.sys.path.insert(0, '/home/schirrmr/code/explaining/reversible//')\n",
    "%cd /home/schirrmr/\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import logging\n",
    "log = logging.getLogger()\n",
    "log.setLevel('INFO')\n",
    "import sys\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s : %(message)s',\n",
    "                     level=logging.INFO, stream=sys.stdout)\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'png'\n",
    "matplotlib.rcParams['figure.figsize'] = (12.0, 1.0)\n",
    "matplotlib.rcParams['font.size'] = 14\n",
    "import seaborn\n",
    "seaborn.set_style('darkgrid')\n",
    "\n",
    "from reversible.sliced import sliced_from_samples\n",
    "\n",
    "from numpy.random import RandomState\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import copy\n",
    "import math\n",
    "\n",
    "import itertools\n",
    "from reversible.plot import create_bw_image\n",
    "import torch as th\n",
    "from braindecode.torch_ext.util import np_to_var, var_to_np\n",
    "from reversible.revnet import ResidualBlock, invert, SubsampleSplitter, ViewAs, ReversibleBlockOld\n",
    "from spectral_norm import spectral_norm\n",
    "from conv_spectral_norm import conv_spectral_norm\n",
    "\n",
    "def display_text(text, fontsize=18):\n",
    "    fig = plt.figure(figsize=(12,0.1))\n",
    "    plt.title(text, fontsize=fontsize)\n",
    "    plt.axis('off')\n",
    "    display(fig)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rng = RandomState(20190401)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i freq\n",
    "# amp_level\n",
    "inputs =  []\n",
    "\n",
    "for i_class, freq_amps  in enumerate((((2,6), (8,4)), ((2,4), (8,6)))):\n",
    "    fft_coefs = np.zeros((300, 33), dtype=np.complex64)\n",
    "    for i_freq, amp in freq_amps:\n",
    "        amps = np.abs(rng.randn(300) + amp)\n",
    "        phases = rng.rand(300) * 2 * np.pi - np.pi\n",
    "        this_fft_coefs_a = amps * np.exp(phases * 1j)\n",
    "        fft_coefs[:,i_freq] = this_fft_coefs_a\n",
    "        \n",
    "    signals = np.fft.irfft(fft_coefs, norm='ortho')\n",
    "    inputs.append(np_to_var(signals, dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def th_angle(x,y):\n",
    "    # yes reverse oder to (y,x)...\n",
    "    return th.atan2(y, x)\n",
    "\n",
    "\n",
    "def th_amp(x,y):\n",
    "    return th.sqrt((x * x) + (y * y))\n",
    "\n",
    "class AmplitudePhaseFFT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AmplitudePhaseFFT, self).__init__()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        expanded = th.cat(\n",
    "            (inputs[:, :1], th.zeros(inputs.shape[0], 1, device=inputs.device),\n",
    "             inputs[:, 1:], th.zeros(inputs.shape[0], 1, device=inputs.device)),\n",
    "            dim=1)\n",
    "        unfolded = expanded.view(expanded.shape[0], expanded.shape[1] // 2, 2)\n",
    "        \n",
    "        x = unfolded.transpose(len(unfolded.shape)-1,0)[0].transpose(\n",
    "            len(unfolded.shape) - 2,0)\n",
    "        y = unfolded.transpose(len(unfolded.shape)-1,0)[1].transpose(\n",
    "            len(unfolded.shape) - 2,0)\n",
    "        \n",
    "        amps = th_amp(x, y)\n",
    "        phases = th_angle(x, y)\n",
    "        \n",
    "        return th.stack((amps, phases), dim=-1)\n",
    "    \n",
    "    def invert(self, out):\n",
    "        amps = out.transpose(len(out.shape) - 1,0)[0].transpose(\n",
    "            len(out.shape) - 2,0)\n",
    "        phases = out.transpose(len(out.shape) - 1,0)[1].transpose(\n",
    "            len(out.shape) - 2,0)\n",
    "        x = th.cos(phases)\n",
    "        y = th.sin(phases)\n",
    "        x_y = th.stack((x,y), dim=-1)\n",
    "        x_y = x_y * amps.unsqueeze(-1)\n",
    "        flattened = x_y.view(x_y.shape[0], -1)\n",
    "        reduced = th.cat((flattened[:, :1], flattened[:, 2:-1]), dim=1)\n",
    "        return reduced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from rfft import RFFT, Interleave\n",
    "from discriminator import ProjectionDiscriminator\n",
    "from reversible.revnet import SubsampleSplitter, ViewAs\n",
    "from reversible.util import set_random_seeds\n",
    "from reversible.revnet import init_model_params\n",
    "from torch.nn import ConstantPad2d\n",
    "import torch as th\n",
    "from conv_spectral_norm import conv_spectral_norm\n",
    "from disttransform import DistTransformResNet\n",
    "\n",
    "feature_model = nn.Sequential(RFFT(),\n",
    "                              AmplitudePhaseFFT())\n",
    "\n",
    "\n",
    "outs = feature_model(inputs[0])\n",
    "\n",
    "ins = invert(feature_model, outs)\n",
    "\n",
    "th.mean(np.abs(ins - inputs[0]))\n",
    "\n",
    "from ot_exact import ot_euclidean_loss_for_samples\n",
    "\n",
    "train_inputs = inputs\n",
    "test_inputs = inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from rfft import RFFT, Interleave\n",
    "from discriminator import ProjectionDiscriminator\n",
    "from reversible.revnet import SubsampleSplitter, ViewAs\n",
    "from reversible.util import set_random_seeds\n",
    "from reversible.revnet import init_model_params\n",
    "from torch.nn import ConstantPad2d\n",
    "import torch as th\n",
    "from conv_spectral_norm import conv_spectral_norm\n",
    "from disttransform import DistTransformResNet\n",
    "\n",
    "\n",
    "set_random_seeds(2019011641, True)\n",
    "\n",
    "feature_model = nn.Sequential(RFFT(),\n",
    "                              AmplitudePhaseFFT())\n",
    "\n",
    "from reversible.training import hard_init_std_mean\n",
    "n_dims = train_inputs[0].shape[1]\n",
    "n_clusters = len(train_inputs)\n",
    "means_per_cluster = [th.autograd.Variable(th.ones(n_dims), requires_grad=True)\n",
    "                     for _ in range(n_clusters)]\n",
    "# keep in mind this is in log domain so 0 is std 1\n",
    "stds_per_cluster = [th.autograd.Variable(th.zeros(n_dims), requires_grad=True)\n",
    "                    for _ in range(n_clusters)]\n",
    "\n",
    "for i_class in range(n_clusters):\n",
    "    this_outs = feature_model(train_inputs[i_class])\n",
    "    means_per_cluster[i_class].data = th.mean(this_outs, dim=0).view(-1).data\n",
    "    stds_per_cluster[i_class].data = th.log(th.std(this_outs, dim=0),).view(-1).data\n",
    "\n",
    "\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "optim_dist = th.optim.Adam(\n",
    "                          [\n",
    "    {'params': means_per_cluster + stds_per_cluster,\n",
    "    'lr': 1e-2,\n",
    "    'weight_decay': 0},], betas=(0,0.9))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from reversible.gaussian import get_gauss_samples\n",
    "from reversible.uniform import get_uniform_samples\n",
    "\n",
    "from reversible.gaussian import get_gauss_samples\n",
    "from reversible.uniform import get_uniform_samples\n",
    "from reversible.revnet import invert \n",
    "import pandas as pd\n",
    "from gradient_penalty import gradient_penalty\n",
    "import time\n",
    "\n",
    "\n",
    "df = pd.DataFrame()\n",
    "g_loss = np_to_var([np.nan],dtype=np.float32)\n",
    "g_grad = np.nan\n",
    "d_loss = np_to_var([np.nan],dtype=np.float32)\n",
    "d_grad = np.nan\n",
    "gradient_loss = np_to_var([np.nan],dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def invert_hierarchical(features):\n",
    "    return invert(feature_model, features)\n",
    "\n",
    "\n",
    "def get_samples(n_samples, i_class):\n",
    "    mean = means_per_cluster[i_class]\n",
    "    std = th.exp(stds_per_cluster[i_class])\n",
    "    # let's create a mask for the std for now\n",
    "    samples_amp = get_gauss_samples(n_samples, mean[::2], std[::2], truncate_to=3)\n",
    "    samples_phase = get_uniform_samples(n_samples, mean.detach()[1::2] * 0, std.detach()[1::2] * 0 + 2* np.pi,)\n",
    "    samples = th.stack((samples_amp, samples_phase), dim=-1)\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1001\n",
    "rng = RandomState(349384)\n",
    "for i_epoch in range(n_epochs):\n",
    "    start_time = time.time()\n",
    "    optim_dist.zero_grad()\n",
    "    for i_class in range(len(train_inputs)):\n",
    "        this_inputs = train_inputs[i_class]\n",
    "        n_samples = len(this_inputs) * 5\n",
    "        samples = get_samples(n_samples, i_class)\n",
    "        inverted = invert_hierarchical(samples)\n",
    "        g_loss = ot_euclidean_loss_for_samples(this_inputs.view(this_inputs.shape[0],-1),\n",
    "                              inverted.view(inverted.shape[0],-1))\n",
    "        g_loss.backward()\n",
    "    g_grad = np.mean([th.sum(p.grad **2).item() for p in itertools.chain(feature_model.parameters())])\n",
    "    dist_grad = np.mean([th.sum(p.grad **2).item() for p in  means_per_cluster + stds_per_cluster])\n",
    "    optim_dist.step()\n",
    "    with th.no_grad():\n",
    "        sample_wd_row = {}\n",
    "        for setname, setinputs in [('train', train_inputs), ('test', test_inputs)]:\n",
    "            for i_class in range(len(setinputs)):\n",
    "                this_inputs = setinputs[i_class]\n",
    "                n_samples = len(this_inputs)\n",
    "                samples = get_samples(n_samples, i_class)\n",
    "                inverted = invert_hierarchical(samples)\n",
    "                in_np = var_to_np(this_inputs).reshape(len(this_inputs), -1)\n",
    "                fake_np = var_to_np(inverted).reshape(len(inverted), -1)\n",
    "                import ot\n",
    "\n",
    "                dist = np.sqrt(np.sum(np.square(in_np[:,None] - fake_np[None]), axis=2))\n",
    "                match_matrix = ot.emd([],[], dist)\n",
    "                cost = np.sum(dist * match_matrix)\n",
    "                sample_wd_row.update({\n",
    "                    setname + '_sampled_wd' + str(i_class): cost,\n",
    "                })\n",
    "        end_time = time.time()\n",
    "        epoch_row = {\n",
    "        'g_loss': g_loss.item(),\n",
    "        'g_grad': g_grad,\n",
    "        'dist_grad': dist_grad,\n",
    "        'runtime': end_time -start_time,}\n",
    "        epoch_row.update(sample_wd_row)\n",
    "        df = df.append(epoch_row, ignore_index=True)\n",
    "        if i_epoch % (max(1,n_epochs // 20)) == 0:\n",
    "            display_text(\"Epoch {:d}\".format(i_epoch))\n",
    "            display(df.iloc[-5:])\n",
    "        if i_epoch % (n_epochs // 20) == 0:\n",
    "            print(\"stds\\n\", var_to_np(th.exp(th.stack(stds_per_cluster))))\n",
    "            fig = plt.figure(figsize=(8,4))\n",
    "            plt.plot(var_to_np(th.exp(th.stack(stds_per_cluster))).squeeze().T)\n",
    "            plt.title(\"Standard deviation\\nper dimension\")\n",
    "            display(fig)\n",
    "            plt.close(fig)\n",
    "            \n",
    "            \n",
    "            fig = plt.figure(figsize=(8,4))\n",
    "            set_inputs = train_inputs\n",
    "            for i_class in range(len(set_inputs)):\n",
    "                ins = var_to_np(set_inputs[i_class].squeeze())\n",
    "                bps = np.abs(np.fft.rfft(ins.squeeze()))\n",
    "                plt.plot(np.fft.rfftfreq(ins.squeeze().shape[1], d=1/ins.squeeze().shape[1]), np.median(bps, axis=0))\n",
    "\n",
    "                n_samples = 5000\n",
    "                samples = get_samples(n_samples, i_class)\n",
    "                inverted = var_to_np(invert_hierarchical(samples).squeeze())\n",
    "                bps = np.abs(np.fft.rfft(inverted.squeeze()))\n",
    "                plt.plot(np.fft.rfftfreq(inverted.squeeze().shape[1], d=1/ins.squeeze().shape[1]), np.median(bps, axis=0),\n",
    "                        color=seaborn.color_palette()[i_class], ls='--')\n",
    "            plt.title(\"Spectrum\")\n",
    "            plt.xlabel('Frequency [Hz]')\n",
    "\n",
    "            plt.ylabel('Amplitude')\n",
    "            plt.legend(['Real Right', 'Fake Right', 'Real Rest', 'Fake Rest'])\n",
    "            display(fig)\n",
    "            plt.close(fig)\n",
    "            \n",
    "            i_dims = (np.argsort(np.max(var_to_np(th.stack(stds_per_cluster)), axis=0))[::-1][:4])\n",
    "            set_inputs = train_inputs\n",
    "            for i_dim in i_dims:\n",
    "                display_text(\"Dimension {:d}\".format(i_dim))\n",
    "                examples_per_class = []\n",
    "                outs_per_class = []\n",
    "                for i_class in range(2):\n",
    "                    mean = means_per_cluster[i_class]\n",
    "                    std = th.exp(stds_per_cluster[i_class])\n",
    "                    i_f_vals = th.linspace((mean[i_dim] - 2 * std[i_dim]).item(),\n",
    "                                           (mean[i_dim] +  2 *std[i_dim]).item(), 21)\n",
    "                    examples = mean.repeat(len(i_f_vals), 1)\n",
    "                    examples.data[:,i_dim] = i_f_vals.data\n",
    "                    examples_per_class.append(examples.view(-1,33,2))\n",
    "                    outs_per_class.append(feature_model(set_inputs[i_class]))\n",
    "                #display_text([\"Right\", \"Rest\"][i_class])\n",
    "                fig, axes = plt.subplots(1,2, figsize=(6,3), sharex=True, sharey=True)\n",
    "                for i_class in range(len(train_inputs)):\n",
    "                    from matplotlib import rcParams, cycler\n",
    "                    cmap = plt.cm.coolwarm\n",
    "                    N = len(examples)\n",
    "                    examples = examples_per_class[i_class]\n",
    "                    axes[i_class].plot(var_to_np(outs_per_class[i_class])[:,i_dim//2, i_dim%2].squeeze(),\n",
    "                                       var_to_np(outs_per_class[i_class])[:,i_dim//2, i_dim%2].squeeze() * 0 - 0.01,\n",
    "                                      ls='', marker='o', alpha=0.25, markersize=3,\n",
    "                                      color=seaborn.color_palette()[i_class])\n",
    "                    axes[i_class].scatter(var_to_np(examples)[:,i_dim//2, i_dim%2].squeeze(),\n",
    "                                          var_to_np(examples)[:,i_dim//2, i_dim%2].squeeze() * 0,\n",
    "                       c=cmap(np.linspace(0, 1, N)))\n",
    "                    if i_class == 0:\n",
    "                        axes[i_class].set_title(\"Latent space:\")\n",
    "\n",
    "                display(fig)\n",
    "                plt.close(fig)\n",
    "                with plt.rc_context({'axes.prop_cycle': cycler(color=cmap(np.linspace(0, 1, N)))}):\n",
    "                    fig, axes = plt.subplots(1,2, figsize=(16,3), sharex=True, sharey=True)\n",
    "                    for i_class in range(2):\n",
    "                        inverted = invert_hierarchical(examples_per_class[i_class])\n",
    "                        axes[i_class].plot(var_to_np(inverted).squeeze().T);\n",
    "                    display(fig)\n",
    "                    plt.close(fig)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4.5,2))\n",
    "plt.plot(np.sin(np.linspace(0,8*np.pi, 64, endpoint=False)))\n",
    "plt.title(\"Faster sine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4.5,2))\n",
    "\n",
    "plt.plot(np.sin(np.linspace(0,2*np.pi, 64, endpoint=False)))\n",
    "plt.title(\"Slower sine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_dims = (np.argsort(np.max(var_to_np(th.stack(stds_per_cluster)), axis=0)[::2])[::-1][:4]) * 2\n",
    "set_inputs = train_inputs\n",
    "for i_dim in i_dims:\n",
    "    display_text(\"Dimension {:d}\".format(i_dim))\n",
    "    examples_per_class = []\n",
    "    outs_per_class = []\n",
    "    for i_class in range(2):\n",
    "        mean = means_per_cluster[i_class]\n",
    "        std = th.exp(stds_per_cluster[i_class])\n",
    "        i_f_vals = th.linspace((mean[i_dim] - 2 * std[i_dim]).item(),\n",
    "                               (mean[i_dim] +  2 *std[i_dim]).item(), 21)\n",
    "        examples = mean.repeat(len(i_f_vals), 1)\n",
    "        examples.data[:,i_dim] = i_f_vals.data\n",
    "        examples_per_class.append(examples.view(-1,33,2))\n",
    "        outs_per_class.append(feature_model(set_inputs[i_class]))\n",
    "    #display_text([\"Right\", \"Rest\"][i_class])\n",
    "    fig, axes = plt.subplots(1,2, figsize=(6,3), sharex=True, sharey=True)\n",
    "    for i_class in range(len(train_inputs)):\n",
    "        from matplotlib import rcParams, cycler\n",
    "        cmap = plt.cm.coolwarm\n",
    "        N = len(examples)\n",
    "        examples = examples_per_class[i_class]\n",
    "        axes[i_class].plot(var_to_np(outs_per_class[i_class])[:,i_dim//2, i_dim%2].squeeze(),\n",
    "                           var_to_np(outs_per_class[i_class])[:,i_dim//2, i_dim%2].squeeze() * 0 - 0.01,\n",
    "                          ls='', marker='o', alpha=0.25, markersize=3,\n",
    "                          color=seaborn.color_palette()[i_class])\n",
    "        axes[i_class].scatter(var_to_np(examples)[:,i_dim//2, i_dim%2].squeeze(),\n",
    "                              var_to_np(examples)[:,i_dim//2, i_dim%2].squeeze() * 0,\n",
    "           c=cmap(np.linspace(0, 1, N)))\n",
    "        if i_class == 0:\n",
    "            axes[i_class].set_title(\"Latent space:\")\n",
    "\n",
    "    display(fig)\n",
    "    plt.close(fig)\n",
    "    with plt.rc_context({'axes.prop_cycle': cycler(color=cmap(np.linspace(0, 1, N)))}):\n",
    "        fig, axes = plt.subplots(1,2, figsize=(16,3), sharex=True, sharey=True)\n",
    "        for i_class in range(2):\n",
    "            inverted = invert_hierarchical(examples_per_class[i_class])\n",
    "            axes[i_class].plot(var_to_np(inverted).squeeze().T);\n",
    "        axes[0].set_title(\"Class A\")\n",
    "        axes[1].set_title(\"Class B\")\n",
    "        display(fig)\n",
    "        plt.close(fig)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_diff = means_per_cluster[1] - means_per_cluster[0]\n",
    "mean_diff.data[1::2] = 0 # phase is same\n",
    "plt.plot(var_to_np(mean_diff));\n",
    "\n",
    "n_samples = 5\n",
    "samples_A = get_samples(n_samples,0)\n",
    "\n",
    "samples_B_amps = samples_A[:,:,0] + mean_diff[::2].unsqueeze(0)\n",
    "samples_B = th.stack((samples_B_amps, samples_A[:,:,1]), dim=-1)\n",
    "\n",
    "in_A = invert_hierarchical(samples_A)\n",
    "in_B = invert_hierarchical(samples_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(n_samples,2, figsize=(12,n_samples * 2), sharex=True, sharey=True);\n",
    "for i_row in range(len(axes)):\n",
    "    for i_col in range(len(axes[i_row])):\n",
    "        ax = axes[i_row][i_col]\n",
    "        if i_col == 0:\n",
    "            ax.plot(var_to_np(in_A[i_row]).squeeze())\n",
    "        else:\n",
    "            ax.plot(var_to_np(in_B[i_row]).squeeze())\n",
    "axes[0][0].set_title(\"Class A\")\n",
    "axes[0][1].set_title(\"Class B\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(var_to_np(th.stack(means_per_cluster)).T);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(var_to_np(th.exp(th.stack(stds_per_cluster))).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stds_per_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
