{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import os\n",
    "import site\n",
    "os.sys.path.insert(0, '/home/schirrmr/code/reversible/reversible2/')\n",
    "os.sys.path.insert(0, '/home/schirrmr/braindecode/code/braindecode/')\n",
    "os.sys.path.insert(0, '/home/schirrmr/code/explaining/reversible//')\n",
    "%cd /home/schirrmr/\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import logging\n",
    "log = logging.getLogger()\n",
    "log.setLevel('INFO')\n",
    "import sys\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s : %(message)s',\n",
    "                     level=logging.INFO, stream=sys.stdout)\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'png'\n",
    "matplotlib.rcParams['figure.figsize'] = (12.0, 1.0)\n",
    "matplotlib.rcParams['font.size'] = 14\n",
    "import seaborn\n",
    "seaborn.set_style('darkgrid')\n",
    "\n",
    "from reversible.sliced import sliced_from_samples\n",
    "\n",
    "from numpy.random import RandomState\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import copy\n",
    "import math\n",
    "\n",
    "import itertools\n",
    "from reversible.plot import create_bw_image\n",
    "import torch as th\n",
    "from braindecode.torch_ext.util import np_to_var, var_to_np\n",
    "from reversible.revnet import ResidualBlock, invert, SubsampleSplitter, ViewAs, ReversibleBlockOld\n",
    "from spectral_norm import spectral_norm\n",
    "from conv_spectral_norm import conv_spectral_norm\n",
    "\n",
    "def display_text(text, fontsize=18):\n",
    "    fig = plt.figure(figsize=(12,0.1))\n",
    "    plt.title(text, fontsize=fontsize)\n",
    "    plt.axis('off')\n",
    "    display(fig)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from braindecode.datasets.bbci import BBCIDataset\n",
    "\n",
    "# we loaded all sensors to always get same cleaning results independent of sensor selection\n",
    "# There is an inbuilt heuristic that tries to use only EEG channels and that definitely\n",
    "# works for datasets in our paper\n",
    "#train_loader = BBCIDataset('/data/schirrmr/schirrmr/HGD-public/reduced/train/13.mat')\n",
    "#test_loader = BBCIDataset('/data/schirrmr/schirrmr/HGD-public/reduced/test/13.mat')\n",
    "cnt = BBCIDataset('/data/schirrmr/schirrmr/HGD-public/reduced/train/4.mat',).load()\n",
    "cnt = cnt.drop_channels(['STI 014'])\n",
    "\n",
    "def car(a):\n",
    "    return a - np.mean(a, keepdims=True, axis=0)\n",
    "\n",
    "cnt = mne_apply(\n",
    "    car, cnt)\n",
    "\n",
    "cnt = cnt.reorder_channels(['C3', 'C4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from braindecode.datautil.trial_segment import create_signal_target_from_raw_mne\n",
    "\n",
    "marker_def = OrderedDict([('Right Hand', [1]), ('Left Hand', [2],),\n",
    "                         ('Rest', [3]), ('Feet', [4])])\n",
    "ival = [500,1500]\n",
    "from braindecode.mne_ext.signalproc import mne_apply, resample_cnt\n",
    "from braindecode.datautil.signalproc import exponential_running_standardize, bandpass_cnt\n",
    "\n",
    "log.info(\"Resampling train...\")\n",
    "cnt = resample_cnt(cnt, 250.0)\n",
    "log.info(\"Standardizing train...\")\n",
    "cnt = mne_apply(lambda a: exponential_running_standardize(a.T ,factor_new=1e-3, init_block_size=1000, eps=1e-4).T,\n",
    "                     cnt)\n",
    "cnt = resample_cnt(cnt, 64.0)\n",
    "cnt = mne_apply(\n",
    "    lambda a: bandpass_cnt(a, 0, 16, cnt.info['sfreq'],\n",
    "                           filt_order=3,\n",
    "                           axis=1), cnt)\n",
    "\n",
    "train_set = create_signal_target_from_raw_mne(cnt, marker_def, ival)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_right = train_set.X[train_set.y == 0]\n",
    "\n",
    "x_rest = train_set.X[train_set.y == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs_a = np_to_var(x_right[:160,0:1,:,None], dtype=np.float32).cuda()\n",
    "\n",
    "inputs_b = np_to_var(x_rest[:160,0:1,:,None], dtype=np.float32).cuda()\n",
    "inputs = [inputs_a, inputs_b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(32,10, figsize=(14,20), sharex=True, sharey=True)\n",
    "for i_class in range(2):\n",
    "    for i_example in range(len(inputs[i_class])):\n",
    "        i_row = i_example // 5\n",
    "        i_col = i_example % 5\n",
    "        i_col += i_class * 5\n",
    "        axes[i_row][i_col].plot(var_to_np(inputs[i_class][i_example]).squeeze(),\n",
    "                               color=seaborn.color_palette()[i_class])\n",
    "fig.suptitle('Input signals')\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "lines = [Line2D([0], [0], color=seaborn.color_palette()[i_class],) for i_class in range(2)]\n",
    "labels = ['Right', 'Rest',]\n",
    "axes[0][-1].legend(lines, labels, bbox_to_anchor=(1,1,0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "plt.figure(figsize=(10,6))\n",
    "for i_class in range(2):\n",
    "    plt.plot(var_to_np(inputs[i_class].squeeze()).T, color=seaborn.color_palette()[i_class],);\n",
    "lines = [Line2D([0], [0], color=seaborn.color_palette()[i_class],) for i_class in range(2)]\n",
    "plt.legend(lines, ['Right', 'Rest',], bbox_to_anchor=(1,1,0,0))\n",
    "plt.title('Input signals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rev_block(n_c, n_i_c):\n",
    "     return ReversibleBlockOld(\n",
    "        nn.Sequential(\n",
    "        nn.Conv2d(n_c // 2, n_i_c,(3,1), stride=1, padding=(1,0),bias=True),\n",
    "        nn.ReLU(),\n",
    "            nn.Conv2d(n_i_c, n_c // 2,(3,1), stride=1, padding=(1,0),bias=True)),\n",
    "         \n",
    "        nn.Sequential(\n",
    "        nn.Conv2d(n_c // 2, n_i_c,(3,1), stride=1, padding=(1,0),bias=True),\n",
    "        nn.ReLU(),\n",
    "            nn.Conv2d(n_i_c, n_c // 2,(3,1), stride=1, padding=(1,0),bias=True))\n",
    "    )\n",
    "    \n",
    "def res_block(n_c, n_i_c):\n",
    "     return ResidualBlock(\n",
    "        nn.Sequential(\n",
    "        nn.Conv2d(n_c, n_i_c, (3,1), stride=1, padding=(1,0),bias=True),\n",
    "        nn.ReLU(),\n",
    "            nn.Conv2d(n_i_c, n_c, (3,1), stride=1, padding=(1,0),bias=True)),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from discriminator import ProjectionDiscriminator\n",
    "from reversible.revnet import SubsampleSplitter, ViewAs\n",
    "from reversible.util import set_random_seeds\n",
    "from reversible.revnet import init_model_params\n",
    "from torch.nn import ConstantPad2d\n",
    "import torch as th\n",
    "from conv_spectral_norm import conv_spectral_norm\n",
    "set_random_seeds(2019011641, True)\n",
    "feature_model = nn.Sequential(\n",
    "    SubsampleSplitter(stride=[2,1],chunk_chans_first=False),\n",
    "    rev_block(2,32),\n",
    "    rev_block(2,32),\n",
    "    SubsampleSplitter(stride=[2,1],chunk_chans_first=False),\n",
    "    rev_block(4,32),\n",
    "    rev_block(4,32),\n",
    "    SubsampleSplitter(stride=[2,1],chunk_chans_first=False),\n",
    "    rev_block(8,32),\n",
    "    rev_block(8,32),\n",
    "    SubsampleSplitter(stride=[2,1],chunk_chans_first=False),\n",
    "    rev_block(16,32),\n",
    "    rev_block(16,32),\n",
    "    SubsampleSplitter(stride=[2,1],chunk_chans_first=False),\n",
    "    rev_block(32,32),\n",
    "    rev_block(32,32),\n",
    "    SubsampleSplitter(stride=[2,1],chunk_chans_first=False),\n",
    "    rev_block(64,32),\n",
    "    rev_block(64,32),\n",
    "    ViewAs((-1,64,1,1), (-1,64))\n",
    ")\n",
    "feature_model.cuda()\n",
    "\n",
    "\n",
    "from braindecode.torch_ext.util import set_random_seeds\n",
    "adv_model = nn.Sequential(\n",
    "    nn.Conv2d(1,16, (3,1), stride=1, padding=(1,0),bias=True),\n",
    "    res_block(16,32),\n",
    "    res_block(16,32),\n",
    "    nn.AvgPool2d((2,1)),\n",
    "    res_block(16,32),\n",
    "    res_block(16,32),\n",
    "    nn.AvgPool2d((2,1)),\n",
    "    res_block(16,32),\n",
    "    res_block(16,32),\n",
    "    nn.AvgPool2d((2,1)),\n",
    "    res_block(16,32),\n",
    "    res_block(16,32),\n",
    "    nn.AvgPool2d((2,1)),\n",
    "    res_block(16,32),\n",
    "    res_block(16,32),\n",
    "    nn.AvgPool2d((2,1)),\n",
    "    res_block(16,32),\n",
    "    res_block(16,32),\n",
    "    ViewAs((-1,16,2,1), (-1,32)),\n",
    "    )\n",
    "\n",
    "from spectral_norm import spectral_norm\n",
    "\n",
    "adv_model = ProjectionDiscriminator(adv_model,32,2,)\n",
    "\n",
    "adv_model.cuda()\n",
    "\n",
    "\n",
    "from reversible.training import hard_init_std_mean\n",
    "n_dims = inputs_b.shape[2]\n",
    "n_clusters = 2\n",
    "means_per_cluster = [th.autograd.Variable(th.ones(n_dims).cuda(), requires_grad=True)\n",
    "                     for _ in range(n_clusters)]\n",
    "# keep in mind this is in log domain so 0 is std 1\n",
    "stds_per_cluster = [th.autograd.Variable(th.zeros(n_dims).cuda(), requires_grad=True)\n",
    "                    for _ in range(n_clusters)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from copy import deepcopy\n",
    "optimizer = th.optim.Adam(\n",
    "                          [\n",
    "    {'params': list(feature_model.parameters()),\n",
    "    'lr': 1e-3,\n",
    "    'weight_decay': 0},], betas=(0,0.9))\n",
    "\n",
    "optim_dist = th.optim.Adam(\n",
    "                          [\n",
    "    {'params': means_per_cluster + stds_per_cluster,\n",
    "    'lr': 1e-2,\n",
    "    'weight_decay': 0},], betas=(0,0.9))\n",
    "\n",
    "\n",
    "optim_adv = th.optim.Adam([{\n",
    "    'params': adv_model.parameters(),\n",
    "    'lr': 4e-3, 'weight_decay': 0.00}],#lr 0.0004\n",
    "                         betas=(0,0.9))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from reversible.gaussian import get_gauss_samples\n",
    "from reversible.uniform import get_uniform_samples\n",
    "\n",
    "def amp_phase_to_x_y(amps, phases):\n",
    "    x, y = th.cos(phases), th.sin(phases)\n",
    "\n",
    "    x = x * amps\n",
    "    y = y * amps\n",
    "    return x, y\n",
    "\n",
    "\n",
    "\n",
    "def get_amp_phase_samples(n_samples, mean, std, truncate_amps_to):\n",
    "    i_half = len(mean) // 2\n",
    "\n",
    "    amps = get_gauss_samples(n_samples, mean[:i_half], std[:i_half], truncate_to=truncate_amps_to)\n",
    "    phases = get_uniform_samples(n_samples, mean[i_half:], std[i_half:] * 2 * np.pi) # then 1 would map to -pi to pi\n",
    "\n",
    "    x, y = amp_phase_to_x_y(amps, phases)\n",
    "\n",
    "    samples = th.cat((x,y), dim=1)\n",
    "    return samples\n",
    "def amp_phase_sample_to_x_y(this_out):\n",
    "    i_half = this_out.shape[1] // 2\n",
    "    x,y = amp_phase_to_x_y(this_out[:,:i_half], this_out[:,i_half:])\n",
    "    return th.cat((x,y,), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from reversible.gaussian import get_gauss_samples\n",
    "from reversible.uniform import get_uniform_samples\n",
    "from reversible.revnet import invert \n",
    "import pandas as pd\n",
    "from gradient_penalty import gradient_penalty\n",
    "import time\n",
    "\n",
    "\n",
    "df = pd.DataFrame()\n",
    "g_loss = np_to_var([np.nan],dtype=np.float32)\n",
    "g_grad = np.nan\n",
    "d_loss = np_to_var([np.nan],dtype=np.float32)\n",
    "d_grad = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10001\n",
    "for i_epoch in range(n_epochs):\n",
    "    start_time = time.time()\n",
    "    optim_adv.zero_grad()\n",
    "    optimizer.zero_grad()\n",
    "    optim_dist.zero_grad()\n",
    "    for i_class in range(len(inputs)):\n",
    "        mean = means_per_cluster[i_class]\n",
    "        std = th.exp(stds_per_cluster[i_class])\n",
    "        this_inputs = inputs[i_class]\n",
    "        y = np_to_var([i_class]).cuda()\n",
    "        samples = get_amp_phase_samples(len(this_inputs), mean, std, truncate_amps_to=3)\n",
    "        inverted = invert(feature_model, samples)\n",
    "        score_fake = adv_model(inverted, y)\n",
    "        if (i_epoch % 10) != 0:\n",
    "            score_real = adv_model(this_inputs, y)\n",
    "            gradient_loss = gradient_penalty(adv_model, this_inputs, inverted[:(len(this_inputs))], y)\n",
    "            d_loss = -score_real.mean() + score_fake.mean() + gradient_loss\n",
    "            d_loss.backward()\n",
    "            d_grad = np.mean([th.sum(p.grad **2).item() for p in adv_model.parameters()])\n",
    "        else:\n",
    "            g_loss = -th.mean(score_fake)\n",
    "            g_loss.backward()\n",
    "            g_grad = np.mean([th.sum(p.grad **2).item() for p in feature_model.parameters()])\n",
    "    if (i_epoch % 10) != 0:\n",
    "            optim_adv.step()\n",
    "    else:\n",
    "        optimizer.step()\n",
    "        optim_dist.step()\n",
    "    sample_wd_row = {}\n",
    "    for i_class in range(len(inputs)):\n",
    "        this_inputs = inputs[i_class]\n",
    "        mean = means_per_cluster[i_class]\n",
    "        std = th.exp(stds_per_cluster[i_class])\n",
    "        y = np_to_var([i_class]).cuda()\n",
    "        samples = get_amp_phase_samples(20, mean, std, truncate_amps_to=3)\n",
    "\n",
    "        inverted = invert(feature_model, samples)\n",
    "        in_np = var_to_np(this_inputs).squeeze()\n",
    "        fake_np = var_to_np(inverted).squeeze()\n",
    "        import ot\n",
    "\n",
    "        dist = np.sum(np.abs(in_np[:,None] - fake_np[None]), axis=2)\n",
    "        match_matrix = ot.emd([],[], dist)\n",
    "        cost = np.sum(dist * match_matrix)\n",
    "        score_fake = adv_model(inverted, y)\n",
    "        score_real = adv_model(inputs[i_class], y)\n",
    "        wd_dist = th.mean(score_real) - th.mean(score_fake)\n",
    "        sample_wd_row.update({\n",
    "            'wd_dist_' + str(i_class): wd_dist.item() ,\n",
    "            'sampled_wd' + str(i_class): cost,\n",
    "            'wd_diff' + str(i_class): cost - wd_dist.item(),\n",
    "        })\n",
    "    end_time = time.time()\n",
    "    epoch_row = {\n",
    "    'd_loss': d_loss.item(),\n",
    "    'g_loss': g_loss.item(),\n",
    "    'o_real': th.mean(score_real).item(),\n",
    "    'o_fake': th.mean(score_fake).item(),\n",
    "    'g_grad': g_grad,\n",
    "    'd_grad': d_grad,\n",
    "    'runtime': end_time -start_time,}\n",
    "    epoch_row.update(sample_wd_row)\n",
    "    df = df.append(epoch_row, ignore_index=True)\n",
    "    if i_epoch % (n_epochs // 20) == 0:\n",
    "        \n",
    "        display_text(\"Epoch {:d}\".format(i_epoch))\n",
    "        display(df.iloc[-5:])\n",
    "        print(\"stds\\n\", var_to_np(th.exp(th.stack(stds_per_cluster))))\n",
    "        for i_class in range(len(stds_per_cluster)):\n",
    "            std = th.exp(stds_per_cluster[i_class])\n",
    "            mean = means_per_cluster[i_class]\n",
    "            i_std_2, i_std_1 = np.argsort(var_to_np(std))[::-1][:2]\n",
    "            feature_a_values = th.linspace(float(mean[i_std_1].data - 2 * std[i_std_1].data),\n",
    "                                   float(mean[i_std_1].data + 2 * std[i_std_1].data), 9)\n",
    "            feature_b_values = th.linspace(float(mean[i_std_2].data - 2 * std[i_std_2].data),\n",
    "                                   float(mean[i_std_2].data + 2 * std[i_std_2].data), 9)\n",
    "            image_grid = np.zeros((len(feature_a_values), len(feature_b_values), inputs[i_class].shape[2]))\n",
    "\n",
    "            for i_f_a_val, f_a_val in enumerate(feature_a_values):\n",
    "                for i_f_b_val, f_b_val in enumerate(feature_b_values):\n",
    "                    this_out = mean.clone()\n",
    "                    this_out.data[i_std_1] = f_a_val\n",
    "                    this_out.data[i_std_2] = f_b_val\n",
    "                    inverted = var_to_np(invert(feature_model, this_out.unsqueeze(0))[0]).squeeze()\n",
    "\n",
    "                    image_grid[i_f_a_val, i_f_b_val] = np.copy(inverted)\n",
    "            fig, axes = plt.subplots(image_grid.shape[0], image_grid.shape[1],\n",
    "                 sharex=True, sharey=True,\n",
    "                figsize=(int(image_grid.shape[0] * 2), int(image_grid.shape[1])))\n",
    "            plt.subplots_adjust(wspace=0, hspace=0)\n",
    "            for ax, curve  in zip(axes.flatten(), image_grid.reshape(-1, image_grid.shape[-1])):\n",
    "                ax.plot(curve)\n",
    "            display(fig)\n",
    "            plt.close(fig)\n",
    "        \n",
    "        fig = plt.figure(figsize=(12,2))\n",
    "        for i_class in range(len(means_per_cluster)):\n",
    "            outs_np = var_to_np(feature_model(inputs[i_class]))\n",
    "            plt.title(\"Std of different dimensions\")\n",
    "            plt.plot(np.std(outs_np, axis=0))\n",
    "            plt.xlabel('Output dimension')\n",
    "        display(fig)\n",
    "        plt.close(fig)\n",
    "        \n",
    "        for i_class in range(len(inputs)):\n",
    "            y = np_to_var([i_class]).cuda()\n",
    "            mean = means_per_cluster[i_class]\n",
    "            std = th.exp(stds_per_cluster[i_class])\n",
    "            this_inputs = inputs[i_class]\n",
    "            samples = get_amp_phase_samples(2000, mean, std, truncate_amps_to=3)\n",
    "\n",
    "            inverted = invert(feature_model, samples)\n",
    "            in_np = var_to_np(this_inputs).squeeze()\n",
    "            fake_np = var_to_np(inverted).squeeze()\n",
    "            import ot\n",
    "\n",
    "            dist = np.sum(np.abs(in_np[:,None] - fake_np[None]), axis=2)\n",
    "            match_matrix = ot.emd([],[], dist)\n",
    "            cost = np.sum(dist * match_matrix)\n",
    "            print(cost)\n",
    "            score_fake = adv_model(inverted, y)\n",
    "            score_real = adv_model(inputs[i_class], y)\n",
    "            wd_dist = th.mean(score_real) - th.mean(score_fake)\n",
    "            print(wd_dist)\n",
    "        fig = plt.figure(figsize=(8,4))\n",
    "        for i_class in range(2):\n",
    "            ins = var_to_np(inputs[i_class].squeeze())\n",
    "            bps = np.abs(np.fft.rfft(ins.squeeze()))\n",
    "            plt.plot(np.fft.rfftfreq(ins.squeeze().shape[1], d=1/ins.squeeze().shape[1]), np.median(bps, axis=0))\n",
    "            mean = means_per_cluster[i_class]\n",
    "            std = th.exp(stds_per_cluster[i_class])\n",
    "            samples = get_amp_phase_samples(5000, mean, std, truncate_amps_to=3)\n",
    "            inverted = var_to_np(invert(feature_model, samples).squeeze())\n",
    "            bps = np.abs(np.fft.rfft(inverted.squeeze()))\n",
    "            plt.plot(np.fft.rfftfreq(inverted.squeeze().shape[1], d=1/ins.squeeze().shape[1]), np.median(bps, axis=0),\n",
    "                    color=seaborn.color_palette()[i_class], ls='--')\n",
    "        plt.title(\"Spectrum\")\n",
    "        plt.xlabel('Frequency [Hz]')\n",
    "\n",
    "        plt.ylabel('Amplitude')\n",
    "        plt.legend(['Real Right', 'Fake Right', 'Real Rest', 'Fake Rest'])\n",
    "        display(fig)\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,4))\n",
    "for i_class in range(2):\n",
    "    ins = var_to_np(inputs[i_class].squeeze())\n",
    "    bps = np.abs(np.fft.rfft(ins.squeeze()))\n",
    "    plt.plot(np.fft.rfftfreq(ins.squeeze().shape[1], d=1/ins.squeeze().shape[1]), np.median(bps, axis=0))\n",
    "    mean = means_per_cluster[i_class]\n",
    "    std = th.exp(stds_per_cluster[i_class])\n",
    "    samples = get_amp_phase_samples(5000, mean, std, truncate_amps_to=3)\n",
    "    inverted = var_to_np(invert(feature_model, samples).squeeze())\n",
    "    bps = np.abs(np.fft.rfft(inverted.squeeze()))\n",
    "    plt.plot(np.fft.rfftfreq(inverted.squeeze().shape[1], d=1/ins.squeeze().shape[1]), np.median(bps, axis=0),\n",
    "            color=seaborn.color_palette()[i_class], ls='--')\n",
    "plt.title(\"Spectrum\")\n",
    "plt.xlabel('Frequency [Hz]')\n",
    "\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend(['Real Right', 'Fake Right', 'Real Rest', 'Fake Rest'])\n",
    "display(fig)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,['sampled_wd0', 'sampled_wd1']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_classes =   len(stds_per_cluster)\n",
    "image_grid = np.zeros((len(std), len(feature_a_values), n_classes, inputs[i_class].shape[2]))\n",
    "for i_class in range(len(stds_per_cluster)):\n",
    "    std = th.exp(stds_per_cluster[i_class])\n",
    "    mean = means_per_cluster[i_class]\n",
    "    for i_std in range(len(std)):\n",
    "        if i_std < len(std) // 2:\n",
    "            feature_a_values = th.linspace(float(mean[i_std].data - 2 * std[i_std].data),\n",
    "                                   float(mean[i_std].data + 2 * std[i_std].data), 9)\n",
    "        else:\n",
    "            feature_a_values = th.linspace(float(mean[i_std].data - 0.5 * std[i_std].data),\n",
    "                                   float(mean[i_std].data + 0.5 * std[i_std].data), 9)\n",
    "            \n",
    "        for i_f_a_val, f_a_val in enumerate(feature_a_values):\n",
    "            this_out = mean.clone()\n",
    "            this_out.data[i_std] = f_a_val\n",
    "            this_out = amp_phase_sample_to_x_y(this_out.unsqueeze(0))\n",
    "            inverted = var_to_np(invert(feature_model, this_out)[0]).squeeze()\n",
    "            image_grid[i_std, i_f_a_val, i_class] = np.copy(inverted)\n",
    "fig, axes = plt.subplots(image_grid.shape[0], image_grid.shape[1],\n",
    "     sharex=True, sharey=True,\n",
    "    figsize=(int(image_grid.shape[1] * 1.5), int(image_grid.shape[0]) * 1.25))\n",
    "plt.subplots_adjust(wspace=0, hspace=0.2)\n",
    "\n",
    "\n",
    "axes[0][-1].legend(['Right', 'Rest'], bbox_to_anchor=[1,1,0,0])\n",
    "from matplotlib.colors import  LinearSegmentedColormap\n",
    "cmap = LinearSegmentedColormap.from_list(\n",
    "        'twoclasses', seaborn.color_palette()[:2][::-1])\n",
    "log_ratios = stds_per_cluster[1] - stds_per_cluster[0]\n",
    "max_abs_log_ratio = var_to_np(th.max(th.abs(log_ratios)))\n",
    "_ , i_sorted_std = th.sort(log_ratios)\n",
    "for i_row, i_std in enumerate(i_sorted_std):\n",
    "    std1 = th.exp(stds_per_cluster[0][i_std]).item()\n",
    "    std2 = th.exp(stds_per_cluster[1][i_std]).item()\n",
    "    log_ratio = stds_per_cluster[0][i_std] - stds_per_cluster[1][i_std]\n",
    "    ratio = th.exp(th.abs(log_ratio)).item()\n",
    "    axes[i_row][0].text(-1000,0,\"{:.1f}\\n{:.1f}\\n{:.1f}\".format(\n",
    "        std1,\n",
    "        std2,\n",
    "        ratio), va='center',color=cmap((log_ratio.item() + max_abs_log_ratio) / (2*max_abs_log_ratio)))\n",
    "    axes[i_row][0].text(-1500,0, \"A\" if i_std < (len(i_sorted_std) // 2) else \"P\")\n",
    "    for i_f_val in range(image_grid.shape[1]):\n",
    "        curves = image_grid[i_std][i_f_val]\n",
    "        for i_class in range(n_classes):\n",
    "            axes[i_row,i_f_val].plot(np.linspace(\n",
    "                0,1000, len(curves[i_class])),\n",
    "                                     curves[i_class], color=seaborn.color_palette()[i_class])\n",
    "\n",
    "axes[0][0].text(-1000,2, \"Stds\\nRatio\")\n",
    "display(fig)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i_class = 1\n",
    "i_std = 63"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "std = th.exp(stds_per_cluster[i_class])\n",
    "mean = means_per_cluster[i_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_a_values = th.linspace(float(mean[i_std].data - 2 * std[i_std].data),\n",
    "                                   float(mean[i_std].data + 2 * std[i_std].data), 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_a_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean[i_std]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std[i_std]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_inverted = []\n",
    "for i_f_a_val, f_a_val in enumerate(feature_a_values):\n",
    "    this_out = mean.clone()\n",
    "    this_out.data[i_std] = f_a_val\n",
    "    this_out = amp_phase_sample_to_x_y(this_out.unsqueeze(0))\n",
    "    inverted = var_to_np(invert(feature_model, this_out)[0]).squeeze()\n",
    "    all_inverted.append(inverted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(all_inverted).T);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_diffs, i_sorted_diffs = th.sort(th.abs(means_per_cluster[1] - means_per_cluster[0]), descending=True)\n",
    "i_sorted_diffs = list(range(len(mean)))\n",
    "fig, axes = plt.subplots(len(sorted_diffs),1, figsize=(8,10), sharex=True, sharey=True)\n",
    "for i_ax, (i_std, diff) in enumerate(zip(i_sorted_diffs, sorted_diffs, )):\n",
    "    midpoint = th.mean(th.stack(means_per_cluster), dim=0)\n",
    "    latents = midpoint.repeat(9,1)\n",
    "\n",
    "    interpolates = th.linspace(means_per_cluster[0][i_std].item(), means_per_cluster[1][i_std].item(), 9)\n",
    "\n",
    "    latents.data[:, i_std] = interpolates\n",
    "\n",
    "    inverted = var_to_np(invert(feature_model, latents)).squeeze()\n",
    "\n",
    "    alphas =np.linspace(0,1,len(inverted))\n",
    "    colors = (1 - alphas)[:,None] * np.array(seaborn.color_palette()[0])[None] + (\n",
    "        alphas[:,None] * np.array(seaborn.color_palette()[1])[None])\n",
    "    \n",
    "    for i_line, line in enumerate(inverted):\n",
    "        axes[i_ax].plot(line, color=colors[i_line])\n",
    "fig.suptitle(\"Interpolating individual dimensions\\ninbetween class means\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 17\n",
    "alphas = th.linspace(-0.5,1.5,n_steps).cuda()\n",
    "mean_dir = means_per_cluster[1] - means_per_cluster[0]\n",
    "\n",
    "vals = means_per_cluster[0].unsqueeze(0) + (alphas.unsqueeze(1) * mean_dir.unsqueeze(0))\n",
    "\n",
    "inverted = invert(feature_model, vals).squeeze()\n",
    "\n",
    "\n",
    "alphas =np.linspace(0,1,len(inverted))\n",
    "colors = (1 - alphas)[:,None] * np.array(seaborn.color_palette()[0])[None] + (\n",
    "    alphas[:,None] * np.array(seaborn.color_palette()[1])[None])\n",
    "plt.figure(figsize=(12,6))\n",
    "for i_line in range(len(colors)):\n",
    "    lw = 0.7\n",
    "    if i_line in [4,17-4]:\n",
    "        lw=2\n",
    "    label = ''\n",
    "    if i_line == 4:\n",
    "        label = 'Right'\n",
    "    elif i_line == (17-4):\n",
    "        label = 'Rest'\n",
    "    plt.plot(var_to_np(inverted)[i_line], color=colors[i_line], lw=lw, label=label);\n",
    "plt.title(\"Morph between two class means\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(var_to_np(invert(feature_model, amp_phase_sample_to_x_y(means_per_cluster[0].unsqueeze(0)))).squeeze())\n",
    "plt.plot(var_to_np(invert(feature_model, amp_phase_sample_to_x_y(means_per_cluster[1].unsqueeze(0)))).squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 17\n",
    "alphas = np.linspace(-0.5,1.5,n_steps)\n",
    "mean_dir = np.mean(var_to_np(inputs[1]).squeeze(), axis=0) - np.mean(var_to_np(inputs[0]).squeeze(), axis=0)\n",
    "\n",
    "inverted = np.mean(var_to_np(inputs[0]).squeeze(), axis=0)[None] + (alphas[:,None] * mean_dir[None])\n",
    "\n",
    "\n",
    "alphas =np.linspace(0,1,len(inverted))\n",
    "colors = (1 - alphas)[:,None] * np.array(seaborn.color_palette()[0])[None] + (\n",
    "    alphas[:,None] * np.array(seaborn.color_palette()[1])[None])\n",
    "plt.figure(figsize=(12,6))\n",
    "for i_line in range(len(colors)):\n",
    "    lw = 0.7\n",
    "    if i_line in [4,17-4]:\n",
    "        lw=2\n",
    "    label = ''\n",
    "    if i_line == 4:\n",
    "        label = 'Right'\n",
    "    elif i_line == (17-4):\n",
    "        label = 'Rest'\n",
    "    plt.plot(inverted[i_line], color=colors[i_line], lw=lw, label=label);\n",
    "plt.title(\"Morph between two class means in input space\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_random_seeds(20180128, True)\n",
    "for i_class in range(2):\n",
    "    mean = means_per_cluster[i_class]\n",
    "    std = th.exp(stds_per_cluster[i_class])\n",
    "    samples = get_amp_phase_samples(5000, mean, std, truncate_amps_to=3)\n",
    "    inverted = var_to_np(invert(feature_model, samples).squeeze())\n",
    "    ins = var_to_np(inputs[i_class].squeeze())\n",
    "\n",
    "    dist_matrix = np.sqrt(np.sum(np.square(ins[:,None] - inverted[None]), axis=2))\n",
    "\n",
    "    coupling = ot.emd([],[], dist_matrix)\n",
    "    fig, axes = plt.subplots(20,8, figsize=(14,16), sharex=True, sharey=True)\n",
    "    for i_in in range(len(ins)):\n",
    "        mask = coupling[i_in] > 1 / (len(inverted) + 1)\n",
    "        matched_samples = inverted[mask]\n",
    "        reference = ins[i_in]\n",
    "        ax = axes.flatten()[i_in]\n",
    "        ax.plot(np.array(matched_samples).T, color=seaborn.color_palette()[0], alpha=0.7, lw=0.75);\n",
    "        ax.plot(reference, color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "for i_class in range(2):\n",
    "    mean = means_per_cluster[i_class]\n",
    "    std = th.exp(stds_per_cluster[i_class])\n",
    "    samples = get_amp_phase_samples(5000, mean, std, truncate_amps_to=3)\n",
    "    inverted = var_to_np(invert(feature_model, samples).squeeze())\n",
    "    ins = var_to_np(inputs[i_class].squeeze())\n",
    "    bps = np.abs(np.fft.rfft(inverted.squeeze()))\n",
    "    plt.plot(np.fft.rfftfreq(inverted.squeeze().shape[1], d=1/ins.squeeze().shape[1]), np.median(bps, axis=0),\n",
    "            color=seaborn.color_palette()[i_class])\n",
    "    bps = np.abs(np.fft.rfft(ins.squeeze()))\n",
    "    plt.plot(np.fft.rfftfreq(ins.squeeze().shape[1], d=1/ins.squeeze().shape[1]), np.median(bps, axis=0), ls='--')\n",
    "plt.title(\"Spectrum\")\n",
    "plt.xlabel('Frequency [Hz]')\n",
    "\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend(['Real Right', 'Fake Right', 'Real Rest', 'Fake Rest'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
