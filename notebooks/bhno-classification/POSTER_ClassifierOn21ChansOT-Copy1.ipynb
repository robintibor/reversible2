{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import importlib\n",
    "importlib.reload(logging) # see https://stackoverflow.com/a/21475297/1469195\n",
    "log = logging.getLogger()\n",
    "log.setLevel('INFO')\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s : %(message)s',\n",
    "                     level=logging.INFO, stream=sys.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import os\n",
    "import site\n",
    "os.sys.path.insert(0, '/home/schirrmr/code/reversible/')\n",
    "os.sys.path.insert(0, '/home/schirrmr/braindecode/code/braindecode/')\n",
    "os.sys.path.insert(0, '/home/schirrmr/code/explaining/reversible//')\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import logging\n",
    "log = logging.getLogger()\n",
    "log.setLevel('INFO')\n",
    "import sys\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s : %(message)s',\n",
    "                     level=logging.INFO, stream=sys.stdout)\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'png'\n",
    "matplotlib.rcParams['figure.figsize'] = (12.0, 1.0)\n",
    "matplotlib.rcParams['font.size'] = 14\n",
    "import seaborn\n",
    "seaborn.set_style('darkgrid')\n",
    "\n",
    "from reversible2.sliced import sliced_from_samples\n",
    "from numpy.random import RandomState\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import copy\n",
    "import math\n",
    "\n",
    "import itertools\n",
    "import torch as th\n",
    "from braindecode.torch_ext.util import np_to_var, var_to_np\n",
    "from reversible2.splitter import SubsampleSplitter\n",
    "\n",
    "from reversible2.view_as import ViewAs\n",
    "\n",
    "from reversible2.affine import AdditiveBlock\n",
    "from reversible2.plot import display_text, display_close\n",
    "from reversible2.bhno import load_file, create_inputs\n",
    "th.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_names = ['Fz', \n",
    "                'FC3','FC1','FCz','FC2','FC4',\n",
    "                'C5','C3','C1','Cz','C2','C4','C6',\n",
    "                'CP3','CP1','CPz','CP2','CP4',\n",
    "                'P1','Pz','P2',\n",
    "                'POz']\n",
    "orig_train_cnt = load_file('/data/schirrmr/schirrmr/HGD-public/reduced/train/4.mat')\n",
    "train_cnt = orig_train_cnt.reorder_channels(sensor_names)\n",
    "\n",
    "train_inputs = create_inputs(train_cnt, final_hz=256, half_before=True,\n",
    "                            start_ms=500, stop_ms=1500)\n",
    "n_split = len(train_inputs[0]) - 40\n",
    "test_inputs = [t[-40:] for t in train_inputs]\n",
    "train_inputs = [t[:-40] for t in train_inputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cuda = True\n",
    "if cuda:\n",
    "    train_inputs = [i.cuda() for i in train_inputs]\n",
    "    test_inputs = [i.cuda() for i in test_inputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_model = th.load('/data/schirrmr/schirrmr/reversible/models/notebooks/21ChansOT/feature_model.pkl')\n",
    "\n",
    "class_dist = th.load('/data/schirrmr/schirrmr/reversible/models/notebooks/21ChansOT/class_dist.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_dist.i_class_inds = [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reversible2.plot import plot_head_signals_tight\n",
    "inverted_per_class = []\n",
    "for i_class in range(2):\n",
    "    samples = class_dist.get_mean_std(i_class)[0].unsqueeze(0)\n",
    "    inverted = feature_model.invert(samples)\n",
    "    inverted_per_class.append(var_to_np(inverted)[0].squeeze())\n",
    "fig = plot_head_signals_tight(np.stack(inverted_per_class, axis=-1), sensor_names=sensor_names,\n",
    "                         figsize=(20,12));\n",
    "ax = plt.gca()\n",
    "\n",
    "fig.legend(ax.get_lines()[:2], [\"Right Hand\", \"Resting State\"], fontsize=24,loc='upper right',\n",
    "          bbox_to_anchor=(0.79,0.81))\n",
    "#plt.savefig('/data/schirrmr/schirrmr/ohbm-rom/bigsignal.png', dpi=300 ,transparent=True,\n",
    "#           bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(var_to_np(class_dist.get_mean_std(1)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from reversible2.plot import plot_head_signals_tight\n",
    "\n",
    "from reversible2.constantmemory import clear_ctx_dicts\n",
    "inverted_per_class = []\n",
    "n_examples = 21\n",
    "for i_class in range(2):\n",
    "    samples = class_dist.get_mean_std(i_class)[0].unsqueeze(0)\n",
    "    samples = samples.repeat(n_examples,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "seaborn.set_context('notebook', font_scale=1.75)\n",
    "\n",
    "mean, std = var_to_np(class_dist.get_mean_std(i_class)[0]), var_to_np(class_dist.get_mean_std(i_class)[1])\n",
    "np.argsort(std)[::-1][:10]\n",
    "\n",
    "for i_i_std in range(5):\n",
    "    samples = class_dist.get_mean_std(i_class)[0].unsqueeze(0)\n",
    "    samples = samples.repeat(n_examples,1)\n",
    "    i_std = np.argsort(var_to_np(class_dist.get_mean_std(1)[1]))[::-1][i_i_std]\n",
    "    print(\"std\", i_std, std[i_std])\n",
    "\n",
    "    interps = np.linspace(mean[i_std] - 1.5 *std[i_std], mean[i_std] + 1.5 *std[i_std], n_examples)\n",
    "\n",
    "    samples.data[:,i_std] = np_to_var(interps, device='cuda', dtype=np.float32)\n",
    "    inverted = feature_model.invert(samples)\n",
    "    clear_ctx_dicts(feature_model)\n",
    "    from matplotlib import rcParams, cycler\n",
    "    cmap = plt.cm.coolwarm\n",
    "    with plt.rc_context(rc=({'axes.prop_cycle': cycler(color=cmap(np.linspace(0, 1, n_examples)))})):\n",
    "        \n",
    "        # Setting up a colormap that's a simple transtion\n",
    "        mymap = matplotlib.colors.LinearSegmentedColormap.from_list('mycolors',['blue','red'])\n",
    "\n",
    "        # Using contourf to provide my colorbar info, then clearing the figure\n",
    "        Z = [[0,0],[0,0]]\n",
    "        levels = range(0, n_examples)\n",
    "        CS3 = plt.contourf(Z, levels, cmap=mymap)\n",
    "        plt.clf()\n",
    "        \n",
    "        fig = plot_head_signals_tight(var_to_np(inverted).squeeze().transpose(1,2,0), sensor_names=sensor_names,\n",
    "                                 figsize=(20,12));\n",
    "        cbar = plt.colorbar(CS3, anchor=(1,2), panchor=(1,2),ax=fig.get_axes()[0])\n",
    "        cbar.set_ticklabels([\"min\",] + ([\"\"] * (len(cbar.get_ticks()) - 2)) +[\"max\"])\n",
    "        cbar.set_label(\"Latent value\", fontsize=16)\n",
    "        plt.savefig('/data/schirrmr/schirrmr/ohbm-rom/visualization{:d}.png'.format(i_i_std),\n",
    "                    dpi=300 ,transparent=False,\n",
    "                   bbox_inches='tight', pad_inches=0)\n",
    "        \n",
    "        display_close(fig)\n",
    "seaborn.set_context('poster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from reversible2.plot import plot_head_signals_tight\n",
    "inverted_per_class = []\n",
    "for i_class in range(2):\n",
    "    with th.no_grad():\n",
    "        samples = class_dist.get_samples(i_class, len(train_inputs[i_class]) * 4)\n",
    "        inverted = feature_model.invert(samples)\n",
    "    clear_ctx_dicts(feature_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ot\n",
    "def transport_mat_for_diffs(samples_a, samples_b):\n",
    "    diffs = samples_a.unsqueeze(1) - samples_b.unsqueeze(0)\n",
    "    diffs = th.norm(diffs, dim=2, p=2)\n",
    "    transport_mat = ot.emd([], [], var_to_np(diffs))\n",
    "    # sometimes weird low values, try to prevent them\n",
    "    # 0.5 could be 1.0, just set ot 0.5 to make more sure nothing\n",
    "    # removed accidentally\n",
    "    transport_mat = transport_mat * (transport_mat >= (0.5 / (diffs.numel())))\n",
    "    return transport_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_mat = transport_mat_for_diffs(train_inputs[i_class].view(len(train_inputs[i_class]),-1),\n",
    "                        inverted.view(len(inverted), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.style as style\n",
    "style.use('seaborn-poster')\n",
    "seaborn.set_context('poster')\n",
    "\n",
    "seaborn.set_palette(\"colorblind\", )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_row in range(5, t_mat.shape[0]):\n",
    "    matches = np.flatnonzero(t_mat[i_row])\n",
    "    signal = var_to_np(train_inputs[i_class][i_row]).squeeze()\n",
    "    inv_matches = var_to_np(inverted[matches]).squeeze()\n",
    "\n",
    "    if i_row > 7:\n",
    "        break\n",
    "\n",
    "    diffs = np.linalg.norm(signal[None] - inv_matches, ord=2, axis=2).squeeze()\n",
    "\n",
    "    i_t, i_c = np.argmin(diffs) // 22, np.argmin(diffs) % 22\n",
    "\n",
    "    with seaborn.axes_style(\"white\"):\n",
    "        fig = plt.figure(figsize=(8,2))\n",
    "        plt.plot(signal[i_c], color=seaborn.color_palette()[2])\n",
    "        plt.plot(inv_matches[i_t][i_c], color=seaborn.color_palette()[3])\n",
    "        plt.axis('off')\n",
    "        plt.legend([\"Real signal\", \"Matched generated signal\"], bbox_to_anchor=(1,1,0,0))\n",
    "        plt.savefig('/data/schirrmr/schirrmr/ohbm-rom/match_legend{:d}.png'.format(i_row), dpi=300 ,transparent=True,\n",
    "           bbox_inches='tight', pad_inches=0)\n",
    "        display_close(fig)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_row in range(5, t_mat.shape[0]):\n",
    "    matches = np.flatnonzero(t_mat[i_row])\n",
    "    signal = var_to_np(train_inputs[i_class][i_row]).squeeze()\n",
    "    inv_matches = var_to_np(inverted[matches]).squeeze()\n",
    "    \n",
    "    if i_row > 7:\n",
    "        break\n",
    "\n",
    "    diffs = np.linalg.norm(signal[None] - inv_matches, ord=2, axis=2).squeeze()\n",
    "\n",
    "    i_t, i_c = np.argmin(diffs) // 22, np.argmin(diffs) % 22\n",
    "\n",
    "    with seaborn.axes_style(\"white\"):\n",
    "        fig = plt.figure(figsize=(8,2))\n",
    "        plt.plot(signal[i_c], color=seaborn.color_palette()[2])\n",
    "        plt.plot(inv_matches[i_t][i_c], color=seaborn.color_palette()[3])\n",
    "        plt.axis('off')\n",
    "        plt.savefig('/data/schirrmr/schirrmr/ohbm-rom/match_{:d}.png'.format(i_row), dpi=300 ,transparent=True,\n",
    "           bbox_inches='tight', pad_inches=0)\n",
    "        display_close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from reversible2.plot import plot_head_signals_tight\n",
    "inverted_per_class = []\n",
    "for i_class in range(2):\n",
    "    with th.no_grad():\n",
    "        samples = class_dist.get_samples(i_class, len(train_inputs[i_class]) * 4)\n",
    "        inverted = feature_model.invert(samples)\n",
    "        inverted = var_to_np(inverted).squeeze()\n",
    "        signals = var_to_np(train_inputs[i_class]).squeeze()\n",
    "    clear_ctx_dicts(feature_model)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,2))\n",
    "plt.plot(np.fft.rfftfreq(256,d=1.0/256.0), np.mean(np.abs(np.fft.rfft(signals)), axis=(0,1)),\n",
    "         color=seaborn.color_palette()[2])\n",
    "plt.plot(np.fft.rfftfreq(256,d=1.0/256.0), np.mean(np.abs(np.fft.rfft(inverted)), axis=(0,1)),\n",
    "         color=seaborn.color_palette()[3])\n",
    "plt.xlabel(\"Frequency [Hz]\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.legend([\"Real Resting State\", \"Generated\"], fontsize=18,loc='upper right',\n",
    "          bbox_to_anchor=(1,1))\n",
    "plt.savefig('/data/schirrmr/schirrmr/ohbm-rom/overall_spectrum.png', dpi=300 ,transparent=False,\n",
    "   bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.rc_context(rc=({'axes.prop_cycle': cycler(color=seaborn.color_palette()[2:4])})):\n",
    "    fig = plot_head_signals_tight(np.stack([np.mean(np.abs(np.fft.rfft(signals)), axis=0),\n",
    "             np.mean(np.abs(np.fft.rfft(inverted)), axis=0)],axis=-1),\n",
    "                                  sensor_names=sensor_names,\n",
    "                                     figsize=(20,12));\n",
    "    plt.ylim(0,55)\n",
    "    ax = plt.gca()\n",
    "\n",
    "    fig.legend(ax.get_lines()[:2], [\"Real Resting State\", \"Generated\"], fontsize=24,loc='upper right',\n",
    "              bbox_to_anchor=(0.77,0.79))\n",
    "    \n",
    "    plt.savefig('/data/schirrmr/schirrmr/ohbm-rom/spectrum_by_chan.png', dpi=300 ,transparent=False,\n",
    "       bbox_inches='tight', pad_inches=0)\n",
    "    \n",
    "    display_close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "state_dict = th.load('/data/schirrmr/schirrmr/models/eegconvnet-public-data-simple-no-multiplication/pretrained/deep/4.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from braindecode.datautil.signal_target import SignalAndTarget\n",
    "def inputs_to_set(inputs):\n",
    "    X = np.concatenate((var_to_np(inputs[0]),\n",
    "                      var_to_np(inputs[1])), \n",
    "                          ).astype(np.float32).squeeze(-1)\n",
    "    y = np.concatenate((np.zeros(len(inputs[0]), dtype=np.int64),\n",
    "                       np.ones(len(inputs[1]), dtype=np.int64)))\n",
    "    return SignalAndTarget(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set = inputs_to_set(train_inputs)\n",
    "test_set = inputs_to_set(test_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.X.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from braindecode.models.deep4 import Deep4Net\n",
    "\n",
    "from torch import nn\n",
    "from braindecode.torch_ext.util import set_random_seeds\n",
    "\n",
    "# Set if you want to use GPU\n",
    "# You can also use torch.cuda.is_available() to determine if cuda is available on your machine.\n",
    "cuda = True\n",
    "set_random_seeds(seed=20170629, cuda=cuda)\n",
    "\n",
    "n_chans = train_set.X.shape[1]\n",
    "n_classes = 2\n",
    "input_time_length = train_set.X.shape[2]\n",
    "model = Deep4Net(n_chans, n_classes,\n",
    "                 input_time_length=input_time_length,\n",
    "                 pool_time_length=2,\n",
    "                 pool_time_stride=2,\n",
    "                 final_conv_length='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from braindecode.torch_ext.optimizers import AdamW\n",
    "import torch.nn.functional as F\n",
    "optimizer = AdamW(model.parameters(), lr=1*0.01, weight_decay=0.5*0.001) # these are good values for the deep model\n",
    "#optimizer = AdamW(model.parameters(), lr=0.0625 * 0.01, weight_decay=0)\n",
    "\n",
    "model.compile(loss=F.nll_loss, optimizer=optimizer, iterator_seed=1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_set.X, train_set.y, epochs=30, batch_size=64, scheduler='cosine',\n",
    "         validation_data=(test_set.X, test_set.y),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from braindecode.torch_ext.optimizers import AdamW\n",
    "import torch.nn.functional as F\n",
    "optimizer = AdamW(model.parameters(), lr=1*0.01, weight_decay=0.5*0.001) # these are good values for the deep model\n",
    "\n",
    "model.compile(loss=F.nll_loss, optimizer=optimizer, iterator_seed=1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from reversible2.plot import plot_head_signals_tight\n",
    "set_random_seeds(201905231, cuda)\n",
    "with th.no_grad():\n",
    "    inverted_per_class = []\n",
    "    for i_class in range(2):\n",
    "        samples = class_dist.get_samples(i_class, 184)\n",
    "        inverted = feature_model.invert(samples)\n",
    "        inverted_per_class.append(inverted.detach())\n",
    "\n",
    "from reversible2.constantmemory import clear_ctx_dicts\n",
    "clear_ctx_dicts(feature_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_set = inputs_to_set(inverted_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(sample_set.X, sample_set.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from braindecode.models.deep4 import Deep4Net\n",
    "\n",
    "from torch import nn\n",
    "from braindecode.torch_ext.util import set_random_seeds\n",
    "\n",
    "# Set if you want to use GPU\n",
    "# You can also use torch.cuda.is_available() to determine if cuda is available on your machine.\n",
    "cuda = True\n",
    "set_random_seeds(seed=20170629, cuda=cuda)\n",
    "\n",
    "n_chans = sample_set.X.shape[1]\n",
    "n_classes = 2\n",
    "input_time_length = sample_set.X.shape[2]\n",
    "sample_model = Deep4Net(n_chans, n_classes,\n",
    "                 input_time_length=input_time_length,\n",
    "                 pool_time_length=2,\n",
    "                 pool_time_stride=2,\n",
    "                 final_conv_length='auto')\n",
    "from braindecode.torch_ext.optimizers import AdamW\n",
    "import torch.nn.functional as F\n",
    "optimizer = AdamW(sample_model.parameters(), lr=1*0.01, weight_decay=0.5*0.001) # these are good values for the deep model\n",
    "#optimizer = AdamW(model.parameters(), lr=0.0625 * 0.01, weight_decay=0)\n",
    "\n",
    "sample_model.compile(loss=F.nll_loss, optimizer=optimizer, iterator_seed=1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_model.fit(sample_set.X, sample_set.y, epochs=30, batch_size=64, scheduler='cosine',\n",
    "         validation_data=(test_set.X, test_set.y),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from reversible2.plot import plot_head_signals_tight\n",
    "set_random_seeds(201905231, cuda)\n",
    "with th.no_grad():\n",
    "    inverted_per_class = []\n",
    "    for i_class in range(2):\n",
    "        samples = class_dist.get_samples(i_class, 184*3)\n",
    "        inverted = feature_model.invert(samples)\n",
    "        inverted_per_class.append(inverted.detach())\n",
    "\n",
    "from reversible2.constantmemory import clear_ctx_dicts\n",
    "clear_ctx_dicts(feature_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_set = inputs_to_set(inverted_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from braindecode.models.deep4 import Deep4Net\n",
    "\n",
    "from torch import nn\n",
    "from braindecode.torch_ext.util import set_random_seeds\n",
    "\n",
    "# Set if you want to use GPU\n",
    "# You can also use torch.cuda.is_available() to determine if cuda is available on your machine.\n",
    "cuda = True\n",
    "set_random_seeds(seed=20170629, cuda=cuda)\n",
    "\n",
    "n_chans = sample_set.X.shape[1]\n",
    "n_classes = 2\n",
    "input_time_length = sample_set.X.shape[2]\n",
    "sample_model = Deep4Net(n_chans, n_classes,\n",
    "                 input_time_length=input_time_length,\n",
    "                 pool_time_length=2,\n",
    "                 pool_time_stride=2,\n",
    "                 final_conv_length='auto')\n",
    "from braindecode.torch_ext.optimizers import AdamW\n",
    "import torch.nn.functional as F\n",
    "optimizer = AdamW(sample_model.parameters(), lr=1*0.01, weight_decay=0.5*0.001) # these are good values for the deep model\n",
    "#optimizer = AdamW(model.parameters(), lr=0.0625 * 0.01, weight_decay=0)\n",
    "\n",
    "sample_model.compile(loss=F.nll_loss, optimizer=optimizer, iterator_seed=1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_model.fit(sample_set.X, sample_set.y, epochs=30, batch_size=64, scheduler='cosine',\n",
    "         validation_data=(test_set.X, test_set.y),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_model.evaluate(train_set.X, train_set.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First test, towards inception distance: train on generated signals with deep4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
