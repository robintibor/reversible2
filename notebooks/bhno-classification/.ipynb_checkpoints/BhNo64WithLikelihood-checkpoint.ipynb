{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import importlib\n",
    "importlib.reload(logging) # see https://stackoverflow.com/a/21475297/1469195\n",
    "log = logging.getLogger()\n",
    "log.setLevel('INFO')\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s : %(message)s',\n",
    "                     level=logging.INFO, stream=sys.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import os\n",
    "import site\n",
    "os.sys.path.insert(0, '/home/schirrmr/code/reversible/')\n",
    "os.sys.path.insert(0, '/home/schirrmr/braindecode/code/braindecode/')\n",
    "os.sys.path.insert(0, '/home/schirrmr/code/explaining/reversible//')\n",
    "%cd /home/schirrmr/\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import logging\n",
    "log = logging.getLogger()\n",
    "log.setLevel('INFO')\n",
    "import sys\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s : %(message)s',\n",
    "                     level=logging.INFO, stream=sys.stdout)\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'png'\n",
    "matplotlib.rcParams['figure.figsize'] = (12.0, 1.0)\n",
    "matplotlib.rcParams['font.size'] = 14\n",
    "import seaborn\n",
    "seaborn.set_style('darkgrid')\n",
    "\n",
    "from reversible2.sliced import sliced_from_samples\n",
    "from numpy.random import RandomState\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import copy\n",
    "import math\n",
    "\n",
    "import itertools\n",
    "import torch as th\n",
    "from braindecode.torch_ext.util import np_to_var, var_to_np\n",
    "from reversible2.splitter import SubsampleSplitter\n",
    "\n",
    "from reversible2.view_as import ViewAs\n",
    "from reversible2.invert import invert\n",
    "\n",
    "from reversible2.affine import AdditiveBlock\n",
    "\n",
    "def display_text(text, fontsize=18):\n",
    "    fig = plt.figure(figsize=(12,0.1))\n",
    "    plt.title(text, fontsize=fontsize)\n",
    "    plt.axis('off')\n",
    "    display(fig)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from braindecode.datasets.bbci import BBCIDataset\n",
    "from braindecode.mne_ext.signalproc import mne_apply\n",
    "from collections import OrderedDict\n",
    "from braindecode.datautil.trial_segment import create_signal_target_from_raw_mne\n",
    "\n",
    "def load_file(filename):\n",
    "    cnt = BBCIDataset(filename).load()\n",
    "    cnt = cnt.drop_channels(['STI 014'])\n",
    "    def car(a):\n",
    "        return a - np.mean(a, keepdims=True, axis=0)\n",
    "\n",
    "    cnt = mne_apply(\n",
    "        car, cnt)\n",
    "    return cnt\n",
    "\n",
    "\n",
    "def create_set(cnt):\n",
    "    marker_def = OrderedDict([('Right Hand', [1]), ('Left Hand', [2],),\n",
    "                             ('Rest', [3]), ('Feet', [4])])\n",
    "    ival = [500,1500]\n",
    "    from braindecode.mne_ext.signalproc import mne_apply, resample_cnt\n",
    "    from braindecode.datautil.signalproc import exponential_running_standardize, bandpass_cnt\n",
    "\n",
    "    log.info(\"Resampling train...\")\n",
    "    cnt = resample_cnt(cnt, 250.0)\n",
    "    log.info(\"Standardizing train...\")\n",
    "    cnt = mne_apply(lambda a: exponential_running_standardize(a.T ,factor_new=1e-3, init_block_size=1000, eps=1e-4).T,\n",
    "                         cnt)\n",
    "    cnt = resample_cnt(cnt, 32.0)\n",
    "    cnt = resample_cnt(cnt, 64.0)\n",
    "\n",
    "    dataset = create_signal_target_from_raw_mne(cnt, marker_def, ival)\n",
    "    return dataset\n",
    "def create_inputs(dataset):\n",
    "    x_right = dataset.X[dataset.y == 0]\n",
    "\n",
    "    x_rest = dataset.X[dataset.y == 2]\n",
    "\n",
    "    inputs_a = np_to_var(x_right[:,0:1,:,None], dtype=np.float32)\n",
    "\n",
    "    inputs_b = np_to_var(x_rest[:,0:1,:,None], dtype=np.float32)\n",
    "    inputs = [inputs_a, inputs_b]\n",
    "    return inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cnt = load_file('/data/schirrmr/schirrmr/HGD-public/reduced/train/4.mat')\n",
    "train_cnt = train_cnt.reorder_channels(['C3', 'C4'])\n",
    "train_set = create_set(train_cnt)\n",
    "train_inputs = create_inputs(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cnt = load_file('/data/schirrmr/schirrmr/HGD-public/reduced/test/4.mat')\n",
    "test_cnt = test_cnt.reorder_channels(['C3', 'C4'])\n",
    "test_set = create_set(test_cnt)\n",
    "test_inputs = create_inputs(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cuda = True\n",
    "if cuda:\n",
    "    train_inputs = [i.cuda() for i in train_inputs]\n",
    "    test_inputs = [i.cuda() for i in test_inputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile distribution.py\n",
    "import torch as th\n",
    "from reversible2.gaussian import get_gauss_samples\n",
    "class TwoClassDist(object):\n",
    "    def __init__(self,):\n",
    "        super(TwoClassDist, self).__init__()\n",
    "        self.class_means = th.zeros(2, requires_grad=True)\n",
    "        self.non_class_means = th.zeros(62, requires_grad=True)\n",
    "        self.class_log_stds =  th.zeros(2, requires_grad=True)\n",
    "        self.non_class_log_stds = th.zeros(62, requires_grad=True)\n",
    "        \n",
    "    def get_mean_std(self, i_class):\n",
    "        device = self.class_means.device\n",
    "        cur_mean = th.cat((th.zeros(i_class, device=device),\n",
    "                           self.class_means[i_class:i_class+1],\n",
    "                th.zeros(len(self.class_means) - i_class-1, device=device),\n",
    "                          self.non_class_means))\n",
    "        cur_log_std = th.cat((th.ones(i_class, device=device) * -9,\n",
    "                              self.class_log_stds[i_class:i_class+1],\n",
    "                th.ones(len(self.class_log_stds) - i_class-1, device=device) * -9,\n",
    "                          self.non_class_log_stds))\n",
    "        return cur_mean, th.exp(cur_log_std)\n",
    "\n",
    "    def get_samples(self, i_class, n_samples):\n",
    "        cur_mean, cur_std = self.get_mean_std(i_class)\n",
    "        samples = get_gauss_samples(n_samples, cur_mean, cur_std)\n",
    "        return samples\n",
    "    \n",
    "    def cuda(self):\n",
    "        self.class_means.data = self.class_means.data.cuda()\n",
    "        self.non_class_means.data = self.non_class_means.data.cuda()\n",
    "        self.class_log_stds.data =  self.class_log_stds.data.cuda()\n",
    "        self.non_class_log_stds.data = self.non_class_log_stds.data.cuda()\n",
    "        return self\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [self.class_means, self.non_class_means, self.class_log_stds, self.non_class_log_stds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reversible2.blocks import dense_add_block, conv_add_block_3x3\n",
    "from reversible2.rfft import RFFT, Interleave\n",
    "from reversible2.util import set_random_seeds\n",
    "from torch.nn import ConstantPad2d\n",
    "import torch as th\n",
    "from reversible2.splitter import SubsampleSplitter\n",
    "\n",
    "\n",
    "set_random_seeds(2019011641, cuda)\n",
    "feature_model = nn.Sequential(\n",
    "    SubsampleSplitter(stride=[2,1],chunk_chans_first=False),# 2 x 32\n",
    "    conv_add_block_3x3(2,32),\n",
    "    conv_add_block_3x3(2,32),\n",
    "    SubsampleSplitter(stride=[2,1],chunk_chans_first=True), # 4 x 16\n",
    "    conv_add_block_3x3(4,32),\n",
    "    conv_add_block_3x3(4,32),\n",
    "    SubsampleSplitter(stride=[2,1],chunk_chans_first=True), # 8 x 8\n",
    "    conv_add_block_3x3(8,32),\n",
    "    conv_add_block_3x3(8,32),\n",
    "    SubsampleSplitter(stride=[2,1],chunk_chans_first=True), # 16 x 4\n",
    "    conv_add_block_3x3(16,32),\n",
    "    conv_add_block_3x3(16,32),\n",
    "    SubsampleSplitter(stride=[2,1],chunk_chans_first=True), # 32 x 2\n",
    "    conv_add_block_3x3(32,32),\n",
    "    conv_add_block_3x3(32,32),\n",
    "    SubsampleSplitter(stride=[2,1],chunk_chans_first=True), # 64 x 1\n",
    "    ViewAs((-1,64,1, 1), (-1,64)),\n",
    "    dense_add_block(64,64),\n",
    "    dense_add_block(64,64),\n",
    "    dense_add_block(64,64),\n",
    "    dense_add_block(64,64),\n",
    "    dense_add_block(64,64),\n",
    "    dense_add_block(64,64),\n",
    "    RFFT(),\n",
    ")\n",
    "if cuda:\n",
    "    feature_model.cuda()\n",
    "device = list(feature_model.parameters())[0].device\n",
    "from distribution import TwoClassDist\n",
    "from reversible2.ot_exact import ot_euclidean_loss_for_samples\n",
    "class_dist = TwoClassDist()\n",
    "class_dist.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optim_model = th.optim.Adam(feature_model.parameters())\n",
    "optim_dist = th.optim.Adam(class_dist.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile plot.py\n",
    "import torch as th\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from reversible2.util import var_to_np\n",
    "from matplotlib.patches import Ellipse\n",
    "import seaborn\n",
    "\n",
    "def plot_outs(feature_model_a, train_inputs, test_inputs, class_dist):\n",
    "     # Compute dist for mean/std of encodings\n",
    "    data_cls_dists = []\n",
    "    for i_class in range(len(train_inputs)):\n",
    "        this_class_outs = feature_model_a(train_inputs[i_class])[:,:2]\n",
    "        \n",
    "        data_cls_dists.append(\n",
    "            th.distributions.MultivariateNormal(th.mean(this_class_outs, dim=0),\n",
    "            covariance_matrix=th.diag(th.std(this_class_outs, dim=0))))\n",
    "    for setname, set_inputs in ((\"Train\", train_inputs), (\"Test\", test_inputs)):\n",
    "\n",
    "        outs = [feature_model_a(ins) for ins in set_inputs]\n",
    "        c_outs = [o[:,:2] for o in outs]\n",
    "\n",
    "        c_outs_all = th.cat(c_outs)\n",
    "\n",
    "        cls_dists = []\n",
    "        for i_class in range(len(c_outs)):\n",
    "            mean, std = class_dist.get_mean_std(i_class)\n",
    "            cls_dists.append(\n",
    "                th.distributions.MultivariateNormal(mean[:2],covariance_matrix=th.diag(std[:2])))\n",
    "\n",
    "        preds = th.stack([cls_dists[i_cls].log_prob(c_outs_all)\n",
    "                         for i_cls in range(len(cls_dists))],\n",
    "                        dim=-1)\n",
    "\n",
    "        pred_labels = np.argmax(var_to_np(preds), axis=1)\n",
    "\n",
    "        labels = np.concatenate([np.ones(len(set_inputs[i_cls])) * i_cls \n",
    "         for i_cls in range(len(train_inputs))])\n",
    "\n",
    "        acc = np.mean(labels == pred_labels)\n",
    "        \n",
    "        data_preds = th.stack([data_cls_dists[i_cls].log_prob(c_outs_all)\n",
    "                         for i_cls in range(len(cls_dists))],\n",
    "                        dim=-1)\n",
    "        data_pred_labels = np.argmax(var_to_np(data_preds), axis=1)\n",
    "        data_acc = np.mean(labels == data_pred_labels)\n",
    "\n",
    "        print(\"{:s} Accuracy: {:.2f}%\".format(setname, acc * 100))\n",
    "        fig = plt.figure(figsize=(5,5))\n",
    "        ax = plt.gca()\n",
    "        for i_class in range(len(c_outs)):\n",
    "            o = var_to_np(c_outs[i_class]).squeeze()\n",
    "            plt.scatter(o[:,0], o[:,1], s=20, alpha=0.75)\n",
    "            means = var_to_np(class_dist.class_means).copy()\n",
    "            means[1-i_class] = 0\n",
    "            stds = var_to_np(th.exp(class_dist.class_log_stds))\n",
    "            stds[1-i_class] = 0.05\n",
    "            for sigma in [0.5,1,2,3]:\n",
    "                ellipse = Ellipse(means, stds[0]*sigma, stds[1]*sigma)\n",
    "                ax.add_artist(ellipse)\n",
    "                ellipse.set_edgecolor(seaborn.color_palette()[i_class])\n",
    "                ellipse.set_facecolor(\"None\")\n",
    "        for i_class in range(len(c_outs)):\n",
    "            o = var_to_np(c_outs[i_class]).squeeze()\n",
    "            plt.scatter(np.mean(o[:,0]), np.mean(o[:,1]),\n",
    "                       color=seaborn.color_palette()[i_class+2], s=80, marker=\"^\")\n",
    "\n",
    "        plt.title(\"{:6s} Accuracy:        {:.2f}%\\n\"\n",
    "                  \"From data mean/std: {:.2f}%\".format(setname, acc * 100, data_acc * 100))\n",
    "        plt.legend((\"Right\", \"Rest\", \"Right Mean\", \"Rest Mean\"))\n",
    "        display(fig)\n",
    "        plt.close(fig)\n",
    "        \n",
    "def display_close(fig):\n",
    "    display(fig)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_th_dist(class_dist, i_class):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot import plot_outs, display_close\n",
    "n_epochs = 2001\n",
    "for i_epoch in range(n_epochs):\n",
    "    optim_model.zero_grad()\n",
    "    optim_dist.zero_grad()\n",
    "    for i_class in range(len(train_inputs)):\n",
    "        class_ins = train_inputs[i_class]\n",
    "        samples = class_dist.get_samples(i_class, len(train_inputs[i_class]) * 5)\n",
    "        inverted = invert(feature_model, samples)\n",
    "        ot_loss = ot_euclidean_loss_for_samples(class_ins.squeeze(), inverted.squeeze())\n",
    "        ### from here new\n",
    "        outs = feature_model(class_ins)\n",
    "        mean, std = class_dist.get_mean_std(i_class)\n",
    "        th_dist = th.distributions.MultivariateNormal(mean, covariance_matrix=th.diag(std))\n",
    "        nll_mean = th.mean(-th_dist.log_prob(outs)) * (1/64)\n",
    "        # redo this\n",
    "        loss = ot_loss + nll_mean\n",
    "        loss.backward()\n",
    "    optim_model.step()\n",
    "    optim_dist.step()\n",
    "    if i_epoch % (n_epochs // 20) == 0:\n",
    "        print(\"Epoch {:d} of {:d}\".format(i_epoch, n_epochs))\n",
    "        print(\"Loss: {:E}\".format(loss.item()))\n",
    "        print(\"OT Loss: {:E}\".format(ot_loss.item()))\n",
    "        print(\"NLL Loss: {:E}\".format(nll_mean.item()))\n",
    "        plot_outs(feature_model, train_inputs, test_inputs,\n",
    "                 class_dist)\n",
    "        fig = plt.figure(figsize=(8,2))\n",
    "        plt.plot(var_to_np(th.cat((th.exp(class_dist.class_log_stds),\n",
    "                                 th.exp(class_dist.non_class_log_stds)))),\n",
    "                marker='o')\n",
    "        display_close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for setname, set_inputs in ((\"Train\", train_inputs), (\"Test\", test_inputs)):\n",
    "    total_loss = 0\n",
    "    total_spec_ot = 0\n",
    "    for i_class in range(2):\n",
    "        class_ins = set_inputs[i_class]\n",
    "        samples = class_dist.get_samples(i_class, len(train_inputs[i_class]) * 5)\n",
    "        inverted = invert(feature_model, samples)\n",
    "        loss = ot_euclidean_loss_for_samples(class_ins.squeeze(), inverted.squeeze())\n",
    "        total_loss += loss\n",
    "        spec_ot = ot_euclidean_loss_for_samples(\n",
    "            th.rfft(class_ins.squeeze(), signal_ndim=1, normalized=True).view(class_ins.shape[0],-1),\n",
    "            th.rfft(inverted.squeeze(), signal_ndim=1, normalized=True).view(inverted.shape[0],-1))\n",
    "        total_spec_ot += spec_ot\n",
    "    print(setname + \" Loss: {:.1f}\".format(total_loss.item() / 2))\n",
    "    print(setname + \" SpecLoss: {:.1f}\".format(spec_ot.item() / 2))\n",
    "# Show losses between sets\n",
    "for setname, set_inputs in ((\"Train\", train_inputs),):\n",
    "    total_loss = 0\n",
    "    total_spec_ot = 0\n",
    "    for i_class in range(2):\n",
    "        class_ins = set_inputs[i_class]\n",
    "        samples = class_dist.get_samples(i_class, len(train_inputs[i_class]) * 5) # take same number of samples\n",
    "        inverted = test_inputs[i_class]\n",
    "        loss = ot_euclidean_loss_for_samples(class_ins.squeeze(), inverted.squeeze())\n",
    "        total_loss += loss\n",
    "        spec_ot = ot_euclidean_loss_for_samples(\n",
    "            th.rfft(class_ins.squeeze(), signal_ndim=1, normalized=True).view(class_ins.shape[0],-1),\n",
    "            th.rfft(inverted.squeeze(), signal_ndim=1, normalized=True).view(inverted.shape[0],-1))\n",
    "        total_spec_ot += spec_ot\n",
    "    print(setname + \" Loss: {:.1f}\".format(total_loss.item() / 2))\n",
    "    print(setname + \" SpecLoss: {:.1f}\".format(spec_ot.item() / 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_th_grid(dim_0_vals, dim_1_vals):\n",
    "    curves = []\n",
    "    for dim_0_val in dim_0_vals:\n",
    "        this_curves = []\n",
    "        for dim_1_val in dim_1_vals:\n",
    "            vals = th.stack((dim_0_val, dim_1_val))\n",
    "            this_curves.append(vals)\n",
    "        curves.append(th.stack(this_curves))\n",
    "    curves = th.stack(curves)\n",
    "    return curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "means = th.stack([class_dist.get_mean_std(i_cls,)[0][:2]\n",
    "     for i_cls in range(len(train_inputs))])\n",
    "stds = th.stack([class_dist.get_mean_std(i_cls,)[1][:2]\n",
    "     for i_cls in range(len(train_inputs))])\n",
    "mins = th.min(means - stds * 0.5, dim=1)[0]\n",
    "maxs = th.max(means + stds * 0.5, dim=1)[0]\n",
    "mean_for_plot = th.mean(th.stack((mins, maxs)), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#mins.data[0] = -0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_vals = 20\n",
    "dim_0_vals = th.linspace(mins[0].item(), maxs[0].item(),n_vals, device=mins.device)\n",
    "dim_1_vals = th.linspace(mins[1].item(), maxs[1].item(),n_vals, device=mins.device)\n",
    "\n",
    "\n",
    "grid = create_th_grid(dim_0_vals, dim_1_vals)\n",
    "\n",
    "full_grid = th.cat((grid, class_dist.non_class_means.repeat(grid.shape[0],grid.shape[1],1)), dim=-1)\n",
    "\n",
    "inverted = invert(feature_model, full_grid.view(-1, full_grid.shape[-1])).squeeze()\n",
    "\n",
    "inverted_grid = inverted.view(len(dim_0_vals), len(dim_1_vals),-1)\n",
    "\n",
    "x_len, y_len = var_to_np(maxs - mins) / full_grid.shape[:-1]\n",
    "\n",
    "max_abs = th.max(th.abs(inverted_grid))\n",
    "\n",
    "y_factor =  (y_len / (2*max_abs)).item() * 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(32,32))\n",
    "\n",
    "for i_x in range(full_grid.shape[0]):\n",
    "    for i_y in range(full_grid.shape[1]):\n",
    "        x_start = mins[0].item() + x_len * i_x + 0.1 * x_len\n",
    "        x_end = mins[0].item() + x_len * i_x + 0.9 * x_len\n",
    "        y_center = mins[1].item() + y_len * i_y + 0.5 * y_len\n",
    "        \n",
    "        curve = var_to_np(inverted_grid[i_x][i_y])\n",
    "        label = ''\n",
    "        if i_x == 0 and i_y == 0:\n",
    "            label = 'Generated data'\n",
    "        plt.plot(np.linspace(x_start, x_end, len(curve)),\n",
    "                 curve * y_factor + y_center, color='black',\n",
    "                label=label)\n",
    "outs = [feature_model(ins) for ins in train_inputs]\n",
    "c_outs = [o[:,:2] for o in outs]\n",
    "\n",
    "plt.gca().set_autoscale_on(False)\n",
    "for i_cls, c_out in enumerate(c_outs):\n",
    "    plt.scatter(var_to_np(c_out[:,0]),\n",
    "               var_to_np(c_out[:,1]), s=200, alpha=0.75, label='Encodings {:s}'.format(\n",
    "               [\"Right\", \"Rest\"][i_cls]))\n",
    "    \n",
    "plt.legend(fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,2))\n",
    "for i_class in range(2):\n",
    "    cur_mean, cur_std = class_dist.get_mean_std(i_class, )\n",
    "    inverted = invert(feature_model, cur_mean.unsqueeze(0))\n",
    "    plt.plot(var_to_np(inverted.squeeze()))\n",
    "plt.legend((\"Right Hand\", \"Rest\"))\n",
    "display(fig)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from plot import display_close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_0, _ = get_mean_std(0,class_means, non_class_means,\n",
    "             class_log_stds, non_class_log_stds)\n",
    "mean_1, _ = get_mean_std(1,class_means, non_class_means,\n",
    "             class_log_stds, non_class_log_stds)\n",
    "\n",
    "n_interpolates = 100\n",
    "alphas = th.linspace(1,0,n_interpolates, device=mean_0.device)\n",
    "\n",
    "interpolates = mean_0.unsqueeze(0) * alphas.unsqueeze(1) + mean_1.unsqueeze(0) * (1-alphas.unsqueeze(1))\n",
    "inverted = invert(feature_model,interpolates, )\n",
    "\n",
    "from matplotlib import rcParams, cycler\n",
    "cmap = plt.cm.coolwarm\n",
    "with plt.rc_context(rc={'axes.prop_cycle':cycler(color=cmap(np.linspace(0, 1, len(inverted))))}):\n",
    "    fig = plt.figure(figsize=(8,2))\n",
    "    plt.plot(var_to_np(inverted).squeeze().T,);\n",
    "    display_close(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
