{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import importlib\n",
    "importlib.reload(logging) # see https://stackoverflow.com/a/21475297/1469195\n",
    "log = logging.getLogger()\n",
    "log.setLevel('INFO')\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s : %(message)s',\n",
    "                     level=logging.INFO, stream=sys.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import os\n",
    "import site\n",
    "os.sys.path.insert(0, '/home/schirrmr/code/reversible/')\n",
    "os.sys.path.insert(0, '/home/schirrmr/braindecode/code/braindecode/')\n",
    "os.sys.path.insert(0, '/home/schirrmr/code/explaining/reversible//')\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import logging\n",
    "log = logging.getLogger()\n",
    "log.setLevel('INFO')\n",
    "import sys\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s : %(message)s',\n",
    "                     level=logging.INFO, stream=sys.stdout)\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'png'\n",
    "matplotlib.rcParams['figure.figsize'] = (12.0, 1.0)\n",
    "matplotlib.rcParams['font.size'] = 14\n",
    "import seaborn\n",
    "seaborn.set_style('darkgrid')\n",
    "\n",
    "from reversible2.sliced import sliced_from_samples\n",
    "from numpy.random import RandomState\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import copy\n",
    "import math\n",
    "\n",
    "import itertools\n",
    "import torch as th\n",
    "from braindecode.torch_ext.util import np_to_var, var_to_np\n",
    "from reversible2.splitter import SubsampleSplitter\n",
    "\n",
    "from reversible2.view_as import ViewAs\n",
    "\n",
    "from reversible2.affine import AdditiveBlock\n",
    "from reversible2.plot import display_text, display_close\n",
    "from reversible2.high_gamma import load_file, create_inputs\n",
    "from reversible2.high_gamma import load_train_test\n",
    "th.backends.cudnn.benchmark = True\n",
    "from reversible2.models import deep_invertible\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sensor_names = ['Fz', \n",
    "                'FC3','FC1','FCz','FC2','FC4',\n",
    "                'C5','C3','C1','Cz','C2','C4','C6',\n",
    "                'CP3','CP1','CPz','CP2','CP4',\n",
    "                'P1','Pz','P2',\n",
    "                'POz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "# create dist\n",
    "\n",
    "train_inputs, test_inputs = load_train_test(\n",
    "    subject_id=4,\n",
    "    car=True,\n",
    "    n_sensors=22,\n",
    "    final_hz=256,\n",
    "    start_ms=500,\n",
    "    stop_ms=1500,\n",
    "    half_before=True,\n",
    "    only_load_given_sensors=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "# create dist\n",
    "\n",
    "test_dist_inputs, test_dist_inputs_2 = load_train_test(\n",
    "    subject_id=5,\n",
    "    car=True,\n",
    "    n_sensors=22,\n",
    "    final_hz=256,\n",
    "    start_ms=500,\n",
    "    stop_ms=1500,\n",
    "    half_before=True,\n",
    "    only_load_given_sensors=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from reversible2.mixture import GaussianMixture, TwoClassMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_into_train_valid(train_inputs):\n",
    "    train_val = [th.chunk(t_ins, 2, dim=0) for t_ins in train_inputs]\n",
    "    # class 0 train/valid\n",
    "    # class 1 train/valid\n",
    "    train_inputs = [t for t,v in train_val]\n",
    "    valid_inputs = [v for t,v in train_val]\n",
    "    return train_inputs, valid_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tr_ins = [t[:,:].cuda() for t in train_inputs]\n",
    "te_ins = [t[:,:].cuda() for t in test_inputs]\n",
    "log_stds =  [th.zeros_like(flatten_2d(t), requires_grad=True) for t in tr_ins]\n",
    "for l in log_stds: l.data += 0;\n",
    "\n",
    "optim_log_stds = th.optim.Adam(log_stds, lr=1e-3)\n",
    "mixtures = [GaussianMixture(flatten_2d(t), l) for t,l in zip(tr_ins, log_stds)]\n",
    "mixture = TwoClassMixture(mixtures)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10001\n",
    "rand_noise_factor = 1e-2\n",
    "for i_epoch in range(n_epochs):\n",
    "    optim_log_stds.zero_grad()\n",
    "    for i_class in range(2):\n",
    "        tr_inds, val_inds = th.chunk(th.randperm(len(tr_ins[i_class])),2)\n",
    "        this_ins = flatten_2d(tr_ins[i_class][val_inds])\n",
    "        this_ins = this_ins + (th.rand_like(this_ins) - 0.5) * rand_noise_factor\n",
    "\n",
    "        mix = GaussianMixture(flatten_2d(tr_ins[i_class][tr_inds]), log_stds[i_class][tr_inds])\n",
    "        nll = -th.mean(mix.log_probs(this_ins))\n",
    "        nll.backward()\n",
    "        del mix\n",
    "        del this_ins\n",
    "    optim_log_stds.step()\n",
    "    if i_epoch % (n_epochs // 20) == 0:\n",
    "        print(\"Epoch {:d} of {:d}\".format(i_epoch, n_epochs))\n",
    "\n",
    "        for i_class in range(2):\n",
    "            for j_class in range(2):\n",
    "                nll = -th.mean(mixtures[j_class].log_probs(flatten_2d(tr_ins[i_class])))\n",
    "                print(\"NLL {:d}->{:d} {:.1E}\".format(i_class, j_class, nll.item(),))\n",
    "                \n",
    "        for setname, ins in ((\"Train\", tr_ins), (\"Test\", te_ins)):\n",
    "            corrects = []\n",
    "            for i_class in range(2):\n",
    "                corrects.extend(np.argmax(var_to_np(mixture.log_softmax(flatten_2d(ins[i_class]))), axis=1)  == i_class)\n",
    "            acc = np.mean(corrects)\n",
    "            print(\"{:6s} Accuracy: {:.1f}\".format(setname, acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reversible2.mixture import GaussianMixture\n",
    "mixtures = [GaussianMixture(flatten_2d(t), l) for t,l in zip(tr_ins, log_stds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 5000\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,3))\n",
    "for i_class in range(2):\n",
    "    samples = mixtures[i_class].sample(5000).view(-1, *train_inputs[0].shape[1:]).squeeze()\n",
    "    bps_fake = np.abs(np.fft.rfft(var_to_np(samples)))\n",
    "    plt.plot(np.fft.rfftfreq(256, 1/256.0), np.mean(np.mean(bps_fake, axis=0), axis=0),\n",
    "            color=seaborn.color_palette()[i_class], ls=\"--\",\n",
    "            label=\"Fake {:s}\".format([\"Right\", \"Rest\"][i_class]))\n",
    "    bps_real = np.abs(np.fft.rfft(var_to_np(train_inputs[i_class].squeeze())))\n",
    "    plt.plot(np.fft.rfftfreq(256, 1/256.0), np.mean(np.mean(bps_real, axis=0), axis=0),\n",
    "            color=seaborn.color_palette()[i_class], ls=\"-\",\n",
    "            label=\"Real {:s}\".format([\"Right\", \"Rest\"][i_class]))\n",
    "    \n",
    "plt.legend()\n",
    "plt.title(\"Spectrum of real and generated data\")\n",
    "plt.xlabel(\"Freq [Hz]\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reversible2.plot import plot_head_signals_tight\n",
    "\n",
    "plt.plot(var_to_np(samples)[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_head_signals_tight(var_to_np(samples)[0], sensor_names=sensor_names, figsize=(16,12))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Earlier:  Fixed split train/valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tr_ins, val_ins = split_into_train_valid(train_inputs)\n",
    "\n",
    "tr_ins = [t[:,:].cuda() for t in tr_ins]\n",
    "val_ins = [t[:,:].cuda() for t in val_ins]\n",
    "te_ins = [t[:,:].cuda() for t in test_inputs]\n",
    "log_stds =  [th.zeros_like(flatten_2d(t), requires_grad=True) for t in tr_ins]\n",
    "for l in log_stds: l.data += 0;\n",
    "\n",
    "mixtures = [GaussianMixture(flatten_2d(t), l) for t,l in zip(tr_ins, log_stds)]\n",
    "mixture = TwoClassMixture(mixtures)\n",
    "optim_log_stds = th.optim.Adam(log_stds, lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10001\n",
    "rand_noise_factor = 1e-2\n",
    "for i_epoch in range(n_epochs):\n",
    "    optim_log_stds.zero_grad()\n",
    "    for i_class in range(2):\n",
    "        this_ins = flatten_2d(val_ins[i_class])\n",
    "        this_ins = this_ins + (th.rand_like(this_ins) - 0.5) * rand_noise_factor\n",
    "        nll = -th.mean(mixtures[i_class].log_probs(this_ins))\n",
    "        nll.backward()\n",
    "    optim_log_stds.step()\n",
    "    if i_epoch % (n_epochs // 20) == 0:\n",
    "        print(\"Epoch {:d} of {:d}\".format(i_epoch, n_epochs))\n",
    "\n",
    "        for i_class in range(2):\n",
    "            for j_class in range(2):\n",
    "                nll = -th.mean(mixtures[j_class].log_probs(flatten_2d(val_ins[i_class])))\n",
    "                print(\"NLL {:d}->{:d} {:.1E}\".format(i_class, j_class, nll.item(),))\n",
    "                \n",
    "        for setname, ins in ((\"Train\", tr_ins), (\"Valid\", val_ins), (\"Test\", te_ins)):\n",
    "            corrects = []\n",
    "            for i_class in range(2):\n",
    "                corrects.extend(np.argmax(var_to_np(mixture.log_softmax(flatten_2d(ins[i_class]))), axis=1)  == i_class)\n",
    "            acc = np.mean(corrects)\n",
    "            print(\"{:6s} Accuracy: {:.1f}\".format(setname, acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(var_to_np(log_stds[0]).T, lw=0.5, color='black');\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(np.exp(var_to_np(log_stds[0]).T), lw=0.5, color='black');\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(np.mean(np.exp(var_to_np(log_stds[0])), axis=0), lw=0.5, color='black');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
