{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import importlib\n",
    "importlib.reload(logging) # see https://stackoverflow.com/a/21475297/1469195\n",
    "log = logging.getLogger()\n",
    "log.setLevel('INFO')\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s : %(message)s',\n",
    "                     level=logging.INFO, stream=sys.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import os\n",
    "import site\n",
    "os.sys.path.insert(0, '/home/schirrmr/code/reversible/')\n",
    "os.sys.path.insert(0, '/home/schirrmr/braindecode/code/braindecode/')\n",
    "os.sys.path.insert(0, '/home/schirrmr/code/explaining/reversible//')\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import logging\n",
    "log = logging.getLogger()\n",
    "log.setLevel('INFO')\n",
    "import sys\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s : %(message)s',\n",
    "                     level=logging.INFO, stream=sys.stdout)\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'png'\n",
    "matplotlib.rcParams['figure.figsize'] = (12.0, 1.0)\n",
    "matplotlib.rcParams['font.size'] = 14\n",
    "import seaborn\n",
    "seaborn.set_style('darkgrid')\n",
    "\n",
    "from reversible2.sliced import sliced_from_samples\n",
    "from numpy.random import RandomState\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import copy\n",
    "import math\n",
    "\n",
    "import itertools\n",
    "import torch as th\n",
    "from braindecode.torch_ext.util import np_to_var, var_to_np\n",
    "from reversible2.splitter import SubsampleSplitter\n",
    "\n",
    "from reversible2.view_as import ViewAs\n",
    "\n",
    "from reversible2.affine import AdditiveBlock\n",
    "from reversible2.plot import display_text, display_close\n",
    "th.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reversible2.high_gamma import load_train_test, to_signal_target\n",
    "train_inputs, test_inputs = load_train_test(subject_id=4, car=True,n_sensors=22,final_hz=256,\n",
    "                                           start_ms=500, stop_ms=1500,half_before=True,\n",
    "                                            only_load_given_sensors=False)\n",
    "\n",
    "cuda = True\n",
    "train_set, valid_set = to_signal_target(train_inputs, test_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reversible2.models import larger_model\n",
    "from braindecode.torch_ext.optimizers import AdamW\n",
    "import torch.nn.functional as F\n",
    "from reversible2.models import add_softmax, add_bnorm_before_relu, add_dropout_before_convs\n",
    "\n",
    "n_chans = train_inputs[0].shape[1]\n",
    "n_time = train_inputs[0].shape[2]\n",
    "\n",
    "feature_model = larger_model(n_chans=n_chans, n_time=n_time, final_fft=True, \n",
    "                             kernel_length=9, constant_memory=False)\n",
    "feature_model = add_softmax(feature_model)\n",
    "add_bnorm_before_relu(feature_model)\n",
    "add_dropout_before_convs(feature_model, p_conv=0.5, p_full=0.5)\n",
    "feature_model.cuda()\n",
    "\n",
    "from braindecode.models.base import BaseModel\n",
    "class WrappedModel(BaseModel):\n",
    "    def __init__(self, network):\n",
    "        self.given_network = network\n",
    "\n",
    "    def create_network(self):\n",
    "        return self.given_network\n",
    "\n",
    "from torch import nn\n",
    "from braindecode.torch_ext.util import set_random_seeds\n",
    "set_random_seeds(2019011641, cuda)\n",
    "model = WrappedModel(feature_model)\n",
    "model.cuda()\n",
    "lr = 1e-3\n",
    "weight_decay = 1e-3\n",
    "optimizer = AdamW(model.parameters(), lr=lr,\n",
    "                  weight_decay=weight_decay)\n",
    "\n",
    "max_epochs = 30\n",
    "model.compile(loss=F.nll_loss, optimizer=optimizer, iterator_seed=1, )\n",
    "model.fit(train_set.X, train_set.y, epochs=max_epochs, batch_size=64,\n",
    "          scheduler='cosine',\n",
    "          validation_data=(valid_set.X, valid_set.y), )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simpler Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transpose_1st_and_3rd_dim(x):\n",
    "    return x.permute(0, 3, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_chain_modules(n_chans, n_time, n_blocks_per_stage, n_filters_per_stage):\n",
    "    \n",
    "    cur_n_time = n_time\n",
    "    modules = []\n",
    "    i_stage = 0\n",
    "\n",
    "    while cur_n_time > 1:\n",
    "        chunk_chans_first = not (cur_n_time == n_time)\n",
    "        modules.append(SubsampleSplitter(stride=[2,1],chunk_chans_first=chunk_chans_first))\n",
    "        cur_n_time = cur_n_time  // 2\n",
    "        factor = int(2 ** (i_stage+1))\n",
    "\n",
    "        if cur_n_time == 1:\n",
    "            modules.append(ViewAs((-1,factor*n_chans,1,1), (-1, factor*n_chans,)))\n",
    "\n",
    "        for _ in range(n_blocks_per_stage):\n",
    "            if cur_n_time > 1:\n",
    "                modules.append(conv_add_3x3_no_switch(factor*n_chans, n_filters_per_stage[i_stage]))\n",
    "            else:\n",
    "                modules.append(dense_add_no_switch(factor*n_chans, n_filters_per_stage[i_stage]))\n",
    "        i_stage += 1\n",
    "    return modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reversible2.blocks import dense_add_no_switch, conv_add_3x3_no_switch\n",
    "from reversible2.view_as import ViewAs\n",
    "from reversible2.splitter import SubsampleSplitter\n",
    "from reversible2.rfft import RFFT\n",
    "from braindecode.torch_ext.modules import Expression\n",
    "\n",
    "n_blocks_per_stage = 3\n",
    "n_filters_per_stage = [32,48,64,128,192,256,384,512]\n",
    "\n",
    "\n",
    "cur_n_time = n_time\n",
    "modules = []\n",
    "i_stage = 0\n",
    "#modules.append(nn.Conv2d(n_chans,n_chans,(1,1)))\n",
    "modules.append(Expression(transpose_1st_and_3rd_dim))\n",
    "modules.append(\n",
    "    nn.Conv2d(\n",
    "        1, 25, (11, 1), stride=1,padding=(5,0)\n",
    "        ))\n",
    "modules.append(nn.Conv2d(25,n_chans,(1,n_chans)))\n",
    "\n",
    "modules.extend(create_chain_modules(n_chans, n_time, n_blocks_per_stage, n_filters_per_stage))\n",
    "\n",
    "feature_model = nn.Sequential(*modules, RFFT())\n",
    "feature_model = add_softmax(feature_model)\n",
    "add_bnorm_before_relu(feature_model)\n",
    "add_dropout_before_convs(feature_model, p_conv=0.2, p_full=0.5)\n",
    "feature_model.cuda()\n",
    "\n",
    "from torch import nn\n",
    "from braindecode.torch_ext.util import set_random_seeds\n",
    "set_random_seeds(2019011641, cuda)\n",
    "model = WrappedModel(feature_model)\n",
    "model.cuda()\n",
    "lr = 5e-4\n",
    "weight_decay = 1e-5\n",
    "optimizer = AdamW(model.parameters(), lr=lr,\n",
    "                  weight_decay=weight_decay)\n",
    "\n",
    "max_epochs = 30\n",
    "model.compile(loss=F.nll_loss, optimizer=optimizer, iterator_seed=1, )\n",
    "model.fit(train_set.X, train_set.y, epochs=max_epochs, batch_size=64,\n",
    "          scheduler='cosine',\n",
    "          validation_data=(valid_set.X, valid_set.y), )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from braindecode.models.deep4 import Deep4Net\n",
    "n_classes = 2\n",
    "model = Deep4Net(n_chans, n_classes,\n",
    "             input_time_length=train_set.X.shape[2],\n",
    "             pool_time_length=2,\n",
    "             pool_time_stride=2,\n",
    "             final_conv_length='auto')\n",
    "model.cuda()\n",
    "lr = 1 * 0.01\n",
    "weight_decay = 0.5 * 0.001\n",
    "optimizer = AdamW(model.parameters(), lr=lr,\n",
    "                  weight_decay=weight_decay)\n",
    "\n",
    "max_epochs = 30\n",
    "model.compile(loss=F.nll_loss, optimizer=optimizer, iterator_seed=1, )\n",
    "model.fit(train_set.X, train_set.y, epochs=max_epochs, batch_size=64,\n",
    "          scheduler='cosine',\n",
    "          validation_data=(valid_set.X, valid_set.y), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
